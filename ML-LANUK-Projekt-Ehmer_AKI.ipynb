{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f68948-dc8e-4163-b279-a274c975f8a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ML-Projekt - Entwicklung und Evaluation klassischer Machine Learning Modelle zur Luftqualitätsvorhersage basierend auf LANUK-Messdaten aus mindestens zwei NRW-Städten\n",
    "-----------------------------------------------------------------\n",
    "## 0. Projektvorbemerkungen und Zielsetzung\n",
    "-----------------------------------------------------------------\n",
    "## 1. Projekthintergrund und Motivation (Wissenschaftliche Einführung)\n",
    ">### 1.1 Thema\n",
    ">### 1.2 Projektziel\n",
    ">### 1.3 kurze wissenschaftliche Betrachtung\n",
    ">### 1.4 Datengrundlage\n",
    ">>#### 1.4.1 Datenquelle und - Verfügbarkeit\n",
    ">>#### 1.4.2 Warum die Auswahl auf Köln / Duisburg fiel\n",
    ">>#### 1.4.3 Betrachtete Daten\n",
    ">>#### 1.4.4 Herausforderungen bei den Daten\n",
    ">### 1.5 Vorangegangene Notebooks\n",
    ">### 1.6 Hinweise zum aktuellen Notebook\n",
    ">### 1.7 Code und Einsatz von KI im Projekt\n",
    "-----------------------------------------------------------------\n",
    "## 2. Methodischer Ansatz\n",
    ">### 2.1 eingesetzte Machine Learning Algorithmen\n",
    ">### 2.2 Einzelbetrachtung eingesetzte Machine Learning Algorithmen in Hinblick auf das Projekt\n",
    ">>#### 2.2.1 Warum XGBoost als Hauptmodell?\n",
    ">>#### 2.2.2 Warum Random Forest als Stabilisator?\n",
    ">>####  2.2.3 Warum Gradient Boosting als Spezialist?\n",
    ">>####  2.2.4 Warum Ensemble (Voting/Stacking)?\n",
    ">### 2.3 Warum diese Kombination die Projektherausforderungen lösen soll\n",
    ">### 2.4 Validierung der Modellwahl\n",
    ">### 2.5 Zusammenfassung\n",
    "-----------------------------------------------------------------     \n",
    "## 3. Technische Implementierung\n",
    ">### 3.1 Projektinitialisierung (Imports und Setup)\n",
    ">### 3.2 Pfade und Parameter definieren (Konfiguration )\n",
    ">### 3.3 Rohdaten einlesen (Datenimport)\n",
    ">### 3.4 Datenzusammenführung (Daten kombinieren)\n",
    ">### 3.5 Projekt-Zeitraum-Strategie\n",
    ">>#### 3.5.1 COVID-19 Sondereffekt und Zeitraum Strategie\n",
    ">>#### 3.5.2 Training: 2015-2022 (inkl. COVID)\n",
    ">>#### 3.5.3 Validation: 2023 (Post-COVID)\n",
    ">>#### 3.5.4 Test: 2024-2025 (Aktuelle Bedingungen)\n",
    ">### 3.6 Trainings-/Validierungs-/Test-Split - Daten in Training, Validation und Test aufteilen\n",
    "-----------------------------------------------------------------   \n",
    "\n",
    "## 4. Feature Engineering\n",
    ">### 4.1 Iterative Modelloptimierung: Von schlechten Ergebnissen zur Lösung (Teil A)\n",
    ">>#### 4.1.1 Problemstellung\n",
    ">>#### 4.1.2 Ziel der Tests\n",
    ">>>>#### 4.1.3 Test-Übersicht\n",
    ">>#### 4.1.4 Durchführung\n",
    ">>>##### 4.1.4.1 Schritt-für-Schritt Anleitung\n",
    ">>#### 4.1.5 Interpretation der Ergebnisse\n",
    ">>>##### 4.1.5.1 Schlechte Performance ohne Lag-Features\n",
    ">>>##### 4.1.5.2 Overfitting-Indikator\n",
    ">>#### 4.1.6 Physikalische Hintergründe\n",
    ">>>##### 4.1.6.1 Warum PM10 autokorreliert ist\n",
    ">>#### 4.1.7 Erwartete Erkenntnisse\n",
    ">>#### 4.1.8 Zielkriterien für finales Modell\n",
    ">### 4.2 Feature Engineering Anpassungen (Teil B)\n",
    ">>#### 4.2.1 Basis-Features erstellen\n",
    ">>#### 4.2.2 Langzeittrends neutralisieren\n",
    ">>#### 4.2.3 Die Autokorrelations-Falle\n",
    ">>>##### 4.2.3.1 Autokorrelation vs. Data Leakage\n",
    ">>>##### 4.2.3.2 Physikalische Grundlage und optimale Lag-Auswahl\n",
    ">>>##### 4.2.3.3 Praktische Implementierung\n",
    ">>>##### 4.2.3.4 Kritischer Implementierungsfehler\n",
    "-----------------------------------------------------------------   \n",
    "## 5. Systematische Modell-Tests (Iterativer Prozess)\n",
    ">### 5.1 Die Modell-Pipeline (Zellen 8-14)\n",
    ">>#### 5.1.1 XGBoost\n",
    ">>>##### 5.1.1.1 XGBoost - Grundlagen\n",
    ">>>##### 5.1.1.2 XGBoost Modell trainieren\n",
    ">>>##### 5.1.1.3 XGBoost Metriken und Modellbewertung\n",
    ">>>##### 5.1.1.4 XGBoost Feature Importance Analyse\n",
    ">>#### 5.1.2 Gradient Boosting\n",
    ">>>##### 5.1.2.1 Gradient Boosting - Grundlagen\n",
    ">>>##### 5.1.2.2 Gradient Boosting - Modell trainieren\n",
    ">>#### 5.1.3 Random Forest\n",
    ">>>##### 5.1.3.1 Random Forest - Grundlagen\n",
    ">>>##### 5.1.3.2 Random Forest - Modell trainieren\n",
    ">>#### 5.1.4 Ensemble\n",
    ">>>##### *5.1.4.1 Ensemble - Grundlagen\n",
    ">>>##### 5.1.4.2 Ensemble - Modelle kombinieren\n",
    ">>#### 5.1.5 Modellvergleich - Alle Modelle zusammen\n",
    ">### 5.2 Iterative Durchführung\n",
    ">>#### 5.2.1 Zusammenfassung aller 6 Testergebnisse\n",
    ">### 5.3 Wissenschaftliche Auswertung\n",
    ">>#### 5.3.1 Zusammenfassung der Untersuchung\n",
    ">>#### 5.3.2 Methodik und Datenbasis\n",
    ">>#### 5.3.3 Experimentelles Design\n",
    ">>#### 5.3.4 Modellperformance (Ergebnistabelle)\n",
    ">>#### 5.3.5 Kritische Beobachtungen\n",
    ">>#### 5.3.6 Autokorrelationsproblematik\n",
    ">>#### 5.3.7 Modellinterpretation\n",
    ">>#### 5.3.8 Vergleich mit operationellen Systemen\n",
    "\n",
    "-----------------------------------------------------------------   \n",
    "## 6. Zusammenfassung\n",
    "-----------------------------------------------------------------   \n",
    "\n",
    "## 8. Literaturverzeichnis\n",
    "-----------------------------------------------------------------   \n",
    "## 9. Anhang: Testergebnisse im Detail (Test 0-5)\n",
    "\n",
    "-----------------------------------------------------------------   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0da436-5905-4aed-b620-9cce06aed029",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "# 0. Vorbemerkungen zum Projekt\n",
    "\n",
    "## Motivation zur Datensatzauswahl\n",
    "\n",
    "Auf der Suche nach passenden Datensätzen zur Bearbeitung des Projektes stieß ich auf den LANUV Datensatz. Ziel bei der Suche nach Datensätzen war es, nach Möglichkeit einen Datensatz zu finden, der ML, im nächsten Semester DL und alle anderen Bereiche des Studiums bis hin zur Masterarbeit als Grundlage dienen sollte.\n",
    "\n",
    "## Aktuelle Nutzung der LANUK-Daten\n",
    "\n",
    "Bei weiteren Recherchen stellte sich folgendes Bild heraus: Die Daten werden zwar für verschiedene Projekte genutzt (LANUV: EURAD-IM Modell, iterac...), allerdings sind auch viele Forschungslücken vorhanden (Echtzeit-Anomalie-Erkennung, Multi Transfer Learning...). Dies bietet mir, dann mein Vorhaben umzusetzen und \"einen Datensatz\" bis zum Ende des Studium zu nutzen.\n",
    "Die Suche nach einem passenden Datensatz dauerte mehrere Wochen.\n",
    "\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559556ab-95c7-4969-a60d-0eeee4649463",
   "metadata": {},
   "source": [
    "# 1. Projekthintergrund und Motivation (Wissenschaftliche Einführung)\n",
    "## 1.1 Thema\n",
    "**Entwicklung und Evaluation klassischer Machine Learning Modelle zur Luftqualitätsvorhersage basierend auf LANUV-Messdaten aus mindestens zwei NRW-Städten**\n",
    "\n",
    "## 1.2 Projektziel\n",
    "Das Projekt zielt darauf ab, robuste Vorhersagemodelle für Luftqualitätsparameter (PM10, PM2.5, NO2, O3, SO2, CO) zu entwickeln, die 24-72 Stunden im Voraus präzise Prognosen ermöglichen. Durch die vergleichende Analyse mehrerer Städte (voraussichtlich Köln, Düsseldorf und Essen) soll eine solide Datenbasis für zukünftige Transfer Learning Ansätze im Deep Learning Bereich geschaffen werden.\n",
    "\n",
    "## 1.3 wissenschaftliche Betrachtung (kurz)\n",
    "Feinstaub (PM10 - Particulate Matter < 10 μm) stellt eine erhebliche Gefahr für \n",
    "die menschliche Gesundheit dar. Die WHO schätzt, dass Luftverschmutzung jährlich \n",
    "zu 7 Millionen vorzeitigen Todesfällen führt (WHO, 2021). Eine präzise Vorhersage \n",
    "von PM10-Konzentrationen ermöglicht:\n",
    "\n",
    "1. Frühwarnsysteme für vulnerable Bevölkerungsgruppen\n",
    "2. Evidenzbasierte Verkehrssteuerung\n",
    "3. Evaluierung von Umweltmaßnahmen\n",
    "\n",
    "## 1.4. Datengrundlage\n",
    "\n",
    "Die LANUk Daten werden stündlich an 747 Stationen und rund 252 Städte erfasst. \n",
    "\n",
    ">>### 1.4.1 Datenquell und - verfügbarkeit\n",
    "Die Luftqualitätsdaten stammen vom Landesamt für Natur, Umwelt und \n",
    "Konsumentenschutz Nordrhein-Westfalen (LANUK NRW).\n",
    "\n",
    "**Datenbereitstellung**: \n",
    "https://www.opengeodata.nrw.de/produkte/umwelt_klima/luftqualitaet/luqs/konti_nach_komponenten/ [1]\n",
    "\n",
    "**LANUK Homepage**: \n",
    "https://www.lanuk.nrw.de/ [2]\n",
    "\n",
    ">>### 1.4.2 Warum Fokus auf Köln/Duisburg?\n",
    "Die Analyse aller NRW-Stationen zeigte klare Cluster:\n",
    "\n",
    "- 44 Stadt-Cluster identifiziert mit unterschiedlicher Datenqualität\n",
    "- Top 20 Städte nach Luftqualität analysiert\n",
    "- Entscheidung: Köln und Duisburg bieten beste Kombination aus Datenverfügbarkeit, Stationsdichte und Relevanz (Großstädte mit Luftqualitätsproblemen)\n",
    "- Herausforderungen zur Datenlage siehe Dokumentation zum Projekt\n",
    "\n",
    "1. **Köln**: 37.6% Verfügbarkeit + vollständige Meteorologie\n",
    "2. **Duisburg**: 32.3% Verfügbarkeit + vollständige Meteorologie\n",
    "\n",
    ">>### 1.4.3 Betrachtete Daten\n",
    "Die Rohdaten umfassen stündliche Messungen von 742 Stationen über den Zeitraum 1980-2025 \n",
    "des Landesamts für Natur, Umwelt und Konsumentenschutz Nordrhein-Westfalen (LANUK NRW).\n",
    "Dieses Projekt nutzt stündliche Messdaten des Zeitraumes von 2015-2025.\n",
    "Zwar werden die PM10 - Werte (Feinstaub) schon seit Anfang 2001 erfasst, allerdings nicht flächendeckend und auch nicht kontinuierlich genug.\n",
    "aus diesem Grund habe ich mich auf die letzten 10 Jahre fokussiert.\n",
    "Die Daten umfassen:\n",
    "\n",
    "- Luftschadstoffe: PM10, NO2, NO, O3, SO2\n",
    "- Meteorologie: Temperatur (LTEM), relative Feuchte (RFEU)\n",
    "- Wind: Geschwindigkeit (WGES), Richtung (WRI)\n",
    "\n",
    "Fokusregionen: Köln (Stadt-ID: 131) und Duisburg (Stadt-ID: 47)\n",
    "\n",
    ">>### 1.4.4 Haurausforderungen bei den Daten\n",
    "\n",
    "- 70-94% NULL-Werte\n",
    "- Autokorrelation\n",
    "- Lückenmuster\n",
    "***Verfügbarkeit nach Parametern (742 Stationen):***\n",
    "\n",
    "| Parameter | Verfügbarkeit | Stationen | Bedeutung |\n",
    "|-----------|---------------|-----------|-----------|\n",
    "| PM10      | 30.6%        | 141       | Zielvariable |\n",
    "| NO2       | 13.6%        | 314       | Verkehrsindikator |\n",
    "| NO        | 7.0%         | 315       | Verkehrsindikator |\n",
    "| O3        | 10.2%        | 209       | Photochemie |\n",
    "| SO2       | 6.0%         | 245       | Industrie |\n",
    "| LTEM      | 29.9%        | 52        | Temperatur (kritisch) |\n",
    "| RFEU      | 29.3%        | 53        | Feuchtigkeit (kritisch) |\n",
    "| WGES      | 9.8%         | 290       | Windgeschwindigkeit |\n",
    "| WRI       | 11.0%        | 278       | Windrichtung |\n",
    "\n",
    ">### 1.5. Notebook-Pipeline\n",
    "\n",
    "Dieses Notebook ist Teil einer 5-teiligen Analysepipeline:\n",
    "\n",
    "1. **Datenzusammenführung**: Konsolidierung der LANUK-Rohdaten aus verschiedenen \n",
    "   Zeiträumen und Formaten\n",
    "   \n",
    "2. **Datenanalyse I**: Explorative Datenanalyse, Identifikation von Datenlücken,\n",
    "   Qualitätsprüfung und statistische Charakterisierung\n",
    "   \n",
    "3. **Imputation**: Behandlung fehlender Werte mittels verschiedener Verfahren\n",
    "   - Ergebnis: Nur marginale Verbesserung (0.1-1.2% R²-Gewinn)\n",
    "   - Entscheidung: Da alle Daten der Imputation unterzogen wurden, werden diese Daten auch verwendet im finalen Modell (XGBoost handhabt NaN nativ)\n",
    "   \n",
    "4. **Datenanalyse II (Selektion)**: Feature-Selektion, Identifikation relevanter\n",
    "   Stationen und Parameter für ML-Modellierung\n",
    "   \n",
    "5. **ML Projekt** (dieses Notebook): Training und Evaluation der Vorhersagemodelle\n",
    "   - WICHTIGE LEKTION: Lag-Features sind essentiell (90% der Vorhersagekraft)\n",
    "  \n",
    ">### 1.6. Hinweise zum aktuellen Notebook\n",
    "Es wurden aus dem Projekt einige Test-Szenarien implementiert. Siehe Dokumentation der Tests. Nachdem ersten Durchlauf und den schlechten \n",
    "Ergbnissen wurde nach möglichen Ursachen recherchiert. Diese Recherche und die Anwendungen sind im Bereich \"Feature Engineering\" direkt eingflossen.\n",
    "Die Recherche ist ebenfalls dokumentiert.\n",
    "\n",
    ">### 1.6. Code und Einsatz von KI im Projekt und Unterstützung\n",
    "Der Code ist im einfachen Code geschrieben. Das hat mir die \"Fehlersuche\" und das Verstehen der Modelle vereinfacht. Mir ist bewusst, dass\n",
    "ich durch den einfachen Code (viel Copy & Paste) sehr viel redundanten Code generiert habe. Aller Anfang ist schwer. Zudem habe ich viel \"printen\" lassen, um zu sehen, ob es durchläuft.\n",
    "Zum Debuggen habe ich Google und Claude benutzt. Bei Google wurden einige Bugs die ich recherchierte über Gemini beantwortet.\n",
    "Recherchen zum Projekt wurden über das klassische Google, Perplexity, Gemini (automatische Antwort bei Suchanfragen) und Claude durchgeführt.\n",
    "Korrekturlesung wurde durch meinen Sohn gemacht (IT Fachinformatiker Systemintegration / Anwendungsentwicklung).\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e9d33-f80c-49f2-82ff-6fca77fc0dc2",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------\n",
    "## 2. Methodischer Ansatz\n",
    "\n",
    ">### 2.1 Das Notebook implementiert und vergleicht mehrere Machine Learning Algorithmen:\n",
    "\n",
    "1. XGBoost [3]\n",
    "2. Gradient Boosting [3]\n",
    "3. Random Forest [3]\n",
    "4. Ensemble-Methoden (Voting, Stacking) [3]\n",
    "\n",
    ">### 2.2 Die Einzelbetrachtungen der Machine Learning Algorithmen in Bezug auf die ausgewählten Daten\n",
    "\n",
    ">>#### 2.2.1 Warum XGBoost als Hauptmodell?\n",
    "Killer-Feature: Native NULL-Behandlung\n",
    "\n",
    "- Bei 70-94% Lücken in Köln/Duisburg unverzichtbar\n",
    "- XGBoost entscheidet bei jedem Split automatisch, wohin NULL-Werte gehen\n",
    "- KEINE Imputation nötig (Tests zeigten nur 0.6-1.2% Verbesserung)\n",
    "- Speziell wichtig für Duisburg mit industriebedingten Sensorausfällen\n",
    "\n",
    "***Zusätzliche Vorteile für ausgewählte Städte:***\n",
    "- Behandelt Köln's urbane Muster UND Duisburg's Industrie-Charakteristika\n",
    "- Regularisierung verhindert Overfitting an Stations-IDs (CHOR, Hafen etc.)\n",
    "- Schnelles Training trotz großer Datenmenge beider Städte\n",
    "\n",
    ">>#### 2.2.2 Warum Random Forest als Stabilisator?\n",
    ">>Killer-Feature: Robustheit durch Zufälligkeit\n",
    ">>- Verhindert Überanpassung an Autokorrelation\n",
    ">>- Jeder Baum sieht andere Feature-Kombinationen\n",
    ">>- Mittelung über viele Bäume glättet Ausreißer\n",
    "\n",
    ">>Spezifisch für ausgewählte Daten:\n",
    "\n",
    ">>- Robust bei räumlicher Redundanz (ignoriert zufällig Stationen)\n",
    ">>- Gut bei Klassenungleichgewicht (Extremereignisse)\n",
    ">>- Funktioniert auch bei \"löchrigen\" Datensätzen\n",
    "\n",
    ">>#### 2.2.3 Warum Gradient Boosting als Spezialist?\n",
    ">>Killer-Feature: Lernt aus Fehlern\n",
    "\n",
    ">>- Fokussiert auf schwierige Fälle (Extremereignisse!)\n",
    ">>- Kann komplexe Änderungsmuster modellieren\n",
    ">>- Adaptiert sich an zeitliche Inhomogenitäten\n",
    "\n",
    ">>Einsatzgebiet:\n",
    "\n",
    ">>- Wenn normale Muster versagen\n",
    ">>- Bei systematischen Vorhersagefehlern\n",
    ">>- Für Trend-Änderungen\n",
    "\n",
    ">>#### 2.2.4 Warum Ensemble (Voting/Stacking)?\n",
    ">>Das \"Best of All Worlds\" Prinzip:\n",
    ">>- Situation A: Viele Daten verfügbar → XGBoost dominiert\n",
    ">>- Situation B: Viele Lücken → Random Forest übernimmt\n",
    ">>- Situation C: Extremereignis → Gradient Boosting aktiviert\n",
    ">>- Voting: Einfache gewichtete Mittelung\n",
    ">>- Stacking: Intelligentes Meta-Modell lernt optimale Kombination\n",
    "\n",
    "\n",
    ">### 2.3 Warum diese Kombination die Projektherausforderungen lösen soll\n",
    "> Lösungsmatrix\n",
    "| Problem | XGBoost | Random Forest | Gradient Boosting | Ensemble-Lösung |\n",
    "|---------|---------|---------------|-------------------|-----------------|\n",
    "| 70-94% NULL-Werte | **++** Nativ | **!!** Braucht Tricks | **--** Imputation | XGB führt |\n",
    "| Autokorrelation |**!!** Overfitting |**++** Randomisiert |**!!**  Kann lernen | RF balanciert |\n",
    "| Extremereignisse |**!!**  Zu selten | **++** Bagging hilft | **++** Fokussiert | GB für Extreme |\n",
    "| Lückenmuster | **++** Adaptiv | **++** Robust |**!!**  Sequenziell | Situativ wählen |\n",
    "| Stationseffekte | **--** Lernt IDs | **++** Ignoriert teilweise |**!!**  Kann abstrahieren | RF verhindert |\n",
    "\n",
    "> Legende\n",
    "\n",
    "> - ++:    Gut geeignet - Modell bewältigt Problem nativ\n",
    "> - !!:    Eingeschränkt - Funktioniert mit Anpassungen\n",
    "> - --:    Ungeeignet - Erhebliche Schwächen\n",
    "\n",
    ">### 2.4  Validierung der Modellwahl\n",
    "\n",
    "> **Empirische Bestätigung**\n",
    "> Imputation aus Extra- Notebook: 0.6-1.2% Verbesserung\n",
    "\n",
    "> - Zeigt: XGBoost's native NULL-Behandlung ist primäre Lösung\n",
    "> - ABER: Imputation mittels hoher Stations-Korrelation brachte messbare Verbesserung\n",
    "> - Bestätigt: Intelligente Nutzung der Autokorrelation für Datenvervollständigung sinnvoll\n",
    "\n",
    "> **Test-Modell mit reiner Autokorrelation:**\n",
    "\n",
    "> - R² = 0.994 → Zu gut um wahr zu sein!\n",
    "> - Entscheidung: Modell verworfen, Fokus auf robustere Ansätze\n",
    "> - Lektion: Hohe Metriken ≠ Gute Vorhersage\n",
    "\n",
    "> **Einzelmodell vs. Ensemble:**\n",
    "\n",
    "> - Einzelmodelle: Versagen bei spezifischen Szenarien\n",
    "> - Ensemble: Konsistent robust über alle Situationen\n",
    "\n",
    "> Zeitliche Stabilität:\n",
    "\n",
    "> - 2023 (sauberes Jahr) hätte Einzelmodelle verwirrt\n",
    "> - Ensemble adaptiert wahrscheinlich erfolgreich\n",
    "\n",
    "> **Theoretische Fundierung**\n",
    "    **No Free Lunch Theorem:**[4]\n",
    "\n",
    "> **\"Kein einzelner Algorithmus ist für alle Probleme optimal\"**\n",
    "\n",
    "> Die Projekt-Lösung: Kombiniere mehrere Algorithmen!\n",
    "\n",
    "\n",
    ">### 2.6 Zusammenfassung\n",
    "\n",
    "> **Kernerkenntnisse**\n",
    "Die Kombination \n",
    "XGBoost + Random Forest + Gradient Boosting + Ensemble \n",
    "ist keine willkürliche Wahl, sondern die logische Antwort auf unsere spezifischen Herausforderungen:\n",
    "\n",
    "> - Massive Datenlücken → XGBoost's native NULL-Behandlung\n",
    "> - Autokorrelations-Falle → Random Forest's Randomisierung\n",
    "> - Seltene Extremereignisse → Gradient Boosting's Fehler-Fokus\n",
    "> - Heterogene Muster → Ensemble's adaptive Kombination\n",
    "\n",
    "> **Der entscheidende Vorteil:**\n",
    "Nicht die Suche nach dem \"perfekten\" Modell, sondern die Erkenntnis:\n",
    "\n",
    "**Verschiedene Probleme brauchen verschiedene Lösungen - gleichzeitig!**\n",
    "\n",
    "Das Ensemble ermöglicht, für jede Datensituation die optimale Modellkombination zu nutzen, ohne im Vorfeld wissen zu müssen, welche Situation gerade vorliegt.\n",
    "\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addbafc0-9e85-4cbd-bd7d-20e9f934b1ac",
   "metadata": {},
   "source": [
    "# 3. Technische Implementierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6eb849-8907-412c-aa40-56b7f8d8bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup abgeschlossen - Alle Bibliotheken erfolgreich importiert\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 3.1  Projektinitialisierung - Imports und Setup\n",
    "# ================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error # Standard Metriken implemnetieren\n",
    "from sklearn.ensemble import (GradientBoostingRegressor, RandomForestRegressor, \n",
    "                            VotingRegressor, StackingRegressor) # PEML: S. 259,266\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Unterdrücke Warnungen für bessere Lesbarkeit\n",
    "warnings.filterwarnings('ignore') #https://python-forum.io/thread-35299.html\n",
    "\n",
    "print(\"Setup abgeschlossen - Alle Bibliotheken erfolgreich importiert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793ef0e8-2812-4ecf-b33f-6303b3fb8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Datenverzeichnis: C:\\Users\\simeo\\output\\ml_data\n",
      " Zielvariable: PM10\n",
      " Input-Features: NO2, NO, O3, SO2, LTEM, RFEU, WGES, WRI\n",
      " Städte: Köln & Duisburg\n",
      "\n",
      "Prüfe verfügbare Dateien...\n",
      "Gefundene Dateien:\n",
      "  ✓ PM10  - pm10_koeln_duisburg_2015-01_2025-07.csv (5.26 MB)\n",
      "  ✓ NO2   - no2_koeln_duisburg_2015-01_2025-07.csv (5.22 MB)\n",
      "  ✓ NO    - no_koeln_duisburg_2015-01_2025-07.csv (4.02 MB)\n",
      "  ✓ O3    - o3_koeln_duisburg_2015-01_2025-07.csv (3.00 MB)\n",
      "  ✓ SO2   - so2_koeln_duisburg_2015-01_2025-07.csv (2.73 MB)\n",
      "  ✓ LTEM  - ltem_koeln_duisburg_2015-01_2025-07.csv (4.43 MB)\n",
      "  ✓ RFEU  - rfeu_koeln_duisburg_2015-01_2025-07.csv (4.63 MB)\n",
      "  ✓ WGES  - wges_koeln_duisburg_2015-01_2025-07.csv (4.48 MB)\n",
      "  ✓ WRI   - wri_koeln_duisburg_2015-01_2025-07.csv (5.51 MB)\n",
      "\n",
      " 9 von 9 Dateien verfügbar\n",
      "\n",
      "============================================================\n",
      "Konfiguration bereit.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 3.2 Pfade und Parameter definieren - Konfiguration \n",
    "# ================================================================================\n",
    "\n",
    "# DATEIPFADE\n",
    "# Pfad zu den exportierten ML-Daten\n",
    "ML_DATA_PATH = r\"C:\\Users\\simeo\\output\\ml_data\"\n",
    "\n",
    "# VERFÜGBARE DATEIEN \n",
    "# Diese Dateien wurden von Zelle 13 exportiert\n",
    "# Format: parameter_städte_zeitraum.csv\n",
    "VERFUEGBARE_DATEIEN = {\n",
    "    'PM10': 'pm10_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'NO2': 'no2_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'NO': 'no_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'O3': 'o3_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'SO2': 'so2_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'LTEM': 'ltem_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'RFEU': 'rfeu_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'WGES': 'wges_koeln_duisburg_2015-01_2025-07.csv',\n",
    "    'WRI': 'wri_koeln_duisburg_2015-01_2025-07.csv'\n",
    "}\n",
    "\n",
    "# PARAMETER FÜR ML \n",
    "# Hauptparameter für Luftqualitätsvorhersage\n",
    "ML_PARAMETER = {\n",
    "    'target': 'PM10',  # Zielvariable\n",
    "    'features': ['NO2', 'NO', 'O3','SO2', 'LTEM', 'RFEU', 'WGES', 'WRI'],  # Input-Features\n",
    "    'optional': ['O3', 'SO2']  # Optionale Features\n",
    "}\n",
    "\n",
    "# STÄDTE-Stationen\n",
    "# Die Daten enthalten Köln und Duisburg\n",
    "STAEDTE_INFO = {\n",
    "    '131': {\n",
    "        'name': 'Köln',\n",
    "        'stationen_erwartet': ['CHOR', 'RIEH', 'RODE', 'VKCL', 'VKOE', 'VKTU', 'VOGE']\n",
    "    },\n",
    "    '47': {\n",
    "        'name': 'Duisburg', \n",
    "        'stationen_erwartet': ['BUCH', 'DUB2', 'DUBR', 'DURH', 'KALD', 'MEID', 'VDUI', 'VDUR', 'WALS']\n",
    "    }\n",
    "}\n",
    "\n",
    "#  ZEITRÄUME FÜR SPLIT \n",
    "# Diese Zeiträume werden für Train/Val/Test Split verwendet\n",
    "# (Die Dateien enthalten bereits nur 2015-01 bis 2025-07) da vorher selektiert\n",
    "ZEITRAEUME = {\n",
    "    'gesamt': {\n",
    "        'start': '2015-01-01',\n",
    "        'ende': '2025-07-31'\n",
    "    },\n",
    "    'training': {\n",
    "        'start': '2015-01-01',\n",
    "        'ende': '2022-12-31',\n",
    "        'beschreibung': '8 Jahre (inkl. COVID-Zeit)'\n",
    "    },\n",
    "    'validation': {\n",
    "        'start': '2023-01-01',\n",
    "        'ende': '2023-12-31',\n",
    "        'beschreibung': '1 Jahr'\n",
    "    },\n",
    "    'test': {\n",
    "        'start': '2024-01-01',\n",
    "        'ende': '2025-07-31',\n",
    "        'beschreibung': '1.5 Jahre (aktuelle Daten)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# HELFER FUNKTIONEN \n",
    "def check_files():\n",
    "    \"\"\"Prüft welche Dateien vorhanden sind\"\"\"\n",
    "    print(\"\\nPrüfe verfügbare Dateien...\")\n",
    "    gefunden = []\n",
    "    fehlt = []\n",
    "    \n",
    "    for param, filename in VERFUEGBARE_DATEIEN.items():\n",
    "        filepath = os.path.join(ML_DATA_PATH, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "            gefunden.append(f\"  ✓ {param:5} - {filename} ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            fehlt.append(f\"  ✗ {param:5} - {filename}\")\n",
    "    \n",
    "    if gefunden:\n",
    "        print(\"Gefundene Dateien:\")\n",
    "        for f in gefunden:\n",
    "            print(f)\n",
    "    \n",
    "    if fehlt:\n",
    "        print(\"\\nFehlende Dateien:\")\n",
    "        for f in fehlt:\n",
    "            print(f)\n",
    "    \n",
    "    return len(gefunden), len(fehlt)\n",
    "\n",
    "# STATUS AUSGABE \n",
    "print(f\"\\n Datenverzeichnis: {ML_DATA_PATH}\")\n",
    "print(f\" Zielvariable: {ML_PARAMETER['target']}\")\n",
    "print(f\" Input-Features: {', '.join(ML_PARAMETER['features'])}\")\n",
    "print(f\" Städte: Köln & Duisburg\")\n",
    "\n",
    "# Prüfe Dateien\n",
    "gefunden, fehlt = check_files()\n",
    "\n",
    "if gefunden > 0:\n",
    "    print(f\"\\n {gefunden} von {len(VERFUEGBARE_DATEIEN)} Dateien verfügbar\")\n",
    "else:\n",
    "    print(f\"\\n WARNUNG: Keine Dateien gefunden!\")\n",
    "    print(f\"   Bitte prüfen Sie ob der Pfad korrekt ist: {ML_DATA_PATH}\")\n",
    "    print(f\"   Haben Sie Zelle 13 (Datenexport) ausgeführt?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Konfiguration bereit.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c265366e-3c38-4a8f-85a9-c041bc73885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Lade PM10 Daten...\n",
      "   OK: PM10 geladen! Größe: (87601, 13)\n",
      "   Erste Spalten: ['47-BUCH', '47-DUB2', '47-DUBR', '47-DURH', '47-MEID']\n",
      "\n",
      "2. Lade NO2 Daten...\n",
      "   OK: NO2 geladen! Größe: (87601, 16)\n",
      "\n",
      "3. Lade NO Daten...\n",
      "   OK: NO geladen! Größe: (87601, 16)\n",
      "\n",
      "4. Lade O3 (Ozon) Daten...\n",
      "   OK: O3 geladen! Größe: (87601, 5)\n",
      "\n",
      "5. Lade SO2 Daten...\n",
      "   OK: SO2 geladen! Größe: (87601, 10)\n",
      "\n",
      "6. Lade Temperatur Daten...\n",
      "   OK: Temperatur geladen! Größe: (87601, 8)\n",
      "\n",
      "7. Lade Luftfeuchtigkeit Daten...\n",
      "   OK: Feuchtigkeit geladen! Größe: (87601, 8)\n",
      "\n",
      "8. Lade Windgeschwindigkeit Daten...\n",
      "   OK: Windgeschwindigkeit geladen! Größe: (87601, 10)\n",
      "\n",
      "9. Lade Windrichtung Daten...\n",
      "   OK: Windrichtung geladen! Größe: (87601, 10)\n",
      "\n",
      "============================================================\n",
      "DATENIMPORT ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "Erfolgreich geladen: 9 von 9 Dateien\n",
      "\n",
      "PM10 Zeitraum-Check:\n",
      "  Erste Zeilen: [Timestamp('2015-01-01 00:00:00'), Timestamp('2015-01-01 01:00:00'), Timestamp('2015-01-01 02:00:00')]\n",
      "  Letzte Zeilen: [Timestamp('2025-07-30 22:00:00'), Timestamp('2025-07-30 23:00:00'), Timestamp('2025-07-31 00:00:00')]\n",
      "\n",
      "Daten sind bereit\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Dictionary\n",
      "  PM10 ins Dictionary\n",
      "  NO2 ins Dictionary\n",
      "  NO ins Dictionary\n",
      "  O3 ins Dictionary\n",
      "  SO2 ins Dictionary\n",
      "  LTEM ins Dictionary\n",
      "  RFEU ins Dictionary\n",
      "  WGES ins Dictionary\n",
      "  WRI ins Dictionary\n",
      "\n",
      "Dictionary erstellt mit 9 Parametern\n",
      "Verfügbare Parameter: ['PM10', 'NO2', 'NO', 'O3', 'SO2', 'LTEM', 'RFEU', 'WGES', 'WRI']\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 3.3 Rohdaten einlesen - Datenimport\n",
    "# ================================================================================\n",
    "# Ich speichere den Pfad zu meinen Daten\n",
    "# KORRIGIERT: Richtige Pfad zu den ML-Daten\n",
    "mein_pfad = \"C:/Users/simeo/output/ml_data/\"\n",
    "\n",
    "# PM10 LADEN\n",
    "print(\"\\n1. Lade PM10 Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    pm10_datei = mein_pfad + \"pm10_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    pm10_daten = pd.read_csv(pm10_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: PM10 geladen! Größe: {pm10_daten.shape}\")\n",
    "    \n",
    "    # Erste Zeilen anschauen\n",
    "    print(\"   Erste Spalten:\", list(pm10_daten.columns[:5]))\n",
    "except:\n",
    "    print(\"   FEHLER: PM10 konnte nicht geladen werden!\")\n",
    "    pm10_daten = None\n",
    "\n",
    "# NO2 LADEN\n",
    "print(\"\\n2. Lade NO2 Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    no2_datei = mein_pfad + \"no2_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    no2_daten = pd.read_csv(no2_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: NO2 geladen! Größe: {no2_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: NO2 konnte nicht geladen werden!\")\n",
    "    no2_daten = None\n",
    "\n",
    "# NO LADEN \n",
    "print(\"\\n3. Lade NO Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    no_datei = mein_pfad + \"no_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    no_daten = pd.read_csv(no_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: NO geladen! Größe: {no_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: NO konnte nicht geladen werden!\")\n",
    "    no_daten = None\n",
    "\n",
    "# O3 LADEN \n",
    "print(\"\\n4. Lade O3 (Ozon) Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    o3_datei = mein_pfad + \"o3_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    o3_daten = pd.read_csv(o3_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: O3 geladen! Größe: {o3_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: O3 konnte nicht geladen werden!\")\n",
    "    o3_daten = None\n",
    "\n",
    "# SO2 LADEN \n",
    "print(\"\\n5. Lade SO2 Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    so2_datei = mein_pfad + \"so2_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    so2_daten = pd.read_csv(so2_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: SO2 geladen! Größe: {so2_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: SO2 konnte nicht geladen werden!\")\n",
    "    so2_daten = None\n",
    "\n",
    "# TEMPERATUR LADEN\n",
    "print(\"\\n6. Lade Temperatur Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    temp_datei = mein_pfad + \"ltem_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    temp_daten = pd.read_csv(temp_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: Temperatur geladen! Größe: {temp_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: Temperatur konnte nicht geladen werden!\")\n",
    "    temp_daten = None\n",
    "\n",
    "# FEUCHTIGKEIT LADEN \n",
    "print(\"\\n7. Lade Luftfeuchtigkeit Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    feuchte_datei = mein_pfad + \"rfeu_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    feuchte_daten = pd.read_csv(feuchte_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: Feuchtigkeit geladen! Größe: {feuchte_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: Feuchtigkeit konnte nicht geladen werden!\")\n",
    "    feuchte_daten = None\n",
    "\n",
    "# WINDGESCHWINDIGKEIT LADEN \n",
    "print(\"\\n8. Lade Windgeschwindigkeit Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    wind_datei = mein_pfad + \"wges_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    wind_daten = pd.read_csv(wind_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: Windgeschwindigkeit geladen! Größe: {wind_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: Windgeschwindigkeit konnte nicht geladen werden!\")\n",
    "    wind_daten = None\n",
    "\n",
    "#  WINDRICHTUNG LADEN \n",
    "print(\"\\n9. Lade Windrichtung Daten...\")\n",
    "try:\n",
    "    # KORRIGIERT: Richtiger Dateiname + DateTime-Index\n",
    "    windrichtung_datei = mein_pfad + \"wri_koeln_duisburg_2015-01_2025-07.csv\"\n",
    "    windrichtung_daten = pd.read_csv(windrichtung_datei, sep=';', decimal=',', index_col=0, parse_dates=True)\n",
    "    print(f\"   OK: Windrichtung geladen! Größe: {windrichtung_daten.shape}\")\n",
    "except:\n",
    "    print(\"   FEHLER: Windrichtung konnte nicht geladen werden!\")\n",
    "    windrichtung_daten = None\n",
    "\n",
    "# ZUSAMMENFASSUNG \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATENIMPORT ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Zähle erfolgreich geladene Dateien\n",
    "geladene_dateien = 0\n",
    "if pm10_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if no2_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if no_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if o3_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if so2_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if temp_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if feuchte_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if wind_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "if windrichtung_daten is not None:\n",
    "    geladene_dateien += 1\n",
    "\n",
    "print(f\"\\nErfolgreich geladen: {geladene_dateien} von 9 Dateien\")\n",
    "\n",
    "# Zeige Zeitraum der PM10 Daten (falls geladen)\n",
    "if pm10_daten is not None and not pm10_daten.empty:\n",
    "    # Erste und letzte Zeile anschauen (Index sollte DateTime sein)\n",
    "    print(f\"\\nPM10 Zeitraum-Check:\")\n",
    "    print(f\"  Erste Zeilen: {pm10_daten.head(3).index.tolist()}\")\n",
    "    print(f\"  Letzte Zeilen: {pm10_daten.tail(3).index.tolist()}\")\n",
    "\n",
    "print(\"\\nDaten sind bereit\")\n",
    "\n",
    "# ERSTELLE DICTIONARY \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Dictionary\")\n",
    "\n",
    "# Sammle alle geladenen Daten in einem Dictionary\n",
    "# (Zelle 4 braucht das Format all_data['PM10'] etc.)\n",
    "all_data = {}\n",
    "\n",
    "if pm10_daten is not None:\n",
    "    all_data['PM10'] = pm10_daten\n",
    "    print(\"  PM10 ins Dictionary\")\n",
    "\n",
    "if no2_daten is not None:\n",
    "    all_data['NO2'] = no2_daten\n",
    "    print(\"  NO2 ins Dictionary\")\n",
    "\n",
    "if no_daten is not None:\n",
    "    all_data['NO'] = no_daten\n",
    "    print(\"  NO ins Dictionary\")\n",
    "\n",
    "if o3_daten is not None:\n",
    "    all_data['O3'] = o3_daten\n",
    "    print(\"  O3 ins Dictionary\")\n",
    "\n",
    "if so2_daten is not None:\n",
    "    all_data['SO2'] = so2_daten\n",
    "    print(\"  SO2 ins Dictionary\")\n",
    "\n",
    "if temp_daten is not None:\n",
    "    all_data['LTEM'] = temp_daten\n",
    "    print(\"  LTEM ins Dictionary\")\n",
    "\n",
    "if feuchte_daten is not None:\n",
    "    all_data['RFEU'] = feuchte_daten\n",
    "    print(\"  RFEU ins Dictionary\")\n",
    "\n",
    "if wind_daten is not None:\n",
    "    all_data['WGES'] = wind_daten\n",
    "    print(\"  WGES ins Dictionary\")\n",
    "\n",
    "if windrichtung_daten is not None:\n",
    "    all_data['WRI'] = windrichtung_daten\n",
    "    print(\"  WRI ins Dictionary\")\n",
    "\n",
    "print(f\"\\nDictionary erstellt mit {len(all_data)} Parametern\")\n",
    "print(f\"Verfügbare Parameter: {list(all_data.keys())}\")\n",
    "\n",
    "# ANMERKUNG:\n",
    "# Diese Daten sind bereits vorgefiltert auf Köln und Duisburg\n",
    "# und auf den Zeitraum 2015-01-01 bis 2025-07-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f046b3e9-c04e-4a3f-9042-2d9eaedae550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KOMBINIERE ALLE PARAMETER IN EINEN GROSSEN DATAFRAME\n",
      "============================================================\n",
      "\n",
      "Schritt 1: Spalten umbenennen...\n",
      "----------------------------------------\n",
      "\n",
      "Bearbeite PM10 (Feinstaub)...\n",
      "  47-BUCH -> BUCH_PM10\n",
      "  47-DUB2 -> DUB2_PM10\n",
      "  47-DUBR -> DUBR_PM10\n",
      "  47-DURH -> DURH_PM10\n",
      "  47-MEID -> MEID_PM10\n",
      "  47-VDUI -> VDUI_PM10\n",
      "  47-VDUR -> VDUR_PM10\n",
      "  47-WALS -> WALS_PM10\n",
      "  131-CHOR -> CHOR_PM10\n",
      "  131-RODE -> RODE_PM10\n",
      "  131-VKCL -> VKCL_PM10\n",
      "  131-VKOE -> VKOE_PM10\n",
      "  131-VKTU -> VKTU_PM10\n",
      "\n",
      "Bearbeite NO2 (Stickstoffdioxid)...\n",
      "  47-BUCH -> BUCH_NO2\n",
      "  47-DUB2 -> DUB2_NO2\n",
      "  47-DUBR -> DUBR_NO2\n",
      "  47-DURH -> DURH_NO2\n",
      "  47-KALD -> KALD_NO2\n",
      "  47-MEID -> MEID_NO2\n",
      "  47-VDUI -> VDUI_NO2\n",
      "  47-VDUR -> VDUR_NO2\n",
      "  47-WALS -> WALS_NO2\n",
      "  131-CHOR -> CHOR_NO2\n",
      "  131-RIEH -> RIEH_NO2\n",
      "  131-RODE -> RODE_NO2\n",
      "  131-VKCL -> VKCL_NO2\n",
      "  131-VKOE -> VKOE_NO2\n",
      "  131-VKTU -> VKTU_NO2\n",
      "  131-VOGE -> VOGE_NO2\n",
      "\n",
      "Bearbeite NO (Stickstoffmonoxid)...\n",
      "  47-BUCH -> BUCH_NO\n",
      "  47-DUB2 -> DUB2_NO\n",
      "  47-DUBR -> DUBR_NO\n",
      "  47-DURH -> DURH_NO\n",
      "  47-KALD -> KALD_NO\n",
      "  47-MEID -> MEID_NO\n",
      "  47-VDUI -> VDUI_NO\n",
      "  47-VDUR -> VDUR_NO\n",
      "  47-WALS -> WALS_NO\n",
      "  131-CHOR -> CHOR_NO\n",
      "  131-RIEH -> RIEH_NO\n",
      "  131-RODE -> RODE_NO\n",
      "  131-VKCL -> VKCL_NO\n",
      "  131-VKOE -> VKOE_NO\n",
      "  131-VKTU -> VKTU_NO\n",
      "  131-VOGE -> VOGE_NO\n",
      "\n",
      "Bearbeite O3 (Ozon)...\n",
      "  47-DUBR -> DUBR_O3\n",
      "  47-WALS -> WALS_O3\n",
      "  131-CHOR -> CHOR_O3\n",
      "  131-RIEH -> RIEH_O3\n",
      "  131-RODE -> RODE_O3\n",
      "\n",
      "Bearbeite SO2 Schwefeldioxid)...\n",
      "  47-BUCH -> BUCH_SO2\n",
      "  47-DUB2 -> DUB2_SO2\n",
      "  47-DUBR -> DUBR_SO2\n",
      "  47-KALD -> KALD_SO2\n",
      "  47-MEID -> MEID_SO2\n",
      "  47-WALS -> WALS_SO2\n",
      "  131-CHOR -> CHOR_SO2\n",
      "  131-RIEH -> RIEH_SO2\n",
      "  131-RODE -> RODE_SO2\n",
      "  131-VOGE -> VOGE_SO2\n",
      "\n",
      "Bearbeite LTEM (Temperatur)...\n",
      "  47-DUB2 -> DUB2_LTEM\n",
      "  47-DUBR -> DUBR_LTEM\n",
      "  47-DURH -> DURH_LTEM\n",
      "  47-WALS -> WALS_LTEM\n",
      "  131-CHOR -> CHOR_LTEM\n",
      "  131-RODE -> RODE_LTEM\n",
      "  131-VKCL -> VKCL_LTEM\n",
      "  131-VKTU -> VKTU_LTEM\n",
      "\n",
      "Bearbeite RFEU (Feuchtigkeit)...\n",
      "  47-DUB2 -> DUB2_RFEU\n",
      "  47-DUBR -> DUBR_RFEU\n",
      "  47-DURH -> DURH_RFEU\n",
      "  47-WALS -> WALS_RFEU\n",
      "  131-CHOR -> CHOR_RFEU\n",
      "  131-RODE -> RODE_RFEU\n",
      "  131-VKCL -> VKCL_RFEU\n",
      "  131-VKTU -> VKTU_RFEU\n",
      "\n",
      "Bearbeite WGES (Windgeschwindigkeit)...\n",
      "  47-BUCH -> BUCH_WGES\n",
      "  47-DUB2 -> DUB2_WGES\n",
      "  47-DUBR -> DUBR_WGES\n",
      "  47-DURH -> DURH_WGES\n",
      "  47-VDUR -> VDUR_WGES\n",
      "  47-WALS -> WALS_WGES\n",
      "  131-CHOR -> CHOR_WGES\n",
      "  131-RODE -> RODE_WGES\n",
      "  131-VKCL -> VKCL_WGES\n",
      "  131-VKTU -> VKTU_WGES\n",
      "\n",
      "Bearbeite WRI (Windrichtung)...\n",
      "  47-BUCH -> BUCH_WRI\n",
      "  47-DUB2 -> DUB2_WRI\n",
      "  47-DUBR -> DUBR_WRI\n",
      "  47-DURH -> DURH_WRI\n",
      "  47-VDUR -> VDUR_WRI\n",
      "  47-WALS -> WALS_WRI\n",
      "  131-CHOR -> CHOR_WRI\n",
      "  131-RODE -> RODE_WRI\n",
      "  131-VKCL -> VKCL_WRI\n",
      "  131-VKTU -> VKTU_WRI\n",
      "\n",
      "============================================================\n",
      "Schritt 2: Alle DataFrames zusammenfuegen...\n",
      "============================================================\n",
      "\n",
      "Anzahl DataFrames zum Kombinieren: 9\n",
      "Starte mit 13 Spalten\n",
      "Nach DataFrame 2: 29 Spalten\n",
      "Nach DataFrame 3: 45 Spalten\n",
      "Nach DataFrame 4: 50 Spalten\n",
      "Nach DataFrame 5: 60 Spalten\n",
      "Nach DataFrame 6: 68 Spalten\n",
      "Nach DataFrame 7: 76 Spalten\n",
      "Nach DataFrame 8: 86 Spalten\n",
      "Nach DataFrame 9: 96 Spalten\n",
      "\n",
      "============================================================\n",
      "KOMBINATION ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "Finaler DataFrame:\n",
      "  Zeilen (Zeitpunkte): 87601\n",
      "  Spalten (Messreihen): 96\n",
      "  Zeitraum: 2015-01-01 00:00:00 bis 2025-07-31 00:00:00\n",
      "\n",
      "Beispiel-Spalten (ersten 10):\n",
      "    1. BUCH_PM10\n",
      "    2. DUB2_PM10\n",
      "    3. DUBR_PM10\n",
      "    4. DURH_PM10\n",
      "    5. MEID_PM10\n",
      "    6. VDUI_PM10\n",
      "    7. VDUR_PM10\n",
      "    8. WALS_PM10\n",
      "    9. CHOR_PM10\n",
      "    10. RODE_PM10\n",
      "    ... und 86 weitere\n",
      "\n",
      "Fehlende Werte:\n",
      "  Total: 4256233 von 8409696\n",
      "  Prozent: 50.6%\n",
      "\n",
      "Variable 'df_combined' enthaelt alle kombinierten Daten\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 3.4 Datenzusammenführung - Daten kombinieren \n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KOMBINIERE ALLE PARAMETER IN EINEN GROSSEN DATAFRAME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# all_data kommt aus Zelle 3\n",
    "# Es enthaelt: PM10, NO2, NO, O3, SO2, LTEM, RFEU, WGES, WRI\n",
    "\n",
    "print(\"\\nSchritt 1: Spalten umbenennen...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Ich mache fuer jeden Parameter einen neuen DataFrame mit besseren Namen\n",
    "alle_dataframes = []\n",
    "\n",
    "# PM10 (Feinstaub)\n",
    "if \"PM10\" in all_data:\n",
    "    print(\"\\nBearbeite PM10 (Feinstaub)...\")\n",
    "    pm10_df = all_data[\"PM10\"]\n",
    "    \n",
    "    # Neue Spaltennamen erstellen\n",
    "    neue_namen = {}\n",
    "    for alte_spalte in pm10_df.columns:\n",
    "        # \"131-CHOR\" wird zu \"CHOR_PM10\"\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]  # CHOR\n",
    "            neuer_name = station + \"_PM10\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    # Spalten umbenennen\n",
    "    pm10_renamed = pm10_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(pm10_renamed)\n",
    "\n",
    "# NO2 (Stickstoffdioxid)\n",
    "if \"NO2\" in all_data:\n",
    "    print(\"\\nBearbeite NO2 (Stickstoffdioxid)...\")\n",
    "    no2_df = all_data[\"NO2\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in no2_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_NO2\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    no2_renamed = no2_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(no2_renamed)\n",
    "\n",
    "# NO (Stickstoffmonxid)\n",
    "if \"NO\" in all_data:\n",
    "    print(\"\\nBearbeite NO (Stickstoffmonoxid)...\")\n",
    "    no_df = all_data[\"NO\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in no_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_NO\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    no_renamed = no_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(no_renamed)\n",
    "\n",
    "# O3 (Ozon)\n",
    "if \"O3\" in all_data:\n",
    "    print(\"\\nBearbeite O3 (Ozon)...\")\n",
    "    o3_df = all_data[\"O3\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in o3_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_O3\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    o3_renamed = o3_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(o3_renamed)\n",
    "\n",
    "# SO2 (Schwefeldioxid)\n",
    "if \"SO2\" in all_data:\n",
    "    print(\"\\nBearbeite SO2 Schwefeldioxid)...\")\n",
    "    so2_df = all_data[\"SO2\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in so2_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_SO2\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    so2_renamed = so2_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(so2_renamed)\n",
    "\n",
    "# LTEM (Temperatur)\n",
    "if \"LTEM\" in all_data:\n",
    "    print(\"\\nBearbeite LTEM (Temperatur)...\")\n",
    "    ltem_df = all_data[\"LTEM\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in ltem_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_LTEM\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    ltem_renamed = ltem_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(ltem_renamed)\n",
    "\n",
    "# RFEU (Feuchtigkeit) \n",
    "if \"RFEU\" in all_data:\n",
    "    print(\"\\nBearbeite RFEU (Feuchtigkeit)...\")\n",
    "    rfeu_df = all_data[\"RFEU\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in rfeu_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_RFEU\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    rfeu_renamed = rfeu_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(rfeu_renamed)\n",
    "\n",
    "# WGES (Windgeschwindigkeit) \n",
    "if \"WGES\" in all_data:\n",
    "    print(\"\\nBearbeite WGES (Windgeschwindigkeit)...\")\n",
    "    wges_df = all_data[\"WGES\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in wges_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_WGES\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    wges_renamed = wges_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(wges_renamed)\n",
    "\n",
    "# WRI (Windrichtung) \n",
    "if \"WRI\" in all_data:\n",
    "    print(\"\\nBearbeite WRI (Windrichtung)...\")\n",
    "    wri_df = all_data[\"WRI\"]\n",
    "    \n",
    "    neue_namen = {}\n",
    "    for alte_spalte in wri_df.columns:\n",
    "        if \"-\" in alte_spalte:\n",
    "            teile = alte_spalte.split(\"-\")\n",
    "            station = teile[1]\n",
    "            neuer_name = station + \"_WRI\"\n",
    "            neue_namen[alte_spalte] = neuer_name\n",
    "            print(\"  \" + alte_spalte + \" -> \" + neuer_name)\n",
    "    \n",
    "    wri_renamed = wri_df.rename(columns=neue_namen)\n",
    "    alle_dataframes.append(wri_renamed)\n",
    "\n",
    "# SCHRITT 2: ALLES ZUSAMMENFUEGEN \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Schritt 2: Alle DataFrames zusammenfuegen...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nAnzahl DataFrames zum Kombinieren: \" + str(len(alle_dataframes)))\n",
    "\n",
    "# Alle DataFrames zusammenfuegen\n",
    "if len(alle_dataframes) > 0:\n",
    "    # Ersten DataFrame als Basis nehmen\n",
    "    df_combined = alle_dataframes[0]\n",
    "    print(\"Starte mit \" + str(df_combined.shape[1]) + \" Spalten\")\n",
    "    \n",
    "    # Alle anderen dazu fuegen\n",
    "    for i in range(1, len(alle_dataframes)):\n",
    "        df_combined = pd.concat([df_combined, alle_dataframes[i]], axis=1)\n",
    "        print(\"Nach DataFrame \" + str(i+1) + \": \" + str(df_combined.shape[1]) + \" Spalten\")\n",
    "else:\n",
    "    print(\"FEHLER: Keine DataFrames zum Kombinieren!\")\n",
    "    df_combined = pd.DataFrame()\n",
    "\n",
    "# ERGEBNIS \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KOMBINATION ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFinaler DataFrame:\")\n",
    "print(\"  Zeilen (Zeitpunkte): \" + str(df_combined.shape[0]))\n",
    "print(\"  Spalten (Messreihen): \" + str(df_combined.shape[1]))\n",
    "\n",
    "if len(df_combined) > 0:\n",
    "    print(\"  Zeitraum: \" + str(df_combined.index[0]) + \" bis \" + str(df_combined.index[-1]))\n",
    "    \n",
    "    # Beispiel-Spalten zeigen\n",
    "    print(\"\\nBeispiel-Spalten (ersten 10):\")\n",
    "    for i, spalte in enumerate(df_combined.columns[:10]):\n",
    "        print(\"    \" + str(i+1) + \". \" + spalte)\n",
    "    \n",
    "    if len(df_combined.columns) > 10:\n",
    "        print(\"    ... und \" + str(len(df_combined.columns) - 10) + \" weitere\")\n",
    "    \n",
    "    # Statistik\n",
    "    total_werte = df_combined.shape[0] * df_combined.shape[1] # Verdeutlichung der sehr großen Datenfragmentierung\n",
    "    fehlende_werte = df_combined.isna().sum().sum()\n",
    "    prozent_fehlend = (fehlende_werte / total_werte) * 100\n",
    "    \n",
    "    print(\"\\nFehlende Werte:\")\n",
    "    print(\"  Total: \" + str(fehlende_werte) + \" von \" + str(total_werte))\n",
    "    print(\"  Prozent: \" + str(round(prozent_fehlend, 1)) + \"%\")\n",
    "\n",
    "print(\"\\nVariable 'df_combined' enthaelt alle kombinierten Daten\") # brauchte ich, da ich ncoh in anderen Notebooks ausprobiert habe\n",
    "\n",
    "# ANMERKUNG:\n",
    "# Ja, ich weiss, dass das sehr viel Copy-Paste Code ist.\n",
    "# Aber so verstehe ich jeden einzelnen Schritt!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a183600b-b8d9-422f-8844-5d0fe685dd3b",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    ">## 3.5 Projekt-Zeitraum-Strategie\n",
    "\n",
    "\n",
    "> Teilt die Daten in Training-, Validierungs- und Testsets auf.\n",
    "> Die zeitliche Trennung verhindert Data Leakage und ermöglicht eine\n",
    "> realistische Evaluation der Vorhersagequalität.\n",
    "\n",
    ">>### 3.5.1 COVID-19 SONDEREFFEKT UND ZEITRAUM-STRATEGIE\n",
    "\n",
    ">>Die COVID-19 Pandemie führte zu beispiellosen Veränderungen in der Luftqualität:\n",
    "\n",
    ">>***Lockdown-Effekte (März 2020 - Mai 2021)- Corona:***\n",
    ">>- **Verkehrsreduktion**: -60% während hartem Lockdown\n",
    ">>- **PM10-Rückgang**: -30 bis -40% in urbanen Gebieten  \n",
    ">>- **NO2-Reduktion**: -50% an Verkehrsstationen\n",
    "\n",
    "\n",
    "\n",
    ">>### 3.5.2 Training: 2015-2022 (inkl. COVID)\n",
    ">>- 8 Jahre Daten für Robustheit\n",
    ">>- Modell lernt sowohl normale als auch anomale Muster\n",
    "\n",
    ">>### 3.5.3 Validation: 2023 (Post-COVID)\n",
    ">>- Test der Generalisierung nach Pandemie\n",
    "\n",
    ">>### 3.5.4 Test: 2024-2025 (Aktuelle Bedingungen)\n",
    ">>- Realistische Performance-Evaluation\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14442b1-5d09-4d70-89d6-3a71b7dac6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEILE DATEN IN TRAINING, VALIDATION UND TEST\n",
      "============================================================\n",
      "\n",
      "Zeitraeume:\n",
      "  Training:   2015-2022 (8 Jahre)\n",
      "  Validation: 2023 (1 Jahr)\n",
      "  Test:       2024-2025 (1.5 Jahre)\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Training-Daten...\n",
      "  Training-Daten: 70128 Zeitpunkte\n",
      "  Von: 2015-01-01 00:00:00\n",
      "  Bis: 2022-12-31 23:00:00\n",
      "\n",
      "Zaehle COVID-Periode im Training...\n",
      "  COVID-Zeitpunkte: 10968\n",
      "  Das sind 15.6% vom Training\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Validation-Daten...\n",
      "  Validation-Daten: 8760 Zeitpunkte\n",
      "  Von: 2023-01-01 00:00:00\n",
      "  Bis: 2023-12-31 23:00:00\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Test-Daten...\n",
      "  Test-Daten: 8713 Zeitpunkte\n",
      "  Von: 2024-01-01 00:00:00\n",
      "  Bis: 2025-07-31 00:00:00\n",
      "\n",
      "============================================================\n",
      "AUFTEILUNG ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "Gesamte Daten: 87601 Zeitpunkte\n",
      "\n",
      "Aufteilung:\n",
      "  Training:   70128 (80.1%)\n",
      "  Validation: 8760 (10.0%)\n",
      "  Test:       8713 (9.9%)\n",
      "\n",
      " Alle Daten wurden aufgeteilt!\n",
      "\n",
      "----------------------------------------\n",
      "Stichprobe der Daten:\n",
      "\n",
      "Training - Erste 3 Spalten:\n",
      "  Spalten: ['BUCH_PM10', 'DUB2_PM10', 'DUBR_PM10']\n",
      "  Anzahl Zeilen: 70128\n",
      "\n",
      "Validation - Erste 3 Spalten:\n",
      "  Spalten: ['BUCH_PM10', 'DUB2_PM10', 'DUBR_PM10']\n",
      "  Anzahl Zeilen: 8760\n",
      "\n",
      "Test - Erste 3 Spalten:\n",
      "  Spalten: ['BUCH_PM10', 'DUB2_PM10', 'DUBR_PM10']\n",
      "  Anzahl Zeilen: 8713\n",
      "\n",
      "============================================================\n",
      "Alle Daten:\n",
      "============================================================\n",
      "Variablen:\n",
      "  df_train = Training-Daten\n",
      "  df_val   = Validation-Daten\n",
      "  df_test  = Test-Daten\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 3.6 Trainings- /Validierungs- /Test-Split  - Daten in Training, Validation und Test aufteilen\n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEILE DATEN IN TRAINING, VALIDATION UND TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# df_combined kommt aus Zelle 4\n",
    "\n",
    "# ZEITRAEUME FESTLEGEN \n",
    "print(\"\\nZeitraeume:\")\n",
    "print(\"  Training:   2015-2022 (8 Jahre)\")\n",
    "print(\"  Validation: 2023 (1 Jahr)\")\n",
    "print(\"  Test:       2024-2025 (1.5 Jahre)\")\n",
    "\n",
    "# TRAINING DATEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Training-Daten...\")\n",
    "\n",
    "# Leere Liste fuer Training-Zeilen\n",
    "training_zeilen = []\n",
    "\n",
    "# Durch alle Zeiten gehen und Jahre pruefen\n",
    "for datum in df_combined.index:\n",
    "    jahr = datum.year  # Das Jahr aus dem Datum holen\n",
    "    \n",
    "    # Ist es zwischen 2015 und 2022?\n",
    "    if jahr >= 2015 and jahr <= 2022:\n",
    "        training_zeilen.append(True)\n",
    "    else:\n",
    "        training_zeilen.append(False)\n",
    "\n",
    "# Training DataFrame erstellen\n",
    "df_train = df_combined[training_zeilen]\n",
    "\n",
    "print(\"  Training-Daten: \" + str(len(df_train)) + \" Zeitpunkte\")\n",
    "if len(df_train) > 0:\n",
    "    print(\"  Von: \" + str(df_train.index[0]))\n",
    "    print(\"  Bis: \" + str(df_train.index[-1]))\n",
    "\n",
    "# COVID PERIODE ZAEHLEN (nur Info)!!!\n",
    "print(\"\\nZaehle COVID-Periode im Training...\")\n",
    "\n",
    "covid_zaehler = 0\n",
    "for datum in df_train.index:\n",
    "    jahr = datum.year\n",
    "    monat = datum.month\n",
    "    \n",
    "    # COVID war von Maerz 2020 bis Mai 2021\n",
    "    # 2020: Monat >= 3\n",
    "    # 2021: Monat <= 5\n",
    "    if jahr == 2020 and monat >= 3:\n",
    "        covid_zaehler = covid_zaehler + 1\n",
    "    elif jahr == 2021 and monat <= 5:\n",
    "        covid_zaehler = covid_zaehler + 1\n",
    "\n",
    "if len(df_train) > 0:\n",
    "    covid_prozent = (covid_zaehler / len(df_train)) * 100\n",
    "    print(\"  COVID-Zeitpunkte: \" + str(covid_zaehler))\n",
    "    print(\"  Das sind \" + str(round(covid_prozent, 1)) + \"% vom Training\")\n",
    "\n",
    "# VALIDATION DATEN\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Validation-Daten...\")\n",
    "\n",
    "validation_zeilen = []\n",
    "\n",
    "for datum in df_combined.index:\n",
    "    jahr = datum.year\n",
    "    \n",
    "    # Ist es 2023?\n",
    "    if jahr == 2023:\n",
    "        validation_zeilen.append(True)\n",
    "    else:\n",
    "        validation_zeilen.append(False)\n",
    "\n",
    "# Validation DataFrame erstellen\n",
    "df_val = df_combined[validation_zeilen]\n",
    "\n",
    "print(\"  Validation-Daten: \" + str(len(df_val)) + \" Zeitpunkte\")\n",
    "if len(df_val) > 0:\n",
    "    print(\"  Von: \" + str(df_val.index[0]))\n",
    "    print(\"  Bis: \" + str(df_val.index[-1]))\n",
    "else:\n",
    "    print(\"  WARNUNG: Keine Validation-Daten gefunden!\")\n",
    "\n",
    "# TEST DATEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Test-Daten...\")\n",
    "\n",
    "test_zeilen = []\n",
    "\n",
    "for datum in df_combined.index:\n",
    "    jahr = datum.year\n",
    "    monat = datum.month\n",
    "    \n",
    "    # 2024: ganzes Jahr\n",
    "    # 2025: nur bis Juli (Monat <= 7)\n",
    "    if jahr == 2024:\n",
    "        test_zeilen.append(True)\n",
    "    elif jahr == 2025 and monat <= 7:\n",
    "        test_zeilen.append(True)\n",
    "    else:\n",
    "        test_zeilen.append(False)\n",
    "\n",
    "# Test DataFrame erstellen\n",
    "df_test = df_combined[test_zeilen]\n",
    "\n",
    "print(\"  Test-Daten: \" + str(len(df_test)) + \" Zeitpunkte\")\n",
    "if len(df_test) > 0:\n",
    "    print(\"  Von: \" + str(df_test.index[0]))\n",
    "    print(\"  Bis: \" + str(df_test.index[-1]))\n",
    "else:\n",
    "    print(\"  WARNUNG: Keine Test-Daten gefunden!\")\n",
    "\n",
    "# ZUSAMMENFASSUNG \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AUFTEILUNG ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gesamt = len(df_combined)\n",
    "train_anzahl = len(df_train)\n",
    "val_anzahl = len(df_val)\n",
    "test_anzahl = len(df_test)\n",
    "\n",
    "print(\"\\nGesamte Daten: \" + str(gesamt) + \" Zeitpunkte\")\n",
    "print(\"\\nAufteilung:\")\n",
    "\n",
    "if gesamt > 0:\n",
    "    print(\"  Training:   \" + str(train_anzahl) + \" (\" + str(round(train_anzahl/gesamt*100, 1)) + \"%)\")\n",
    "    print(\"  Validation: \" + str(val_anzahl) + \" (\" + str(round(val_anzahl/gesamt*100, 1)) + \"%)\")\n",
    "    print(\"  Test:       \" + str(test_anzahl) + \" (\" + str(round(test_anzahl/gesamt*100, 1)) + \"%)\")\n",
    "    \n",
    "    # Pruefen ob alles passt\n",
    "    summe = train_anzahl + val_anzahl + test_anzahl\n",
    "    if summe == gesamt:\n",
    "        print(\"\\n Alle Daten wurden aufgeteilt!\")\n",
    "    else:\n",
    "        differenz = gesamt - summe\n",
    "        print(\"\\nINFO: \" + str(differenz) + \" Zeitpunkte wurden keiner Gruppe zugeordnet\")\n",
    "        print(\"      (Wahrscheinlich Daten vor 2015 oder nach Juli 2025)\")\n",
    "\n",
    "# KURZE INFO AUSGABE\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Stichprobe der Daten:\")\n",
    "\n",
    "print(\"\\nTraining - Erste 3 Spalten:\")\n",
    "if len(df_train) > 0 and len(df_train.columns) > 0:\n",
    "    print(\"  Spalten: \" + str(list(df_train.columns[:3])))\n",
    "    print(\"  Anzahl Zeilen: \" + str(len(df_train)))\n",
    "\n",
    "print(\"\\nValidation - Erste 3 Spalten:\")\n",
    "if len(df_val) > 0 and len(df_val.columns) > 0:\n",
    "    print(\"  Spalten: \" + str(list(df_val.columns[:3])))\n",
    "    print(\"  Anzahl Zeilen: \" + str(len(df_val)))\n",
    "\n",
    "print(\"\\nTest - Erste 3 Spalten:\")\n",
    "if len(df_test) > 0 and len(df_test.columns) > 0:\n",
    "    print(\"  Spalten: \" + str(list(df_test.columns[:3])))\n",
    "    print(\"  Anzahl Zeilen: \" + str(len(df_test)))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Alle Daten:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Variablen:\")\n",
    "print(\"  df_train = Training-Daten\") # ich drucke das an, weil ich ständig die Dateien gesucht habe\n",
    "print(\"  df_val   = Validation-Daten\")\n",
    "print(\"  df_test  = Test-Daten\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986c80f-f100-45be-b654-176f024a5755",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# 4. Feature Engineering\n",
    ">## 4.1 Iterative Modelloptimierung: Von schlechten Ergebnissen zur Lösung\n",
    "\n",
    ">>#### 4.1.1 Problemstellung\n",
    "\n",
    ">>Der vorliegende Testablauf ist das Gesamtergebnis aus x- Testläufen gepaart mit ziemlich viel Frustration.\n",
    "Im ersten Durchlauf des Notebooks wurde ohne Lags gearbeitet. Ich hatte als Anfänger alle Daten von PM10 (feinstaub) gelöscht, ausser PM10_mean. Das  Ergebnis war sehr bescheiden: R² = 0,130 (jetziger Test 4). Ich suchte und googelte nach Gründe kam auf die Lags (Erklärung im Bereich: 4.2.3).Mein zweiter Durchlauf war dann nach der Änderung des \"Featrure-Engineerings\" mit allen Lags. Das Ergebnis war sehr gut: R² = 0,872. - was zu gut ist für eine echte Vorhersage (Die Referenzwerte liegen bei R² = 0,5 - 0,7). Die Vermutung: Das Modell nutzt hauptsächlich die Autokorrelation aus (PM10 heute ≈ PM10 gestern +- Korrekturfaktor) statt echte meteorologische Zusammenhänge zu lernen. Das hatte ich bereits in einigen Test-Notebooks festgestellt, als ich im Bereich AQI (Air Quality Index) gearbeitet habe und nur mit PM10 (Feinstaub) und NO (Stickstoffmonoxid) gearbeitet habe. Ergebnis in diesem Test: R² = 0,995 - leider die totale Autokorrelation. Dieser Ansatz wurde dann verworfen.\n",
    "Bedingt durch die Erfahrungen, wollte ich feststellen, welche Faktoren den größten Einfluss auf das Ergebnis haben, um Maßnahmen zu ergreifen, bzw. eine scheinbar vorliegende Autokorrelation \"zu brechen\".\n",
    "\n",
    ">>#### 4.1.2 Ziel der Tests\n",
    "\n",
    ">>Systematisch untersuchen, wie stark die Performance von Lag-Features abhängt und ob das Modell auch ohne \"Abschreiben von Gestern + Korrekturfaktor\" funktioniert.\n",
    "\n",
    ">>#### 4.1.3 Test-Übersicht\n",
    "\n",
    ">>| Test | Beschreibung | Behaltene Features | Entfernte Features | Erwartete Performance |\n",
    ">>|------|--------------|-------------------|-------------------|----------------------|\n",
    ">>| **Test 0** | BASELINE | Alle Lag-Features | Keine | R² ≈ 0.87, MAE ≈ 1.3 |\n",
    ">>| **Test 1** | Nur 24h-Lag | PM10_lag_24h | lag_6h, lag_168h, rolling_24h, rolling_std | R² ≈ 0.65, MAE ≈ 3-4 |\n",
    ">>| **Test 2** | Nur Rolling Mean | PM10_rolling_24h | lag_6h, lag_24h, lag_168h, rolling_std | R² ≈ 0.75, MAE ≈ 2.5 |\n",
    ">>| **Test 3** | Nur Wochen-Lag | PM10_lag_168h | lag_6h, lag_24h, rolling_24h, rolling_std | R² ≈ 0.80, MAE ≈ 1.8 |\n",
    ">>| **Test 4** | Kombination | lag_24h, lag_168h, rolling_24h | lag_6h, rolling_std | R² ≈ 0.82, MAE ≈ 1.5 |\n",
    ">>| **Test 5** | Ohne Wochen-Lag | lag_24h, rolling_24h | lag_6h, lag_168h, rolling_std | R² ≈ 0.78, MAE ≈ 2.0 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>#### 4.1.4 Durchführung\n",
    "\n",
    ">>>##### 4.1.4.1 Schritt-für-Schritt Anleitung:\n",
    "\n",
    ">>>1. **Test auswählen**\n",
    ">>>   - In Zelle 6: `ACTIVE_TEST = \"Test_0\"` ändern zu gewünschtem Test\n",
    ">>>   - Nur EIN Test aktiv!\n",
    "\n",
    ">>>2. **Notebook durchlaufen**\n",
    ">>>   - Kernel neu starten: `Kernel → Restart`\n",
    ">>>   - Alle Zellen ausführen: `Cell → Run All`\n",
    ">>>   - Warten bis Zelle 14 fertig\n",
    "\n",
    ">>>3. **Ergebnisse dokumentieren**\n",
    " >>>  - Zelle 15 ausführen\n",
    ">>>   - Ergebnisse werden automatisch in JSON gespeichert\n",
    ">>>   - Vergleichstabelle wird angezeigt\n",
    "\n",
    ">>>4. **Nächsten Test**\n",
    ">>>   - Wieder bei Schritt 1 beginnen\n",
    ">>>   - Anderen Test in Zelle 6 aktivieren\n",
    ">>>   - Zelle 15 auf aktuellen Test setzen: `current_test = \"Test_0\"`\n",
    "\n",
    ">>#### 4.1.5 Interpretation der Ergebnisse\n",
    "\n",
    ">>>##### 4.1.5.1 Gute Performance ohne Lag-Features:\n",
    ">>>- **R² > 0.5 ohne lag_24h**: Modell hat echte Zusammenhänge gelernt\n",
    ">>>- **MAE < 5 µg/m³**: Akzeptable Vorhersagegenauigkeit\n",
    "\n",
    ">>>##### 4.1.5.2 Schlechte Performance ohne Lag-Features:\n",
    ">>>- **R² < 0.3**: Modell war auf Autokorrelation angewiesen\n",
    ">>>- **MAE > 10 µg/m³**: Nicht praxistauglich\n",
    "\n",
    ">>>##### 4.1.5.3 Overfitting-Indikator:\n",
    ">>>- **R²(Train) - R²(Val) > 0.15**: Starkes Overfitting\n",
    ">>>- **R²(Train) - R²(Val) < 0.10**: Akzeptables Overfitting\n",
    "\n",
    ">>#### 4.1.6 Physikalische Hintergründe\n",
    "\n",
    ">>>##### 4.1.6.1 Warum PM10 autokorreliert ist:\n",
    "\n",
    ">>>1. **Grenzschichthöhe**: \n",
    ">>>   - Nachts: 50-300m → hohe Konzentration\n",
    ">>>   - Tags: bis 1200m → niedrige Konzentration\n",
    ">>>   - Zyklus wiederholt sich täglich\n",
    "\n",
    ">>>2. **Depositionsgeschwindigkeit**:\n",
    ">>>   - PM10 sinkt mit nur 3.19 cm/s\n",
    ">>>   - Verweildauer: 5-8 Tage in der Atmosphäre\n",
    "\n",
    ">>>3. **Inversionslagen**:\n",
    ">>>   - Können 3-7 Tage anhalten\n",
    ">>>   - Besonders in Tälern und im Winter\n",
    "\n",
    ">>#### 4.1.7 Erwartete Erkenntnisse\n",
    "\n",
    ">>- **Test 1** zeigt, ob 24h-Lag dominiert (vermutlich ja)\n",
    ">>- **Test 4** zeigt Baseline ohne jegliche Autokorrelation\n",
    ">>- **Test 5** zeigt Maximum mit nur Meteorologie\n",
    ">>- **Test 6** könnte guter Kompromiss sein (Wochenmuster ohne Tages-Kopie)\n",
    "\n",
    ">>### 4.1.8 Zielkriterien für finales Modell\n",
    "\n",
    ">>**Akzeptabel für operationellen Einsatz:**\n",
    ">>- R² > 0.5 für Validation\n",
    ">>- MAE < 7 µg/m³ (bei Mittelwert ~25 µg/m³)\n",
    ">>- Keine Nutzung von PM10_lag_24h\n",
    ">>- Overfitting < 15%\n",
    "\n",
    "**Wichtig:** Nach diesem Plan folgt Zelle 6 mit allen Test-Varianten!\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bd252-7b11-4800-be5a-1f85f3b76ea7",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## 4.2 Feature Engineering Anpassungen\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6919698e-536a-4e2b-bccc-3dc6f35eaef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING\n",
      "============================================================\n",
      "✓ DataFrames gefunden:\n",
      "  df_train: (70128, 96)\n",
      "  df_val: (8760, 96)\n",
      "  df_test: (8713, 96)\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Features für Training...\n",
      "  PM10-Spalten gefunden: 13\n",
      "  ✓ PM10_mean: 69949 gültige Werte\n",
      "  ✓ NO2_mean erstellt\n",
      "  ✓ NO_mean erstellt\n",
      "  ✓ O3_mean erstellt\n",
      "  ✓ SO2_mean erstellt\n",
      "  ✓ temp_mean erstellt\n",
      "  ✓ humidity_mean erstellt\n",
      "  ✓ wind_speed_mean erstellt\n",
      "  ✓ wind_dir_mean erstellt\n",
      "  ✓ Zeit-Features erstellt\n",
      "  ✓ Lag-Features erstellt\n",
      "\n",
      "Training: 18 Features erstellt\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Features für Validation...\n",
      "Validation: 18 Features erstellt\n",
      "\n",
      "----------------------------------------\n",
      "Erstelle Features für Test...\n",
      "Test: 18 Features erstellt\n",
      "\n",
      "============================================================\n",
      "ZIELVARIABLE EXTRAHIEREN\n",
      "============================================================\n",
      "✓ Zielvariable erstellt:\n",
      "  y_train: 70128 Werte (69949 gültig)\n",
      "  y_val: 8760 Werte (8573 gültig)\n",
      "  y_test: 8713 Werte (8489 gültig)\n",
      "\n",
      "----------------------------------------\n",
      "Entferne PM10 aus Features (Data Leakage vermeiden)...\n",
      "\n",
      "Aktiver Test: Entferne 4 Features\n",
      "Features zu entfernen: ['PM10_mean', 'PM10_max', 'PM10_lag_24h', 'PM10_rolling_24h']\n",
      "  ✗ Entfernt: PM10_mean\n",
      "  ✗ Entfernt: PM10_max\n",
      "  ✗ Entfernt: PM10_lag_24h\n",
      "  ✗ Entfernt: PM10_rolling_24h\n",
      "\n",
      "Lag-Features Status:\n",
      "  ✓ PM10_lag_168h - wird behalten\n",
      "\n",
      " TEST 1: Ohne PM10_lag_24h (stärkstes Feature)\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "Finale Feature-Anzahl:\n",
      "  X_train: (70128, 14)\n",
      "  X_val: (8760, 14)\n",
      "  X_test: (8713, 14)\n",
      "\n",
      "Zielvariable:\n",
      "  y_train: (70128,)\n",
      "  y_val: (8760,)\n",
      "  y_test: (8713,)\n",
      "\n",
      "Alle Features (14):\n",
      "   1. NO2_mean\n",
      "   2. NO_mean\n",
      "   3. O3_mean\n",
      "   4. SO2_mean\n",
      "   5. temp_mean\n",
      "   6. humidity_mean\n",
      "   7. wind_speed_mean\n",
      "   8. wind_dir_mean\n",
      "   9. hour\n",
      "  10. dayofweek\n",
      "  11. month\n",
      "  12. years_since_base\n",
      "  13. is_weekend\n",
      "  14. PM10_lag_168h [LAG]\n",
      "\n",
      "============================================================\n",
      "TEST-KONFIGURATION:\n",
      "============================================================\n",
      "Um andere Tests zu aktivieren:\n",
      "1. Gehen Sie zu Zeile ~290 in dieser Zelle\n",
      "2. Kommentieren Sie die aktive pm10_direct Zeile aus\n",
      "3. Entkommentieren Sie die gewünschte Test-Zeile\n",
      "4. Kernel neu starten und alles durchlaufen\n",
      "============================================================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 4.2.1 Basis-Features erstellen - Feature Engineering\n",
    "# ================================================================================\n",
    "\n",
    "# Erstellt alle notwendigen Features für PM10-Vorhersage\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PRÜFUNG DataFrames\n",
    "\n",
    "\n",
    "if 'df_train' not in globals() or 'df_val' not in globals() or 'df_test' not in globals():\n",
    "    print(\"❌ FEHLER: DataFrames nicht gefunden!\")\n",
    "    print(\"   Bitte erst Zelle 5 (Datenaufteilung) ausführen!\")\n",
    "    raise NameError(\"DataFrames nicht definiert\")\n",
    "\n",
    "print(f\"✓ DataFrames gefunden:\")\n",
    "print(f\"  df_train: {df_train.shape}\")\n",
    "print(f\"  df_val: {df_val.shape}\")\n",
    "print(f\"  df_test: {df_test.shape}\")\n",
    "\n",
    "# TRAINING FEATURES\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Features für Training...\")\n",
    "\n",
    "X_train = pd.DataFrame(index=df_train.index)\n",
    "\n",
    "# PM10 - Zielvariable\n",
    "pm10_cols = [col for col in df_train.columns if 'PM10' in col]\n",
    "print(f\"  PM10-Spalten gefunden: {len(pm10_cols)}\")\n",
    "if pm10_cols:\n",
    "    X_train['PM10_mean'] = df_train[pm10_cols].mean(axis=1)\n",
    "    X_train['PM10_max'] = df_train[pm10_cols].max(axis=1)\n",
    "    print(f\"  ✓ PM10_mean: {X_train['PM10_mean'].notna().sum()} gültige Werte\")\n",
    "\n",
    "# NO2\n",
    "no2_cols = [col for col in df_train.columns if 'NO2' in col]\n",
    "if no2_cols:\n",
    "    X_train['NO2_mean'] = df_train[no2_cols].mean(axis=1)\n",
    "    print(f\"  ✓ NO2_mean erstellt\")\n",
    "\n",
    "# NO (ohne NO2)\n",
    "no_cols = [col for col in df_train.columns if '_NO' in col]  # Mit Unterstrich\n",
    "if no_cols:\n",
    "    X_train['NO_mean'] = df_train[no_cols].mean(axis=1)\n",
    "    print(f\"  ✓ NO_mean erstellt\")\n",
    "\n",
    "# O3\n",
    "o3_cols = [col for col in df_train.columns if 'O3' in col]\n",
    "if o3_cols:\n",
    "    X_train['O3_mean'] = df_train[o3_cols].mean(axis=1)\n",
    "    print(f\"  ✓ O3_mean erstellt\")\n",
    "\n",
    "# SO2\n",
    "so2_cols = [col for col in df_train.columns if 'SO2' in col]\n",
    "if so2_cols:\n",
    "    X_train['SO2_mean'] = df_train[so2_cols].mean(axis=1)\n",
    "    print(f\"  ✓ SO2_mean erstellt\")\n",
    "\n",
    "# Meteorologie\n",
    "temp_cols = [col for col in df_train.columns if 'LTEM' in col]\n",
    "if temp_cols:\n",
    "    X_train['temp_mean'] = df_train[temp_cols].mean(axis=1)\n",
    "    print(f\"  ✓ temp_mean erstellt\")\n",
    "\n",
    "humidity_cols = [col for col in df_train.columns if 'RFEU' in col]\n",
    "if humidity_cols:\n",
    "    X_train['humidity_mean'] = df_train[humidity_cols].mean(axis=1)\n",
    "    print(f\"  ✓ humidity_mean erstellt\")\n",
    "\n",
    "wind_speed_cols = [col for col in df_train.columns if 'WGES' in col]\n",
    "if wind_speed_cols:\n",
    "    X_train['wind_speed_mean'] = df_train[wind_speed_cols].mean(axis=1)\n",
    "    print(f\"  ✓ wind_speed_mean erstellt\")\n",
    "\n",
    "wind_dir_cols = [col for col in df_train.columns if 'WRI' in col]\n",
    "if wind_dir_cols:\n",
    "    X_train['wind_dir_mean'] = df_train[wind_dir_cols].mean(axis=1)\n",
    "    print(f\"  ✓ wind_dir_mean erstellt\")\n",
    "\n",
    "# Zeit-Features\n",
    "X_train['hour'] = X_train.index.hour\n",
    "X_train['dayofweek'] = X_train.index.dayofweek\n",
    "X_train['month'] = X_train.index.month\n",
    "X_train['years_since_base'] = (X_train.index.year - 2015) / 10.0\n",
    "X_train['is_weekend'] = (X_train.index.dayofweek >= 5).astype(int)\n",
    "print(\"  ✓ Zeit-Features erstellt\")\n",
    "\n",
    "# Lag-Features (nur wenn PM10_mean existiert)\n",
    "if 'PM10_mean' in X_train.columns:\n",
    "    X_train['PM10_lag_24h'] = X_train['PM10_mean'].shift(24)\n",
    "    X_train['PM10_lag_168h'] = X_train['PM10_mean'].shift(168)\n",
    "    X_train['PM10_rolling_24h'] = X_train['PM10_mean'].rolling(24, min_periods=12).mean()\n",
    "    print(\"  ✓ Lag-Features erstellt\")\n",
    "\n",
    "print(f\"\\nTraining: {X_train.shape[1]} Features erstellt\")\n",
    "\n",
    "\n",
    "# VALIDATION FEATURES (identisch zu Training)\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Features für Validation...\")\n",
    "\n",
    "X_val = pd.DataFrame(index=df_val.index)\n",
    "\n",
    "# PM10\n",
    "pm10_cols = [col for col in df_val.columns if 'PM10' in col]\n",
    "if pm10_cols:\n",
    "    X_val['PM10_mean'] = df_val[pm10_cols].mean(axis=1)\n",
    "    X_val['PM10_max'] = df_val[pm10_cols].max(axis=1)\n",
    "\n",
    "# Schadstoffe\n",
    "no2_cols = [col for col in df_val.columns if 'NO2' in col]\n",
    "if no2_cols:\n",
    "    X_val['NO2_mean'] = df_val[no2_cols].mean(axis=1)\n",
    "\n",
    "no_cols = [col for col in df_val.columns if '_NO' in col]\n",
    "if no_cols:\n",
    "    X_val['NO_mean'] = df_val[no_cols].mean(axis=1)\n",
    "\n",
    "o3_cols = [col for col in df_val.columns if 'O3' in col]\n",
    "if o3_cols:\n",
    "    X_val['O3_mean'] = df_val[o3_cols].mean(axis=1)\n",
    "\n",
    "so2_cols = [col for col in df_val.columns if 'SO2' in col]\n",
    "if so2_cols:\n",
    "    X_val['SO2_mean'] = df_val[so2_cols].mean(axis=1)\n",
    "\n",
    "# Meteorologie\n",
    "temp_cols = [col for col in df_val.columns if 'LTEM' in col]\n",
    "if temp_cols:\n",
    "    X_val['temp_mean'] = df_val[temp_cols].mean(axis=1)\n",
    "\n",
    "humidity_cols = [col for col in df_val.columns if 'RFEU' in col]\n",
    "if humidity_cols:\n",
    "    X_val['humidity_mean'] = df_val[humidity_cols].mean(axis=1)\n",
    "\n",
    "wind_speed_cols = [col for col in df_val.columns if 'WGES' in col]\n",
    "if wind_speed_cols:\n",
    "    X_val['wind_speed_mean'] = df_val[wind_speed_cols].mean(axis=1)\n",
    "\n",
    "wind_dir_cols = [col for col in df_val.columns if 'WRI' in col]\n",
    "if wind_dir_cols:\n",
    "    X_val['wind_dir_mean'] = df_val[wind_dir_cols].mean(axis=1)\n",
    "\n",
    "# Zeit\n",
    "X_val['hour'] = X_val.index.hour\n",
    "X_val['dayofweek'] = X_val.index.dayofweek\n",
    "X_val['month'] = X_val.index.month\n",
    "X_val['years_since_base'] = (X_val.index.year - 2015) / 10.0\n",
    "X_val['is_weekend'] = (X_val.index.dayofweek >= 5).astype(int)\n",
    "\n",
    "# Lag-Features\n",
    "if 'PM10_mean' in X_val.columns:\n",
    "    X_val['PM10_lag_24h'] = X_val['PM10_mean'].shift(24)\n",
    "    X_val['PM10_lag_168h'] = X_val['PM10_mean'].shift(168)\n",
    "    X_val['PM10_rolling_24h'] = X_val['PM10_mean'].rolling(24, min_periods=12).mean()\n",
    "\n",
    "print(f\"Validation: {X_val.shape[1]} Features erstellt\")\n",
    "\n",
    "# TEST FEATURES (identisch zu Training)\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Erstelle Features für Test...\")\n",
    "\n",
    "X_test = pd.DataFrame(index=df_test.index)\n",
    "\n",
    "# PM10\n",
    "pm10_cols = [col for col in df_test.columns if 'PM10' in col]\n",
    "if pm10_cols:\n",
    "    X_test['PM10_mean'] = df_test[pm10_cols].mean(axis=1)\n",
    "    X_test['PM10_max'] = df_test[pm10_cols].max(axis=1)\n",
    "\n",
    "# Schadstoffe\n",
    "no2_cols = [col for col in df_test.columns if 'NO2' in col]\n",
    "if no2_cols:\n",
    "    X_test['NO2_mean'] = df_test[no2_cols].mean(axis=1)\n",
    "\n",
    "no_cols = [col for col in df_test.columns if '_NO' in col]\n",
    "if no_cols:\n",
    "    X_test['NO_mean'] = df_test[no_cols].mean(axis=1)\n",
    "\n",
    "o3_cols = [col for col in df_test.columns if 'O3' in col]\n",
    "if o3_cols:\n",
    "    X_test['O3_mean'] = df_test[o3_cols].mean(axis=1)\n",
    "\n",
    "so2_cols = [col for col in df_test.columns if 'SO2' in col]\n",
    "if so2_cols:\n",
    "    X_test['SO2_mean'] = df_test[so2_cols].mean(axis=1)\n",
    "\n",
    "# Meteorologie\n",
    "temp_cols = [col for col in df_test.columns if 'LTEM' in col]\n",
    "if temp_cols:\n",
    "    X_test['temp_mean'] = df_test[temp_cols].mean(axis=1)\n",
    "\n",
    "humidity_cols = [col for col in df_test.columns if 'RFEU' in col]\n",
    "if humidity_cols:\n",
    "    X_test['humidity_mean'] = df_test[humidity_cols].mean(axis=1)\n",
    "\n",
    "wind_speed_cols = [col for col in df_test.columns if 'WGES' in col]\n",
    "if wind_speed_cols:\n",
    "    X_test['wind_speed_mean'] = df_test[wind_speed_cols].mean(axis=1)\n",
    "\n",
    "wind_dir_cols = [col for col in df_test.columns if 'WRI' in col]\n",
    "if wind_dir_cols:\n",
    "    X_test['wind_dir_mean'] = df_test[wind_dir_cols].mean(axis=1)\n",
    "\n",
    "# Zeit\n",
    "X_test['hour'] = X_test.index.hour\n",
    "X_test['dayofweek'] = X_test.index.dayofweek\n",
    "X_test['month'] = X_test.index.month\n",
    "X_test['years_since_base'] = (X_test.index.year - 2015) / 10.0\n",
    "X_test['is_weekend'] = (X_test.index.dayofweek >= 5).astype(int)\n",
    "\n",
    "# Lag-Features\n",
    "if 'PM10_mean' in X_test.columns:\n",
    "    X_test['PM10_lag_24h'] = X_test['PM10_mean'].shift(24)\n",
    "    X_test['PM10_lag_168h'] = X_test['PM10_mean'].shift(168)\n",
    "    X_test['PM10_rolling_24h'] = X_test['PM10_mean'].rolling(24, min_periods=12).mean()\n",
    "\n",
    "print(f\"Test: {X_test.shape[1]} Features erstellt\")\n",
    "\n",
    "# ZIELVARIABLE EXTRAHIEREN\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ZIELVARIABLE EXTRAHIEREN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'PM10_mean' in X_train.columns:\n",
    "    # Kopiere Zielvariable\n",
    "    y_train = X_train['PM10_mean'].copy()\n",
    "    y_val = X_val['PM10_mean'].copy()\n",
    "    y_test = X_test['PM10_mean'].copy()\n",
    "    \n",
    "    print(f\"✓ Zielvariable erstellt:\")\n",
    "    print(f\"  y_train: {len(y_train)} Werte ({y_train.notna().sum()} gültig)\")\n",
    "    print(f\"  y_val: {len(y_val)} Werte ({y_val.notna().sum()} gültig)\")\n",
    "    print(f\"  y_test: {len(y_test)} Werte ({y_test.notna().sum()} gültig)\")\n",
    "    \n",
    "    # JETZT PM10 aus Features entfernen (nach Extraktion!)\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Entferne PM10 aus Features (Data Leakage vermeiden)...\")\n",
    "    \n",
    "    # ================================================================================\n",
    "    # TEST-VARIANTEN - Immer nur EINE Zeile aktiv!\n",
    "    # ================================================================================\n",
    "    # Kommentieren Sie alle anderen aus und lassen nur den gewünschten Test aktiv\n",
    "    \n",
    "    # pm10_direct = ['PM10_mean', 'PM10_max']  # Test 0: BASELINE (alle Lags behalten)\n",
    "    # pm10_direct = ['PM10_mean', 'PM10_max', 'PM10_lag_24h']  # Test 1: Ohne lag_24h (wichtigstes Feature)\n",
    "    # pm10_direct = ['PM10_mean', 'PM10_max', 'PM10_rolling_24h']  # Test 2: Ohne rolling_24h\n",
    "    # pm10_direct = ['PM10_mean', 'PM10_max', 'PM10_lag_168h']  # Test 3: Ohne lag_168h (Wochenmuster)\n",
    "    # pm10_direct = ['PM10_mean', 'PM10_max', 'PM10_lag_24h', 'PM10_lag_168h', 'PM10_rolling_24h']  # Test 4: Ohne ALLE Lags\n",
    "    pm10_direct = ['PM10_mean', 'PM10_max', 'PM10_lag_24h', 'PM10_rolling_24h']  # Test 5: NUR lag_168h behalten\n",
    "    \n",
    "    print(f\"\\nAktiver Test: Entferne {len(pm10_direct)} Features\")\n",
    "    print(f\"Features zu entfernen: {pm10_direct}\")\n",
    "    \n",
    "    for feature in pm10_direct:\n",
    "        if feature in X_train.columns:\n",
    "            X_train.drop(feature, axis=1, inplace=True)\n",
    "            X_val.drop(feature, axis=1, inplace=True)\n",
    "            X_test.drop(feature, axis=1, inplace=True)\n",
    "            print(f\"  ✗ Entfernt: {feature}\")\n",
    "    \n",
    "    # Lag-Features behalten (für Baseline)\n",
    "    lag_features = ['PM10_lag_24h', 'PM10_lag_168h', 'PM10_rolling_24h']\n",
    "    print(\"\\nLag-Features Status:\")\n",
    "    for feature in lag_features:\n",
    "        if feature in X_train.columns:\n",
    "            if feature in pm10_direct:\n",
    "                print(f\"  ✗ {feature} - WIRD ENTFERNT (Test)\")\n",
    "            else:\n",
    "                print(f\"  ✓ {feature} - wird behalten\")\n",
    "    \n",
    "    # Test-Beschreibung\n",
    "    if 'PM10_lag_24h' in pm10_direct:\n",
    "        print(\"\\n TEST 1: Ohne PM10_lag_24h (stärkstes Feature)\")\n",
    "    elif 'PM10_rolling_24h' in pm10_direct:\n",
    "        print(\"\\n TEST 2: Ohne PM10_rolling_24h\")\n",
    "    elif 'PM10_lag_168h' in pm10_direct:\n",
    "        if 'PM10_lag_24h' in pm10_direct:\n",
    "            print(\"\\n TEST 4: Ohne ALLE Lag-Features (nur Wetter)\")\n",
    "        else:\n",
    "            print(\"\\n TEST 3: Ohne PM10_lag_168h (Wochenmuster)\")\n",
    "    elif len(pm10_direct) == 2:\n",
    "        print(\"\\n TEST 0: BASELINE (alle Lag-Features behalten)\")\n",
    "    else:\n",
    "        print(\"\\n TEST 6: Spezial-Konfiguration\")\n",
    "    \n",
    "else:\n",
    "    print(\" FEHLER: PM10_mean wurde nicht erstellt!\")\n",
    "    print(\"   Mögliche Ursachen:\")\n",
    "    print(\"   - Keine PM10-Spalten in den Daten\")\n",
    "    print(\"   - Fehler beim Feature Engineering\")\n",
    "    \n",
    "    # Debug-Info\n",
    "    print(\"\\nDebug-Information:\")\n",
    "    print(f\"Spalten in df_train: {df_train.columns.tolist()[:10]}...\")\n",
    "    pm10_test = [col for col in df_train.columns if 'PM10' in col]\n",
    "    print(f\"PM10-Spalten gefunden: {len(pm10_test)}\")\n",
    "    if pm10_test:\n",
    "        print(f\"Erste PM10-Spalte: {pm10_test[0]}\")\n",
    "        print(f\"Beispielwerte: {df_train[pm10_test[0]].head()}\")\n",
    "    \n",
    "    raise ValueError(\"Kann ohne PM10_mean nicht fortfahren!\")\n",
    "\n",
    "# ZUSAMMENFASSUNG\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nFinale Feature-Anzahl:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "\n",
    "print(f\"\\nZielvariable:\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "\n",
    "# Feature-Liste mit Test-Info\n",
    "print(f\"\\nAlle Features ({len(X_train.columns)}):\")\n",
    "for i, col in enumerate(X_train.columns, 1):\n",
    "    marker = \" [LAG]\" if \"lag\" in col.lower() or \"rolling\" in col.lower() else \"\"\n",
    "    print(f\"  {i:2}. {col}{marker}\")\n",
    "\n",
    "# Test-Zusammenfassung\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST-KONFIGURATION:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Um andere Tests zu aktivieren:\")\n",
    "print(\"1. Gehen Sie zu Zeile ~290 in dieser Zelle\")\n",
    "print(\"2. Kommentieren Sie die aktive pm10_direct Zeile aus\")\n",
    "print(\"3. Entkommentieren Sie die gewünschte Test-Zeile\")\n",
    "print(\"4. Kernel neu starten und alles durchlaufen\")\n",
    "print(\"=\"*60)\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a76624-02e2-4a5a-99a9-1bd0db339452",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    ">>#### 4.2.2 Langzeittrends neutralisieren\n",
    "\n",
    "\n",
    ">>JAHR-NORMALISIERUNG: UMGANG MIT ZEITLICHEN TRENDS\n",
    "\n",
    ">>PM10-Konzentrationen zeigen einen kontinuierlichen Rückgang über die Jahre.\n",
    "Ohne Normalisierung würde das Jahr-Feature die Vorhersage dominieren.\n",
    "\n",
    ">>Unsere Lösung: years_since_base = (year - 2015) / 10.0\n",
    "\n",
    ">>Dies resultiert in:\n",
    ">>- Wertebereich [0, 1] statt [2015, 2025]\n",
    ">>- Reduzierte Feature Importance (25% → 7%)\n",
    ">>- Bessere Extrapolationsfähigkeit\n",
    "\n",
    ">>#### 4.2.3 Die Autokorrelations-Falle\n",
    ">>>##### 4.2.3.1 Autokorrelation vs. Data Leakage\n",
    ">>>**DATA LEAKAGE (schlecht):**\n",
    "\n",
    ">>>Zukunftsinformationen in Features (PM10 von morgen für heute)\n",
    ">>>- Das wäre Betrug!\n",
    "\n",
    ">>>**AUTOKORRELATION (gut und physikalisch korrekt):**\n",
    "\n",
    ">>>- Vergangenheitsinformationen nutzen (PM10 von gestern für morgen)\n",
    ">>>- PM10-Partikel schweben 10-48 Stunden in der Luft\n",
    ">>>- Korrelation PM10(heute) mit PM10(gestern) = 0.65\n",
    "\n",
    ">>>**Die dramatische Auswirkung:**\n",
    "\n",
    ">>>- OHNE Lag-Features: R² = 0.21 (79% unerklärte Varianz)\n",
    ">>>- MIT Lag-Features: R² = 0.907 (nur 9% unerklärte Varianz, nach Durchlauf)\n",
    "\n",
    ">>>##### 4.2.3.2 Physikalische Grundlage und optimale Lag-Auswahl\n",
    ">>>**PM10-Persistenz in der Atmosphäre**\n",
    ">>>**PM10 zeigt eine Persistenz von 48 Stunden** in städtischen Gebieten:[5], [6], [7]\n",
    "\n",
    ">>>- Bei stabilen Hochdrucklagen im Winter persistieren hohe Konzentrationen mehrere Tage\n",
    ">>>- Korrelation zwischen PM2.5 und PM10: r = 0.89 (sehr ähnliche Variationstrends)\n",
    "\n",
    ">>>**Wissenschaftlich belegte Vorhersagekraft**\n",
    "Die Vorhersagekraft nimmt mit zunehmendem Lag systematisch ab:\n",
    "\n",
    ">>>- **0-24h Lag:** r > 0.7 (sehr starke Vorhersagekraft)\n",
    ">>>- **24-48h Lag:** r ≈ 0.4-0.5 (noch signifikant)\n",
    ">>>- **48h Lag:** r < 0.3 (rapide abnehmend)\n",
    ">>>- **168h Lag (1 Woche):** r ≈ 0.2 (erfasst Wochenmuster)\n",
    "\n",
    ">>>Diese Werte führen direkt zur optimalen Feature-Auswahl für Machine Learning Modelle.\n",
    "\n",
    ">>>##### 4.2.3.3 Praktische Implementierung\n",
    ">>>**Standard Lag-Features** [8]\n",
    ">>>\n",
    "```\n",
    "# Wissenschaftlich optimierte Lag-Auswahl basierend auf Korrelationsstärke:\n",
    "X_train['PM10_lag_1h'] = df['PM10'].shift(1)     # r ≈ 0.9 (sehr stark)\n",
    "X_train['PM10_lag_24h'] = df['PM10'].shift(24)   # r ≈ 0.7 (stark)\n",
    "X_train['PM10_lag_48h'] = df['PM10'].shift(48)   # r ≈ 0.4 (mittel)\n",
    "X_train['PM10_lag_168h'] = df['PM10'].shift(168) # r ≈ 0.2 (Wochenmuster)\n",
    "\n",
    "# Rolling Averages für Glättung:\n",
    "X_train['PM10_rolling_24h'] = df['PM10'].rolling(24).mean()\n",
    "```\n",
    ">>>\n",
    "***Integration in Facebook Prophet***\n",
    "Prophet's Formel mit Lag-Features: [9]\n",
    "\n",
    ">>>y(t) = g(t) + s(t) + h(t) + β₁*PM10(t-24) + β₂*PM10(t-168) + ε\n",
    "\n",
    ">>>Wobei:\n",
    "\n",
    ">>>g(t) = Trend-Komponente\n",
    ">>>\n",
    ">>>s(t) = Saisonalität (Tageszeit, Wochentag)\n",
    ">>>\n",
    ">>>h(t) = Feiertage/Events\n",
    ">>>\n",
    ">>>PM10(t-24) = Lag-Feature von gestern\n",
    ">>>\n",
    ">>>PM10(t-168) = Lag-Feature von letzter Woche\n",
    "\n",
    ">>>##### 4.2.3.4 Kritischer Implementierungsfehler\n",
    ">>>Der häufigste Fehler beim Entfernen der Zielvariable:[8]\n",
    "```\n",
    "# KRITISCHER FEHLER - Entfernt ALLE PM10-Features (auch die wichtigen Lag-Features!):\n",
    "pm10_features = [col for col in df.columns if 'PM10' in col]\n",
    "df.drop(pm10_features, axis=1, inplace=True)  # Löscht auch PM10_lag_24h etc.!\n",
    "\n",
    "# KORREKT - Nur die Zielvariable entfernen:\n",
    "df.drop(['PM10'], axis=1, inplace=True)  # Behält Lag-Features\n",
    "# ODER spezifischer:\n",
    "X_train = df.drop(columns=['PM10'])  # Zielvariable entfernen\n",
    "y_train = df['PM10']  # Zielvariable separat speichern\n",
    "```\n",
    ">>>Dieser Fehler kann die Modellperformance von R² = 0.907 auf R² = 0.21 reduzieren!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0aab01-2234-4a90-a8aa-269496231d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PRUEFE DATENQUALITAET VOR DEM TRAINING\n",
      "============================================================\n",
      "(Schaue wie viele NaN-Werte wir haben...)\n",
      "\n",
      "----------------------------------------\n",
      "1. Training Daten:\n",
      "----------------------------------------\n",
      "  X_train Groesse: 70128 Zeilen, 14 Spalten\n",
      "  y_train Groesse: 70128 Werte\n",
      "\n",
      "  Zaehle NaN in X_train...\n",
      "    NO2_mean: 127 NaN\n",
      "    NO_mean: 122 NaN\n",
      "    O3_mean: 5270 NaN\n",
      "    SO2_mean: 45010 NaN\n",
      "    temp_mean: 1 NaN\n",
      "    humidity_mean: 1 NaN\n",
      "    wind_speed_mean: 1 NaN\n",
      "    wind_dir_mean: 1 NaN\n",
      "    PM10_lag_168h: 347 NaN\n",
      "\n",
      "  Total NaN in X_train: 50880 von 981792\n",
      "  Das sind 5.2% fehlende Werte\n",
      "\n",
      "  Zaehle NaN in y_train...\n",
      "  NaN in y_train: 179 von 70128\n",
      "  Das sind 0.3% fehlende Werte\n",
      "\n",
      "  BRAUCHBARE Training Samples: 69949\n",
      "  (Zeilen wo y nicht NaN ist)\n",
      "\n",
      "----------------------------------------\n",
      "2. Validation Daten:\n",
      "----------------------------------------\n",
      "  X_val Groesse: 8760 Zeilen, 14 Spalten\n",
      "  y_val Groesse: 8760 Werte\n",
      "  NaN in X_val: 6141 (5.0%)\n",
      "  NaN in y_val: 187 (2.1%)\n",
      "  BRAUCHBARE Validation Samples: 8573\n",
      "\n",
      "----------------------------------------\n",
      "3. Test Daten:\n",
      "----------------------------------------\n",
      "  X_test Groesse: 8713 Zeilen, 14 Spalten\n",
      "  y_test Groesse: 8713 Werte\n",
      "  NaN in X_test: 7012 (5.7%)\n",
      "  NaN in y_test: 224 (2.6%)\n",
      "  BRAUCHBARE Test Samples: 8489\n",
      "\n",
      "============================================================\n",
      "ZUSAMMENFASSUNG DATENQUALITAET\n",
      "============================================================\n",
      "\n",
      "Brauchbare Samples (wo y nicht NaN ist):\n",
      "  Training:   69949 von 70128\n",
      "  Validation: 8573 von 8760\n",
      "  Test:       8489 von 8713\n",
      "\n",
      "  GESAMT: 87011 von 87601\n",
      "\n",
      "Genug Daten fuer Training vorhanden!\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 4.2.4 Qualitätskontrolle der Features - Datenqualitaet pruefen - \n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PRUEFE DATENQUALITAET VOR DEM TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"(Schaue wie viele NaN-Werte wir haben...)\")\n",
    "\n",
    "# TRAININGSDATEN PRUEFEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"1. Training Daten:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"  X_train Groesse: \" + str(X_train.shape[0]) + \" Zeilen, \" + str(X_train.shape[1]) + \" Spalten\")\n",
    "print(\"  y_train Groesse: \" + str(len(y_train)) + \" Werte\")\n",
    "\n",
    "# Zaehle fehlende Werte in X_train (langsam aber verstaendlich)\n",
    "print(\"\\n  Zaehle NaN in X_train...\")\n",
    "nan_zaehler_x_train = 0\n",
    "total_werte_x_train = 0\n",
    "\n",
    "for spalte in X_train.columns:\n",
    "    spalten_nan = 0\n",
    "    for i in range(len(X_train)):\n",
    "        wert = X_train[spalte].iloc[i]\n",
    "        total_werte_x_train = total_werte_x_train + 1\n",
    "        \n",
    "        if pd.isna(wert):\n",
    "            nan_zaehler_x_train = nan_zaehler_x_train + 1\n",
    "            spalten_nan = spalten_nan + 1\n",
    "    \n",
    "    if spalten_nan > 0:\n",
    "        print(\"    \" + spalte + \": \" + str(spalten_nan) + \" NaN\")\n",
    "\n",
    "prozent_nan_x = (nan_zaehler_x_train / total_werte_x_train) * 100\n",
    "print(\"\\n  Total NaN in X_train: \" + str(nan_zaehler_x_train) + \" von \" + str(total_werte_x_train))\n",
    "print(\"  Das sind \" + str(round(prozent_nan_x, 1)) + \"% fehlende Werte\")\n",
    "\n",
    "# Zaehle fehlende Werte in y_train\n",
    "print(\"\\n  Zaehle NaN in y_train...\")\n",
    "nan_zaehler_y_train = 0\n",
    "\n",
    "for wert in y_train:\n",
    "    if pd.isna(wert):\n",
    "        nan_zaehler_y_train = nan_zaehler_y_train + 1\n",
    "\n",
    "prozent_nan_y = (nan_zaehler_y_train / len(y_train)) * 100\n",
    "print(\"  NaN in y_train: \" + str(nan_zaehler_y_train) + \" von \" + str(len(y_train)))\n",
    "print(\"  Das sind \" + str(round(prozent_nan_y, 1)) + \"% fehlende Werte\")\n",
    "\n",
    "# Wie viele Samples?\n",
    "brauchbare_train = len(y_train) - nan_zaehler_y_train\n",
    "print(\"\\n  BRAUCHBARE Training Samples: \" + str(brauchbare_train))\n",
    "print(\"  (Zeilen wo y nicht NaN ist)\")\n",
    "\n",
    "# VALIDATIONSDATEN PRUEFEN\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"2. Validation Daten:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"  X_val Groesse: \" + str(X_val.shape[0]) + \" Zeilen, \" + str(X_val.shape[1]) + \" Spalten\")\n",
    "print(\"  y_val Groesse: \" + str(len(y_val)) + \" Werte\")\n",
    "\n",
    "# Zaehle NaN in X_val\n",
    "nan_zaehler_x_val = 0\n",
    "total_werte_x_val = X_val.shape[0] * X_val.shape[1]\n",
    "\n",
    "for spalte in X_val.columns:\n",
    "    for i in range(len(X_val)):\n",
    "        wert = X_val[spalte].iloc[i]\n",
    "        if pd.isna(wert):\n",
    "            nan_zaehler_x_val = nan_zaehler_x_val + 1\n",
    "\n",
    "if total_werte_x_val > 0:\n",
    "    prozent_nan_x_val = (nan_zaehler_x_val / total_werte_x_val) * 100\n",
    "    print(\"  NaN in X_val: \" + str(nan_zaehler_x_val) + \" (\" + str(round(prozent_nan_x_val, 1)) + \"%)\")\n",
    "else:\n",
    "    print(\"  X_val ist leer!\")\n",
    "\n",
    "# Zaehle NaN in y_val\n",
    "nan_zaehler_y_val = 0\n",
    "for wert in y_val:\n",
    "    if pd.isna(wert):\n",
    "        nan_zaehler_y_val = nan_zaehler_y_val + 1\n",
    "\n",
    "if len(y_val) > 0:\n",
    "    prozent_nan_y_val = (nan_zaehler_y_val / len(y_val)) * 100\n",
    "    print(\"  NaN in y_val: \" + str(nan_zaehler_y_val) + \" (\" + str(round(prozent_nan_y_val, 1)) + \"%)\")\n",
    "    \n",
    "    brauchbare_val = len(y_val) - nan_zaehler_y_val\n",
    "    print(\"  BRAUCHBARE Validation Samples: \" + str(brauchbare_val))\n",
    "else:\n",
    "    print(\"  y_val ist leer!\")\n",
    "\n",
    "# TESTDATEN PRUEFEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"3. Test Daten:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"  X_test Groesse: \" + str(X_test.shape[0]) + \" Zeilen, \" + str(X_test.shape[1]) + \" Spalten\")\n",
    "print(\"  y_test Groesse: \" + str(len(y_test)) + \" Werte\")\n",
    "\n",
    "# Zaehle NaN in X_test\n",
    "nan_zaehler_x_test = 0\n",
    "total_werte_x_test = X_test.shape[0] * X_test.shape[1]\n",
    "\n",
    "for spalte in X_test.columns:\n",
    "    for i in range(len(X_test)):\n",
    "        wert = X_test[spalte].iloc[i]\n",
    "        if pd.isna(wert):\n",
    "            nan_zaehler_x_test = nan_zaehler_x_test + 1\n",
    "\n",
    "if total_werte_x_test > 0:\n",
    "    prozent_nan_x_test = (nan_zaehler_x_test / total_werte_x_test) * 100\n",
    "    print(\"  NaN in X_test: \" + str(nan_zaehler_x_test) + \" (\" + str(round(prozent_nan_x_test, 1)) + \"%)\")\n",
    "else:\n",
    "    print(\"  X_test ist leer!\")\n",
    "\n",
    "# Zaehle NaN in y_test\n",
    "nan_zaehler_y_test = 0\n",
    "for wert in y_test:\n",
    "    if pd.isna(wert):\n",
    "        nan_zaehler_y_test = nan_zaehler_y_test + 1\n",
    "\n",
    "if len(y_test) > 0:\n",
    "    prozent_nan_y_test = (nan_zaehler_y_test / len(y_test)) * 100\n",
    "    print(\"  NaN in y_test: \" + str(nan_zaehler_y_test) + \" (\" + str(round(prozent_nan_y_test, 1)) + \"%)\")\n",
    "    \n",
    "    brauchbare_test = len(y_test) - nan_zaehler_y_test\n",
    "    print(\"  BRAUCHBARE Test Samples: \" + str(brauchbare_test))\n",
    "else:\n",
    "    print(\"  y_test ist leer!\")\n",
    "\n",
    "#ZUSAMMENFASSUNG \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ZUSAMMENFASSUNG DATENQUALITAET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nBrauchbare Samples (wo y nicht NaN ist):\")\n",
    "print(\"  Training:   \" + str(brauchbare_train) + \" von \" + str(len(y_train)))\n",
    "print(\"  Validation: \" + str(brauchbare_val) + \" von \" + str(len(y_val)))\n",
    "print(\"  Test:       \" + str(brauchbare_test) + \" von \" + str(len(y_test)))\n",
    "\n",
    "gesamt_brauchbar = brauchbare_train + brauchbare_val + brauchbare_test\n",
    "gesamt_total = len(y_train) + len(y_val) + len(y_test)\n",
    "print(\"\\n  GESAMT: \" + str(gesamt_brauchbar) + \" von \" + str(gesamt_total))\n",
    "\n",
    "if gesamt_brauchbar > 0:\n",
    "    print(\"\\nGenug Daten fuer Training vorhanden!\")\n",
    "else:\n",
    "    print(\"\\nPROBLEM: Keine brauchbaren Daten!\")\n",
    "\n",
    "# Speichere die Zahlen fuer spaeter\n",
    "valid_train = brauchbare_train\n",
    "valid_val = brauchbare_val\n",
    "valid_test = brauchbare_test\n",
    "\n",
    "\n",
    "# ANMERKUNG:\n",
    "# Die vielen NaN-Werte sind normal bei LANUK-Daten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912618c-7aa9-453d-b139-48fa96948476",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "# 5. Systematische Modell-Tests (Iterativer Prozess)\n",
    ">## 5.1 Die Modell-Pipeline \n",
    ">>#### 5.1.1 XGBoost [3],[10], [11]\n",
    ">>>##### 5.1.1.1 XGBoost - Grundlagen\n",
    "\n",
    "\n",
    ">>>**Mathematik**\n",
    ">>>```\n",
    ">>>Obj = ∑ᵢ l(yᵢ, ŷᵢ) + ∑ₖ Ω(fₖ)\n",
    ">>>Ω(f) = γT + ½λ∑ⱼ wⱼ²\n",
    ">>>```\n",
    ">>>NULL-Handling: `Gain = max(GainLinks_mit_NULL, GainRechts_mit_NULL)`\n",
    "\n",
    ">>>**Parameter (Basis)**\n",
    ">>>```python\n",
    ">>>model = xgb.XGBRegressor(\n",
    ">>>    n_estimators=100,\n",
    ">>>    max_depth=6,\n",
    ">>>   learning_rate=0.1,\n",
    ">>>    subsample=0.8,\n",
    ">>>    colsample_bytree=0.8,\n",
    ">>>    random_state=42\n",
    ">>>)\n",
    ">>>model.set_params(missing=np.nan)\n",
    ">>>```\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352241c1-e608-4766-9d08-6764bc4ed36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINIERE XGBOOST MODELL\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "Schritt 1: Bereite Trainingsdaten vor\n",
      "----------------------------------------\n",
      "\n",
      "Entferne Zeilen mit NaN in y_train...\n",
      "  Vorher: 70128 Samples\n",
      "  Nachher: 69949 Samples (ohne NaN)\n",
      "  Entfernt: 179 Samples\n",
      "\n",
      "Entferne Zeilen mit NaN in y_val...\n",
      "  Validation: 8573 saubere Samples\n",
      "\n",
      "----------------------------------------\n",
      "Schritt 2: Erstelle XGBoost Modell\n",
      "----------------------------------------\n",
      "\n",
      "Erstelle XGBoost Regressor...\n",
      "  Parameter (Standardwerte fuer Einsteiger):\n",
      "    n_estimators = 100 (Anzahl Baeume)\n",
      "    max_depth = 6 (Maximale Tiefe)\n",
      "    learning_rate = 0.1 (Lernrate)\n",
      "    random_state = 42 (Fuer Reproduzierbarkeit)\n",
      "\n",
      "Modell erstellt!\n",
      "\n",
      "----------------------------------------\n",
      "Schritt 3: Trainiere das Modell\n",
      "----------------------------------------\n",
      "\n",
      "Starte Training...\n",
      "\n",
      "Training abgeschlossen!\n",
      "  Dauer: 0.7 Sekunden\n",
      "\n",
      "----------------------------------------\n",
      "Schritt 4: Teste Vorhersage auf Trainingsdaten\n",
      "----------------------------------------\n",
      "\n",
      "Mache Vorhersagen auf Trainingsdaten...\n",
      "  Vorhersagen erstellt: 69949 Werte\n",
      "\n",
      "Vergleich erste 5 Werte:\n",
      "  Echt  | Vorhersage | Differenz\n",
      "  -----------------------------------\n",
      "  43.4  | 44.6       | -1.2\n",
      "  53.9  | 54.3       | -0.4\n",
      "  64.0  | 47.9       | 16.1\n",
      "  73.4  | 60.1       | 13.3\n",
      "  82.0  | 74.3       | 7.7\n",
      "\n",
      "----------------------------------------\n",
      "Schritt 5: Teste auf Validation-Daten\n",
      "----------------------------------------\n",
      "\n",
      "Mache Vorhersagen auf Validation-Daten...\n",
      "  Vorhersagen erstellt: 8573 Werte\n",
      "\n",
      "Vergleich erste 5 Validation-Werte:\n",
      "  Echt  | Vorhersage | Differenz\n",
      "  -----------------------------------\n",
      "  14.0  | 24.5       | -10.5\n",
      "  17.6  | 23.3       | -5.7\n",
      "  19.4  | 24.4       | -5.0\n",
      "  19.2  | 25.2       | -6.0\n",
      "  19.9  | 29.5       | -9.6\n",
      "\n",
      "----------------------------------------\n",
      "Schritt 6: Speichere Modell\n",
      "----------------------------------------\n",
      "\n",
      "Modell-Informationen:\n",
      "  Anzahl Baeume: 100\n",
      "  Max Tiefe: 6\n",
      "  Features verwendet: 14\n",
      "\n",
      "Verwendete Features:\n",
      "  1. NO2_mean\n",
      "  2. NO_mean\n",
      "  3. O3_mean\n",
      "  4. SO2_mean\n",
      "  5. temp_mean\n",
      "  6. humidity_mean\n",
      "  7. wind_speed_mean\n",
      "  8. wind_dir_mean\n",
      "  9. hour\n",
      "  10. dayofweek\n",
      "  11. month\n",
      "  12. years_since_base\n",
      "  13. is_weekend\n",
      "  14. PM10_lag_168h\n",
      "\n",
      "============================================================\n",
      "XGBOOST TRAINING ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "Modell trainiert mit:\n",
      "  Training Samples: 69949\n",
      "  Features: 14\n",
      "  Trainingszeit: 0.7 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 5.1.1.2 XGBoost Modell trainieren \n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINIERE XGBOOST MODELL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# VORBEREITUNG -\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Schritt 1: Bereite Trainingsdaten vor\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Entferne Zeilen wo y = NaN ist\n",
    "print(\"\\nEntferne Zeilen mit NaN in y_train...\")\n",
    "\n",
    "# Neue Listen fuer saubere Daten\n",
    "X_train_sauber = []\n",
    "y_train_sauber = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if pd.notna(y_train.iloc[i]):  # Wenn y NICHT NaN ist\n",
    "        X_train_sauber.append(X_train.iloc[i])\n",
    "        y_train_sauber.append(y_train.iloc[i])\n",
    "\n",
    "# Zurueck zu DataFrame/Series\n",
    "X_train_clean = pd.DataFrame(X_train_sauber)\n",
    "y_train_clean = pd.Series(y_train_sauber)\n",
    "\n",
    "print(\"  Vorher: \" + str(len(y_train)) + \" Samples\")\n",
    "print(\"  Nachher: \" + str(len(y_train_clean)) + \" Samples (ohne NaN)\")\n",
    "print(\"  Entfernt: \" + str(len(y_train) - len(y_train_clean)) + \" Samples\")\n",
    "\n",
    "# Das gleiche fuer Validation\n",
    "print(\"\\nEntferne Zeilen mit NaN in y_val...\")\n",
    "\n",
    "X_val_sauber = []\n",
    "y_val_sauber = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    if pd.notna(y_val.iloc[i]):\n",
    "        X_val_sauber.append(X_val.iloc[i])\n",
    "        y_val_sauber.append(y_val.iloc[i])\n",
    "\n",
    "X_val_clean = pd.DataFrame(X_val_sauber)\n",
    "y_val_clean = pd.Series(y_val_sauber)\n",
    "\n",
    "print(\"  Validation: \" + str(len(y_val_clean)) + \" saubere Samples\")\n",
    "\n",
    "# MODELL ERSTELLEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Schritt 2: Erstelle XGBoost Modell\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Einfaches XGBoost Modell \n",
    "print(\"\\nErstelle XGBoost Regressor...\")\n",
    "print(\"  Parameter (Standardwerte fuer Einsteiger):\")\n",
    "print(\"    n_estimators = 100 (Anzahl Baeume)\")\n",
    "print(\"    max_depth = 6 (Maximale Tiefe)\")\n",
    "print(\"    learning_rate = 0.1 (Lernrate)\")\n",
    "print(\"    random_state = 42 (Fuer Reproduzierbarkeit)\")\n",
    "\n",
    "# Modell erstellen\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,      # 100 Baeume\n",
    "    max_depth=6,           # Nicht zu tief\n",
    "    learning_rate=0.1,     # Standard Lernrate\n",
    "    random_state=42        # Immer gleiche Ergebnisse\n",
    ")\n",
    "\n",
    "print(\"\\nModell erstellt!\")\n",
    "\n",
    "# TRAINING \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Schritt 3: Trainiere das Modell\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"\\nStarte Training...\")\n",
    "\n",
    "# Zeit messen\n",
    "import time\n",
    "start_zeit = time.time()\n",
    "\n",
    "# Modell trainieren (ganz einfach!)\n",
    "model.fit(X_train_clean, y_train_clean)\n",
    "\n",
    "# Zeit stoppen\n",
    "end_zeit = time.time()\n",
    "dauer = end_zeit - start_zeit\n",
    "\n",
    "print(\"\\nTraining abgeschlossen!\")\n",
    "print(\"  Dauer: \" + str(round(dauer, 1)) + \" Sekunden\")\n",
    "\n",
    "# ERSTE VORHERSAGE \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Schritt 4: Teste Vorhersage auf Trainingsdaten\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"\\nMache Vorhersagen auf Trainingsdaten...\")\n",
    "y_pred_train = model.predict(X_train_clean)\n",
    "\n",
    "print(\"  Vorhersagen erstellt: \" + str(len(y_pred_train)) + \" Werte\")\n",
    "\n",
    "# Erste 5 Vorhersagen anschauen\n",
    "print(\"\\nVergleich erste 5 Werte:\")\n",
    "print(\"  Echt  | Vorhersage | Differenz\")\n",
    "print(\"  \" + \"-\"*35)\n",
    "\n",
    "for i in range(min(5, len(y_train_clean))):\n",
    "    echt = y_train_clean.iloc[i]\n",
    "    vorher = y_pred_train[i]\n",
    "    diff = echt - vorher\n",
    "    \n",
    "    print(\"  \" + str(round(echt, 1)).ljust(5) + \" | \" + \n",
    "          str(round(vorher, 1)).ljust(10) + \" | \" + \n",
    "          str(round(diff, 1)))\n",
    "\n",
    "# VALIDATION VORHERSAGE \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Schritt 5: Teste auf Validation-Daten\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "if len(X_val_clean) > 0:\n",
    "    print(\"\\nMache Vorhersagen auf Validation-Daten...\")\n",
    "    y_pred_val = model.predict(X_val_clean)\n",
    "    \n",
    "    print(\"  Vorhersagen erstellt: \" + str(len(y_pred_val)) + \" Werte\")\n",
    "    \n",
    "    # Erste 5 Vorhersagen\n",
    "    print(\"\\nVergleich erste 5 Validation-Werte:\")\n",
    "    print(\"  Echt  | Vorhersage | Differenz\")\n",
    "    print(\"  \" + \"-\"*35)\n",
    "    \n",
    "    for i in range(min(5, len(y_val_clean))):\n",
    "        echt = y_val_clean.iloc[i]\n",
    "        vorher = y_pred_val[i]\n",
    "        diff = echt - vorher\n",
    "        \n",
    "        print(\"  \" + str(round(echt, 1)).ljust(5) + \" | \" + \n",
    "              str(round(vorher, 1)).ljust(10) + \" | \" + \n",
    "              str(round(diff, 1)))\n",
    "else:\n",
    "    print(\"  Keine Validation-Daten vorhanden!\")\n",
    "    y_pred_val = []\n",
    "\n",
    "# MODELL SPEICHERN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Schritt 6: Speichere Modell\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Modell-Info speichern\n",
    "print(\"\\nModell-Informationen:\")\n",
    "print(\"  Anzahl Baeume: \" + str(model.n_estimators))\n",
    "print(\"  Max Tiefe: \" + str(model.max_depth))\n",
    "print(\"  Features verwendet: \" + str(len(X_train_clean.columns)))\n",
    "\n",
    "# Modell Feature\n",
    "print(\"\\nVerwendete Features:\")\n",
    "for i, feature in enumerate(X_train_clean.columns):\n",
    "    print(\"  \" + str(i+1) + \". \" + str(feature))\n",
    "\n",
    "# ZUSAMMENFASSUNG \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBOOST TRAINING ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nModell trainiert mit:\")\n",
    "print(\"  Training Samples: \" + str(len(X_train_clean)))\n",
    "print(\"  Features: \" + str(len(X_train_clean.columns)))\n",
    "print(\"  Trainingszeit: \" + str(round(dauer, 1)) + \" Sekunden\")\n",
    "\n",
    "# Speichere Vorhersagen fuer spaeter\n",
    "train_vorhersagen = y_pred_train\n",
    "val_vorhersagen = y_pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46d8ad2c-bdc0-41d1-95f1-191d38969736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BEWERTUNG:\n",
      "============================================================\n",
      "(Verschiedene Metriken berechnen...)\n",
      "\n",
      "Importiere Metriken...\n",
      "Metriken importiert\n",
      "\n",
      "----------------------------------------\n",
      "1. Bewertung auf TRAINING Daten:\n",
      "----------------------------------------\n",
      "\n",
      "Berechne MAE (Mean Absolute Error)...\n",
      "  = Durchschnitt der absoluten Fehler\n",
      "  MAE Training: 3.7 µg/m³\n",
      "  Das heisst: Im Schnitt 3.7 µg/m³ daneben\n",
      "\n",
      "Berechne RMSE (Root Mean Squared Error)...\n",
      "  = Wurzel aus dem durchschnittlichen quadratischen Fehler\n",
      "  RMSE Training: 5.32 µg/m³\n",
      "  (Bestraft grosse Fehler staerker)\n",
      "\n",
      "Berechne R² Score...\n",
      "  = Erklärt, wieviel Varianz, ich erklären kann\n",
      "  R² Training: 0.591\n",
      "  Das heisst: 59.1% der Varianz erklaert\n",
      "  --> OKAY (50-70%)\n",
      "\n",
      "Berechne MAPE (Mean Absolute Percentage Error)...\n",
      "  = Prozentualer Fehler\n",
      "  MAPE Training: 18.3%\n",
      "  Das heisst: Im Schnitt 18.3% daneben\n",
      "\n",
      "Durchschnitt PM10 (echt): 20.3 µg/m³\n",
      "\n",
      "----------------------------------------\n",
      "2. Bewertung auf VALIDATION Daten:\n",
      "----------------------------------------\n",
      "\n",
      "  MAE Validation: 3.63 µg/m³\n",
      "  RMSE Validation: 4.79 µg/m³\n",
      "  R² Validation: 0.088\n",
      "  Das heisst: 8.8% der Varianz erklaert\n",
      "  --> SEHR SCHLECHT! (<30%)\n",
      "  MAPE Validation: 22.4%\n",
      "\n",
      "Durchschnitt PM10 (echt): 16.8 µg/m³\n",
      "\n",
      "----------------------------------------\n",
      "3. Vergleich Training vs Validation:\n",
      "----------------------------------------\n",
      "\n",
      "         | Training | Validation | Differenz\n",
      "  -------|----------|------------|----------\n",
      "  MAE    | 3.7      | 3.63       | 0.07\n",
      "  RMSE   | 5.32     | 4.79       | 0.54\n",
      "  R²     | 0.591    | 0.088      | 0.503\n",
      "\n",
      "Overfitting Check:\n",
      "  WARNUNG: Modell overfittet! (Training viel besser als Validation)\n",
      "\n",
      "============================================================\n",
      "MODELL-BEWERTUNG ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "*** ERGEBNIS ***\n",
      "Das Modell ist SEHR SCHLECHT!\n",
      "R² = 0.088 ist viel zu niedrig!\n",
      "\n",
      "(Metriken gespeichert fuer spaeter)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 5.1.1.3 Metriken und Modellbewertung\n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BEWERTUNG:\")\n",
    "print(\"=\"*60)\n",
    "print(\"(Verschiedene Metriken berechnen...)\")\n",
    "\n",
    "# METRIKEN IMPORTIEREN \n",
    "print(\"\\nImportiere Metriken...\")\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "print(\"Metriken importiert\")\n",
    "\n",
    "# TRAINING METRIKEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"1. Bewertung auf TRAINING Daten:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# MAE - Mean Absolute Error (Durchschnittlicher Fehler)\n",
    "print(\"\\nBerechne MAE (Mean Absolute Error)...\")\n",
    "print(\"  = Durchschnitt der absoluten Fehler\")\n",
    "\n",
    "mae_train = mean_absolute_error(y_train_clean, train_vorhersagen)\n",
    "print(\"  MAE Training: \" + str(round(mae_train, 2)) + \" µg/m³\")\n",
    "print(\"  Das heisst: Im Schnitt \" + str(round(mae_train, 2)) + \" µg/m³ daneben\")\n",
    "\n",
    "# RMSE - Root Mean Squared Error\n",
    "print(\"\\nBerechne RMSE (Root Mean Squared Error)...\")\n",
    "print(\"  = Wurzel aus dem durchschnittlichen quadratischen Fehler\")\n",
    "\n",
    "mse_train = mean_squared_error(y_train_clean, train_vorhersagen)\n",
    "rmse_train = mse_train ** 0.5  # Wurzel ziehen\n",
    "print(\"  RMSE Training: \" + str(round(rmse_train, 2)) + \" µg/m³\")\n",
    "print(\"  (Bestraft grosse Fehler staerker)\")\n",
    "\n",
    "# R² - Bestimmtheitsmass\n",
    "print(\"\\nBerechne R² Score...\")\n",
    "print(\"  = Erklärt, wieviel Varianz, ich erklären kann\")\n",
    "\n",
    "r2_train = r2_score(y_train_clean, train_vorhersagen)\n",
    "print(\"  R² Training: \" + str(round(r2_train, 3)))\n",
    "print(\"  Das heisst: \" + str(round(r2_train * 100, 1)) + \"% der Varianz erklaert\")\n",
    "\n",
    "# Interpretation\n",
    "if r2_train > 0.9:\n",
    "    print(\"  --> SEHR GUT! (>90%)\") # aus Referenzwerte entnommen\n",
    "elif r2_train > 0.7:\n",
    "    print(\"  --> GUT (70-90%)\")\n",
    "elif r2_train > 0.5:\n",
    "    print(\"  --> OKAY (50-70%)\")\n",
    "elif r2_train > 0.3:\n",
    "    print(\"  --> SCHLECHT (30-50%)\")\n",
    "else:\n",
    "    print(\"  --> SEHR SCHLECHT! (<30%)\")\n",
    "\n",
    "# MAPE - Mean Absolute Percentage Error\n",
    "print(\"\\nBerechne MAPE (Mean Absolute Percentage Error)...\")\n",
    "print(\"  = Prozentualer Fehler\")\n",
    "\n",
    "# Manuell berechnen \n",
    "prozent_fehler = []\n",
    "for i in range(len(y_train_clean)):\n",
    "    echt = y_train_clean.iloc[i]\n",
    "    vorher = train_vorhersagen[i]\n",
    "    \n",
    "    if echt != 0:  # Division durch 0 vermeiden\n",
    "        fehler = abs(echt - vorher) / echt * 100\n",
    "        prozent_fehler.append(fehler)\n",
    "\n",
    "if len(prozent_fehler) > 0:\n",
    "    mape_train = sum(prozent_fehler) / len(prozent_fehler)\n",
    "    print(\"  MAPE Training: \" + str(round(mape_train, 1)) + \"%\")\n",
    "    print(\"  Das heisst: Im Schnitt \" + str(round(mape_train, 1)) + \"% daneben\")\n",
    "\n",
    "# Durchschnitt der echten Werte\n",
    "mean_observed_train = y_train_clean.mean()\n",
    "print(\"\\nDurchschnitt PM10 (echt): \" + str(round(mean_observed_train, 1)) + \" µg/m³\")\n",
    "\n",
    "# VALIDATIONS-METRIKEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"2. Bewertung auf VALIDATION Daten:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "if len(val_vorhersagen) > 0:\n",
    "    # MAE\n",
    "    mae_val = mean_absolute_error(y_val_clean, val_vorhersagen)\n",
    "    print(\"\\n  MAE Validation: \" + str(round(mae_val, 2)) + \" µg/m³\")\n",
    "    \n",
    "    # RMSE\n",
    "    mse_val = mean_squared_error(y_val_clean, val_vorhersagen)\n",
    "    rmse_val = mse_val ** 0.5\n",
    "    print(\"  RMSE Validation: \" + str(round(rmse_val, 2)) + \" µg/m³\")\n",
    "    \n",
    "    # R²\n",
    "    r2_val = r2_score(y_val_clean, val_vorhersagen)\n",
    "    print(\"  R² Validation: \" + str(round(r2_val, 3)))\n",
    "    print(\"  Das heisst: \" + str(round(r2_val * 100, 1)) + \"% der Varianz erklaert\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if r2_val > 0.9:\n",
    "        print(\"  --> SEHR GUT! (>90%)\")\n",
    "    elif r2_val > 0.7:\n",
    "        print(\"  --> GUT (70-90%)\")\n",
    "    elif r2_val > 0.5:\n",
    "        print(\"  --> OKAY (50-70%)\")\n",
    "    elif r2_val > 0.3:\n",
    "        print(\"  --> SCHLECHT (30-50%)\")\n",
    "    else:\n",
    "        print(\"  --> SEHR SCHLECHT! (<30%)\")\n",
    "    \n",
    "    # MAPE\n",
    "    prozent_fehler_val = []\n",
    "    for i in range(len(y_val_clean)):\n",
    "        echt = y_val_clean.iloc[i]\n",
    "        vorher = val_vorhersagen[i]\n",
    "        \n",
    "        if echt != 0:\n",
    "            fehler = abs(echt - vorher) / echt * 100\n",
    "            prozent_fehler_val.append(fehler)\n",
    "    \n",
    "    if len(prozent_fehler_val) > 0:\n",
    "        mape_val = sum(prozent_fehler_val) / len(prozent_fehler_val)\n",
    "        print(\"  MAPE Validation: \" + str(round(mape_val, 1)) + \"%\")\n",
    "    \n",
    "    mean_observed_val = y_val_clean.mean()\n",
    "    print(\"\\nDurchschnitt PM10 (echt): \" + str(round(mean_observed_val, 1)) + \" µg/m³\")\n",
    "else:\n",
    "    print(\"  Keine Validation-Daten vorhanden!\")\n",
    "\n",
    "# VERGLEICH TRAINING VS VALIDATION \n",
    "# mit Hilfe von Claude bei der Darstellung\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"3. Vergleich Training vs Validation:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"\\n         | Training | Validation | Differenz\")\n",
    "print(\"  -------|----------|------------|----------\")\n",
    "print(\"  MAE    | \" + str(round(mae_train, 2)).ljust(8) + \" | \" + \n",
    "      str(round(mae_val, 2)).ljust(10) + \" | \" + \n",
    "      str(round(abs(mae_train - mae_val), 2)))\n",
    "print(\"  RMSE   | \" + str(round(rmse_train, 2)).ljust(8) + \" | \" + \n",
    "      str(round(rmse_val, 2)).ljust(10) + \" | \" + \n",
    "      str(round(abs(rmse_train - rmse_val), 2)))\n",
    "print(\"  R²     | \" + str(round(r2_train, 3)).ljust(8) + \" | \" + \n",
    "      str(round(r2_val, 3)).ljust(10) + \" | \" + \n",
    "      str(round(abs(r2_train - r2_val), 3)))\n",
    "\n",
    "# Overfitting Check\n",
    "print(\"\\nOverfitting Check:\")\n",
    "r2_differenz = r2_train - r2_val\n",
    "if r2_differenz > 0.1:\n",
    "    print(\"  WARNUNG: Modell overfittet! (Training viel besser als Validation)\")\n",
    "elif r2_differenz > 0.05:\n",
    "    print(\"  Leichtes Overfitting (Training etwas besser)\")\n",
    "else:\n",
    "    print(\" Kein Overfitting\")\n",
    "\n",
    "# ZUSAMMENFASSUNG \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELL-BEWERTUNG ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n*** ERGEBNIS ***\")\n",
    "if r2_val < 0.3:\n",
    "    print(\"Das Modell ist SEHR SCHLECHT!\")\n",
    "    print(\"R² = \" + str(round(r2_val, 3)) + \" ist viel zu niedrig!\")\n",
    "elif r2_val < 0.7:\n",
    "    print(\"Das Modell ist OKAY, aber nicht gut.\")\n",
    "    print(\"R² = \" + str(round(r2_val, 3)) + \" koennte besser sein.\")\n",
    "else:\n",
    "    print(\"Das Modell ist GUT!\")\n",
    "    print(\"R² = \" + str(round(r2_val, 3)) + \" ist akzeptabel.\")\n",
    "\n",
    "# Speichere Metriken\n",
    "training_metriken = {\n",
    "    'mae': mae_train,\n",
    "    'rmse': rmse_train,\n",
    "    'r2': r2_train,\n",
    "    'mape': mape_train\n",
    "}\n",
    "\n",
    "validation_metriken = {\n",
    "    'mae': mae_val,\n",
    "    'rmse': rmse_val,\n",
    "    'r2': r2_val,\n",
    "    'mape': mape_val\n",
    "}\n",
    "\n",
    "print(\"\\n(Metriken gespeichert fuer spaeter)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1fc6207-c009-4ddb-8a20-c4ad0f9e2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSE\n",
      "============================================================\n",
      "\n",
      "Hole Feature Importance vom XGBoost Modell...\n",
      "  Anzahl Features: 14\n",
      "\n",
      "Sortiere nach Wichtigkeit...\n",
      "\n",
      "----------------------------------------\n",
      "RANKING:\n",
      "----------------------------------------\n",
      "\n",
      "  Platz | Feature           | Importance | Prozent\n",
      "  --------------------------------------------------\n",
      "  1     | NO2_mean          | 0.1956     | 19.6%\n",
      "  2     | month             | 0.1282     | 12.8%\n",
      "  3     | O3_mean           | 0.0925     | 9.3%\n",
      "  4     | years_since_base  | 0.0849     | 8.5%\n",
      "  5     | temp_mean         | 0.082      | 8.2%\n",
      "  6     | wind_dir_mean     | 0.0618     | 6.2%\n",
      "  7     | NO_mean           | 0.0614     | 6.1%\n",
      "  8     | dayofweek         | 0.0591     | 5.9%\n",
      "  9     | humidity_mean     | 0.0586     | 5.9%\n",
      "  10    | PM10_lag_168h     | 0.0568     | 5.7%\n",
      "  11    | wind_speed_mean   | 0.0497     | 5.0%\n",
      "  12    | SO2_mean          | 0.0376     | 3.8%\n",
      "  13    | hour              | 0.0316     | 3.2%\n",
      "  14    | is_weekend        | 0.0        | 0.0%\n",
      "\n",
      "----------------------------------------\n",
      "Top 3 Features:\n",
      "----------------------------------------\n",
      "  1. NO2_mean (19.6%)\n",
      "  2. month (12.8%)\n",
      "  3. O3_mean (9.3%)\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSE ABGESCHLOSSEN\n",
      "============================================================\n",
      "\n",
      "Modell nutzt 14 Features\n",
      "Wichtigstes Feature: NO2_mean\n",
      "\n",
      "(Feature Importance gespeichert)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 5.1.1.4 Feature Importance Analyse\n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# FEATURE IMPORTANCE HOLEN \n",
    "print(\"\\nHole Feature Importance vom XGBoost Modell...\")\n",
    "\n",
    "# XGBoost hat eine eingebaute Feature Importance\n",
    "importance_werte = model.feature_importances_\n",
    "feature_namen = list(X_train_clean.columns)\n",
    "\n",
    "print(\"  Anzahl Features: \" + str(len(feature_namen)))\n",
    "\n",
    "# SORTIEREN \n",
    "print(\"\\nSortiere nach Wichtigkeit...\")\n",
    "\n",
    "# Liste mit Namen und Importance\n",
    "feature_importance_liste = []\n",
    "for i in range(len(feature_namen)):\n",
    "    name = feature_namen[i]\n",
    "    importance = importance_werte[i]\n",
    "    feature_importance_liste.append((name, importance))\n",
    "\n",
    "# Nach Importance sortieren\n",
    "feature_importance_liste.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# AUSGABE -\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"RANKING:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"\\n  Platz | Feature           | Importance | Prozent\")\n",
    "print(\"  \" + \"-\"*50)\n",
    "\n",
    "gesamt_importance = sum(importance_werte)\n",
    "\n",
    "for i, (name, importance) in enumerate(feature_importance_liste):\n",
    "    prozent = (importance / gesamt_importance) * 100\n",
    "    \n",
    "    print(\"  \" + str(i+1).ljust(5) + \" | \" + \n",
    "          name.ljust(17) + \" | \" + \n",
    "          str(round(importance, 4)).ljust(10) + \" | \" +\n",
    "          str(round(prozent, 1)) + \"%\")\n",
    "\n",
    "# TOP 3 \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Top 3 Features:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for i in range(min(3, len(feature_importance_liste))):\n",
    "    name, importance = feature_importance_liste[i]\n",
    "    prozent = (importance / gesamt_importance) * 100\n",
    "    print(\"  \" + str(i+1) + \". \" + name + \" (\" + str(round(prozent, 1)) + \"%)\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSE ABGESCHLOSSEN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nModell nutzt \" + str(len(feature_namen)) + \" Features\")\n",
    "print(\"Wichtigstes Feature: \" + feature_importance_liste[0][0])\n",
    "\n",
    "# Speichere fuer spaeter\n",
    "feature_importance_dict = {}\n",
    "for name, importance in feature_importance_liste:\n",
    "    feature_importance_dict[name] = importance\n",
    "\n",
    "print(\"\\n(Feature Importance gespeichert)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325dc95-7aea-4a4b-9f0b-f78d5ca4386b",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    ">>#### 5.1.2. Gradient Boosting\n",
    ">>>##### 5.1.2.1 Gradient Boosting - Grundlagen [3],[8],[12]\n",
    "\n",
    ">>>**Mathematische Grundlagen**\n",
    ">>>```\n",
    ">>>L(y, F) = ∑ᵢ l(yᵢ, F(xᵢ))  (Verlustfunktion)\n",
    ">>>Fₘ(x) = Fₘ₋₁(x) + γₘ × hₘ(x)  (Iterative Verbesserung)\n",
    ">>>rᵢₘ = -[∂L(yᵢ, F(xᵢ))/∂F(xᵢ)]  (Residuen-Berechnung)\n",
    ">>>```\n",
    ">>>**Parameter** \n",
    ">>>```\n",
    ">>>model_gb = GradientBoostingRegressor(\n",
    ">>>    n_estimators=100,      # 100 Bäume\n",
    ">>>    max_depth=6,           # Nicht zu tief\n",
    ">>>    learning_rate=0.1,     # Lernrate\n",
    ">>>    subsample=0.8,         # 80% der Daten\n",
    ">>>    random_state=42\n",
    ">>>)\n",
    ">>>```\n",
    ">>>**Imputation**\n",
    ">>>python# Mittelwert-Imputation (aus Code)\n",
    ">>>```mittelwerte[spalte] = X_train_clean[spalte].mean()\n",
    ">>>X_train_clean[spalte].fillna(mittelwert)\n",
    ">>>```\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f08cf0e-f51f-4de6-89db-3c7e6f19735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GRADIENT BOOSTING MODELL\n",
      "============================================================\n",
      "\n",
      "Vorbereitung der Daten...\n",
      "  Training: 69949 Datenpunkte\n",
      "  Validation: 8573 Datenpunkte\n",
      "\n",
      "Ersetze fehlende Werte...\n",
      "  OK: Fehlende Werte ersetzt\n",
      "\n",
      "----------------------------------------\n",
      "Trainiere Gradient Boosting...\n",
      "  Starte Training...\n",
      "  (Das dauert etwas laenger als XGBoost...)\n",
      "  Training abgeschlossen!\n",
      "\n",
      "----------------------------------------\n",
      "Bewerte Modell...\n",
      "\n",
      "============================================================\n",
      "ERGEBNISSE GRADIENT BOOSTING\n",
      "============================================================\n",
      "\n",
      "Training:\n",
      "  MAE:  3.75 ug/m3\n",
      "  RMSE: 5.41 ug/m3\n",
      "  R2:   0.578\n",
      "  MAPE: 18.5%\n",
      "\n",
      "Validation:\n",
      "  MAE:  3.61 ug/m3\n",
      "  RMSE: 4.70 ug/m3\n",
      "  R2:   0.121\n",
      "  MAPE: 22.1%\n",
      "\n",
      "----------------------------------------\n",
      "Vergleich mit XGBoost:\n",
      "  XGBoost R2 Val:         0.132\n",
      "  Gradient Boosting R2:   0.121\n",
      "  -> Gradient Boosting ist auch nicht besser...\n",
      "\n",
      "----------------------------------------\n",
      "Feature Importance (Top 5):\n",
      "  1. month                16.3%\n",
      "  2. NO2_mean             15.8%\n",
      "  3. temp_mean            13.3%\n",
      "  4. years_since_base     9.1%\n",
      "  5. humidity_mean        8.0%\n",
      "\n",
      "============================================================\n",
      "Zusammenfassung\n",
      "============================================================\n",
      "Gradient Boosting R2 Training:   0.578\n",
      "Gradient Boosting R2 Validation: 0.121\n",
      "\n",
      "Modell gespeichert als 'model_gb_trained'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5.1.2.2 GRADIENT BOOSTING PROBIEREN\n",
    "# ============================================================\n",
    "\n",
    "# Das Buch \"Praxiseinstieg ML\" sagt, Gradient Boosting ist aehnlich wie XGBoost aber manchmal stabiler. \n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GRADIENT BOOSTING MODELL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# DATEN VORBEREITEN \n",
    "print(\"\\nVorbereitung der Daten...\")\n",
    "\n",
    "# Entferne Zeilen mit NaN im Target\n",
    "train_mask = y_train.notna()\n",
    "X_train_clean = X_train[train_mask]\n",
    "y_train_clean = y_train[train_mask]\n",
    "\n",
    "val_mask = y_val.notna()\n",
    "X_val_clean = X_val[val_mask]\n",
    "y_val_clean = y_val[val_mask]\n",
    "\n",
    "print(f\"  Training: {len(X_train_clean)} Datenpunkte\")\n",
    "print(f\"  Validation: {len(X_val_clean)} Datenpunkte\")\n",
    "\n",
    "# Gradient Boosting kann NICHT mit NaN umgehen!\n",
    "# Muss fehlende Werte ersetzen\n",
    "print(\"\\nErsetze fehlende Werte...\")\n",
    "\n",
    "# Berechne Mittelwerte aus Training\n",
    "mittelwerte = {}\n",
    "for spalte in X_train_clean.columns:\n",
    "    mittelwert = X_train_clean[spalte].mean()\n",
    "    if np.isnan(mittelwert):\n",
    "        mittelwert = 0\n",
    "    mittelwerte[spalte] = mittelwert\n",
    "    X_train_clean[spalte] = X_train_clean[spalte].fillna(mittelwert)\n",
    "\n",
    "# Gleiche Mittelwerte fuer Validation\n",
    "for spalte in X_val_clean.columns:\n",
    "    if spalte in mittelwerte:\n",
    "        X_val_clean[spalte] = X_val_clean[spalte].fillna(mittelwerte[spalte])\n",
    "\n",
    "print(\"  OK: Fehlende Werte ersetzt\")\n",
    "\n",
    "#  MODELL TRAINIEREN\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Trainiere Gradient Boosting...\")\n",
    "\n",
    "# Erstelle Modell mit Parametern aus dem Buch\n",
    "model_gb = GradientBoostingRegressor(\n",
    "    n_estimators=100,        # 100 Baeume\n",
    "    max_depth=6,             # Nicht zu tief\n",
    "    learning_rate=0.1,       # Lernrate\n",
    "    subsample=0.8,           # Nur 80% der Daten pro Baum\n",
    "    random_state=42          # Reproduzierbarkeit\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"  Starte Training...\")\n",
    "print(\"  (Das dauert etwas laenger als XGBoost...)\")\n",
    "\n",
    "model_gb.fit(X_train_clean, y_train_clean)\n",
    "print(\"  Training abgeschlossen!\")\n",
    "\n",
    "# MODELL BEWERTEN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Bewerte Modell...\")\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = model_gb.predict(X_train_clean)\n",
    "y_pred_val = model_gb.predict(X_val_clean)\n",
    "\n",
    "# Metriken Training\n",
    "mae_train = mean_absolute_error(y_train_clean, y_pred_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_clean, y_pred_train))\n",
    "r2_train = r2_score(y_train_clean, y_pred_train)\n",
    "\n",
    "# Metriken Validation\n",
    "mae_val = mean_absolute_error(y_val_clean, y_pred_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val_clean, y_pred_val))\n",
    "r2_val = r2_score(y_val_clean, y_pred_val)\n",
    "\n",
    "# MAPE berechnen (Prozentfehler)\n",
    "def berechne_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() > 0:\n",
    "        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "mape_train = berechne_mape(y_train_clean.values, y_pred_train)\n",
    "mape_val = berechne_mape(y_val_clean.values, y_pred_val)\n",
    "\n",
    "# ERGEBNISSE \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ERGEBNISSE GRADIENT BOOSTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining:\")\n",
    "print(f\"  MAE:  {mae_train:.2f} ug/m3\")\n",
    "print(f\"  RMSE: {rmse_train:.2f} ug/m3\")\n",
    "print(f\"  R2:   {r2_train:.3f}\")\n",
    "print(f\"  MAPE: {mape_train:.1f}%\")\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "print(f\"  MAE:  {mae_val:.2f} ug/m3\")\n",
    "print(f\"  RMSE: {rmse_val:.2f} ug/m3\")\n",
    "print(f\"  R2:   {r2_val:.3f}\")\n",
    "print(f\"  MAPE: {mape_val:.1f}%\")\n",
    "\n",
    "# Vergleich mit XGBoost\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Vergleich mit XGBoost:\")\n",
    "print(\"  XGBoost R2 Val:         0.132\")\n",
    "print(f\"  Gradient Boosting R2:   {r2_val:.3f}\")\n",
    "\n",
    "if r2_val > 0.132:\n",
    "    print(\"  -> Gradient Boosting ist etwas besser!\")\n",
    "    verbesserung = r2_val - 0.132\n",
    "    print(f\"     Um {verbesserung:.3f} besser\")\n",
    "else:\n",
    "    print(\"  -> Gradient Boosting ist auch nicht besser...\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Feature Importance (Top 5):\")\n",
    "\n",
    "importances = model_gb.feature_importances_\n",
    "feature_importance = sorted(zip(X_train_clean.columns, importances), \n",
    "                          key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (feature, importance) in enumerate(feature_importance[:5], 1):\n",
    "    prozent = importance * 100\n",
    "    print(f\"  {i}. {feature:20} {prozent:.1f}%\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Zusammenfassung\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Gradient Boosting R2 Training:   {r2_train:.3f}\")\n",
    "print(f\"Gradient Boosting R2 Validation: {r2_val:.3f}\")\n",
    "\n",
    "# Speichere fuer spaeter\n",
    "model_gb_trained = model_gb\n",
    "gb_results = {\n",
    "    'train_r2': r2_train,\n",
    "    'val_r2': r2_val,\n",
    "    'train_mae': mae_train,\n",
    "    'val_mae': mae_val\n",
    "}\n",
    "\n",
    "print(\"\\nModell gespeichert als 'model_gb_trained'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085fcfc-865b-40e7-8a22-c52e694f59ec",
   "metadata": {},
   "source": [
    "-------------------------\n",
    ">>#### 5.1.3 Random Forest \n",
    ">>>##### 5.1.3.1 Random Forest  - Grundlagen [3],[8], [13]\n",
    "\n",
    ">>>***Mathematische Grundlagen***\n",
    ">>>```\n",
    ">>>f̂(x) = 1/B ∑ᵦ₌₁ᴮ T̂ᵦ(x)  (Ensemble-Vorhersage)\n",
    ">>>D*ᵦ ~ Bootstrap(D, n)  (Bootstrap-Sampling)\n",
    ">>>m = ⌊√p⌋  (Feature-Randomness)\n",
    ">>>```\n",
    "\n",
    ">>>***Parameter***\n",
    "\n",
    ">>>```\n",
    ">>>model_rf = RandomForestRegressor(\n",
    ">>>    n_estimators=100,      # 100 Bäume\n",
    ">>>    max_depth=10,          # Nicht zu tief\n",
    ">>>    min_samples_split=10,  # Min. 10 Samples\n",
    ">>>    random_state=42\n",
    ">>>)\n",
    ">>>```\n",
    ">>>\n",
    ">>>***Imputation***\n",
    ">>>Mittelwert-Imputation\n",
    ">>>```\n",
    ">>>mittelwerte[spalte] = X_train_clean[spalte].mean()\n",
    ">>>if np.isnan(mittelwert):\n",
    ">>>    mittelwert = 0  # Falls alles NaN\n",
    ">>>X_train_clean[spalte].fillna(mittelwert)\n",
    ">>>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b721650-9cb2-4a87-bb04-a8ded4ffbaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM FOREST MODELL\n",
      "============================================================\n",
      "\n",
      "Vorbereitung der Daten...\n",
      "  Training: 69949 Datenpunkte\n",
      "  Validation: 8573 Datenpunkte\n",
      "\n",
      "Ersetze fehlende Werte mit Mittelwert...\n",
      "Fehlende Werte ersetzt\n",
      "\n",
      "----------------------------------------\n",
      "Trainiere Random Forest...\n",
      "  Starte Training...\n",
      "  Training abgeschlossen!\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "ERGEBNISSE RANDOM FOREST\n",
      "============================================================\n",
      "\n",
      "Training:\n",
      "  MAE:  3.93 ug/m3\n",
      "  R2:   0.561\n",
      "\n",
      "Validation:\n",
      "  MAE:  3.68 ug/m3\n",
      "  R2:   0.078\n",
      "\n",
      "----------------------------------------\n",
      "Feature Importance (Top 5):\n",
      "  1. NO2_mean             19.0%\n",
      "  2. month                15.5%\n",
      "  3. temp_mean            12.6%\n",
      "  4. years_since_base     8.1%\n",
      "  5. humidity_mean        7.2%\n",
      "\n",
      "Modell gespeichert als 'model_rf_trained'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5.1.3.2 RANDOM FOREST MODELL TRAINIEREN\n",
    "# ============================================================\n",
    "\n",
    "# Das Buch (PEML) sagt, Random Forest ist robuster und einfacher.\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RANDOM FOREST MODELL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# DATEN VORBEREITEN \n",
    "print(\"\\nVorbereitung der Daten...\")\n",
    "\n",
    "# Entferne Zeilen mit NaN im Target (wie bei XGBoost)\n",
    "# Training\n",
    "train_mask = y_train.notna()\n",
    "X_train_clean = X_train[train_mask]\n",
    "y_train_clean = y_train[train_mask]\n",
    "\n",
    "# Validation\n",
    "val_mask = y_val.notna()\n",
    "X_val_clean = X_val[val_mask]\n",
    "y_val_clean = y_val[val_mask]\n",
    "\n",
    "print(f\"  Training: {len(X_train_clean)} Datenpunkte\")\n",
    "print(f\"  Validation: {len(X_val_clean)} Datenpunkte\")\n",
    "\n",
    "# Bei Random Forest muessen wir NaN in Features ersetzen\n",
    "# Das Buch (Praxiseinstieg ML) empfiehlt: Mit Mittelwert fuellen\n",
    "print(\"\\nErsetze fehlende Werte mit Mittelwert...\")\n",
    "\n",
    "# Berechne Mittelwerte aus Training\n",
    "mittelwerte = {}\n",
    "for spalte in X_train_clean.columns:\n",
    "    mittelwert = X_train_clean[spalte].mean()\n",
    "    if np.isnan(mittelwert):\n",
    "        mittelwert = 0  # Falls alles NaN ist\n",
    "    mittelwerte[spalte] = mittelwert\n",
    "    \n",
    "    # Fuellen\n",
    "    X_train_clean[spalte] = X_train_clean[spalte].fillna(mittelwert)\n",
    "\n",
    "# Gleiche Mittelwerte fuer Validation verwenden!\n",
    "for spalte in X_val_clean.columns:\n",
    "    if spalte in mittelwerte:\n",
    "        X_val_clean[spalte] = X_val_clean[spalte].fillna(mittelwerte[spalte])\n",
    "\n",
    "print(\"Fehlende Werte ersetzt\")\n",
    "\n",
    "# MODELL TRAINIEREN \n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Trainiere Random Forest...\")\n",
    "\n",
    "# Erstelle Modell mit Standard-Parametern aus dem Buch\n",
    "model_rf = RandomForestRegressor(\n",
    "    n_estimators=100,      # 100 Baeume\n",
    "    max_depth=10,          # Nicht zu tief (gegen Overfitting)\n",
    "    min_samples_split=10,  # Mindestens 10 Samples zum Split\n",
    "    random_state=42        # Fuer Reproduzierbarkeit\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"  Starte Training...\")\n",
    "model_rf.fit(X_train_clean, y_train_clean)\n",
    "print(\"  Training abgeschlossen!\")\n",
    "\n",
    "# MODELL BEWERTEN\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "# print(\"Bewerte Modell...\")\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train = model_rf.predict(X_train_clean)\n",
    "y_pred_val = model_rf.predict(X_val_clean)\n",
    "\n",
    "# Metriken berechnen\n",
    "# Training\n",
    "mae_train = mean_absolute_error(y_train_clean, y_pred_train)\n",
    "r2_train = r2_score(y_train_clean, y_pred_train)\n",
    "\n",
    "# Validation\n",
    "mae_val = mean_absolute_error(y_val_clean, y_pred_val)\n",
    "r2_val = r2_score(y_val_clean, y_pred_val)\n",
    "\n",
    "# Zusammenfassung\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ERGEBNISSE RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining:\")\n",
    "print(f\"  MAE:  {mae_train:.2f} ug/m3\")\n",
    "print(f\"  R2:   {r2_train:.3f}\")\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "print(f\"  MAE:  {mae_val:.2f} ug/m3\")\n",
    "print(f\"  R2:   {r2_val:.3f}\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Feature Importance (Top 5):\")\n",
    "\n",
    "importances = model_rf.feature_importances_\n",
    "feature_importance = sorted(zip(X_train_clean.columns, importances), \n",
    "                          key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (feature, importance) in enumerate(feature_importance[:5], 1):\n",
    "    prozent = importance * 100\n",
    "    print(f\"  {i}. {feature:20} {prozent:.1f}%\")\n",
    "\n",
    "# Speichere Modell\n",
    "model_rf_trained = model_rf\n",
    "print(\"\\nModell gespeichert als 'model_rf_trained'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf72e05-e3a3-4200-8cb7-1c95d8552676",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nach Zelle 12:\")\n",
    "print(\"model vorhanden:\", 'model' in locals())\n",
    "print(\"model_gb_trained vorhanden:\", 'model_gb_trained' in locals())\n",
    "print(\"model_rf_trained vorhanden:\", 'model_rf_trained' in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dbcd06-c495-4620-ab63-a36f23fe1913",
   "metadata": {},
   "source": [
    "---------------------------\n",
    ">>#### 5.1.4 Ensemble\n",
    ">>>##### 5.1.4.1 Ensemble - Grundlagen [3],[8]\n",
    "\n",
    ">>>**Mathematische Grundlagen**\n",
    ">>>```\n",
    ">>>f̂ₑₙₛₑₘᵦₗₑ(x) = 1/K ∑ₖ₌₁ᴷ f̂ₖ(x)  (Averaging-Ensemble)\n",
    ">>>```\n",
    "\n",
    ">>>**Gewichtung**\n",
    "\n",
    ">>>```\n",
    ">>>Keine Gewichtung - gleichgewichteter Durchschnitt\n",
    ">>>Jedes Modell hat Gewicht = 1/K\n",
    ">>>Bei 3 Modellen: je 1/3 (33.33%)\n",
    ">>>Bei 2 Modellen: je 1/2 (50%)\n",
    ">>>```\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b17b9de6-dea9-448e-9147-3a1ef2fcdd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENSEMBLE MODELL\n",
      "============================================================\n",
      "\n",
      "Verfuegbare Modelle:\n",
      "  - XGBoost\n",
      "  - Gradient Boosting\n",
      "  - Random Forest\n",
      "\n",
      "Anzahl Modelle: 3\n",
      "\n",
      "Bereite Daten vor...\n",
      "\n",
      " Vorhersagen mit allen Modellen...\n",
      "  XGBoost: OK\n",
      "  Gradient Boosting: OK\n",
      "  Random Forest: OK\n",
      "\n",
      "Berechne Durchschnitt...\n",
      "  Durchschnitt berechnet\n",
      "\n",
      "----------------------------------------\n",
      "Ensemble Ergebnisse:\n",
      "\n",
      "Training:\n",
      "  MAE:  3.74 ug/m3\n",
      "  RMSE: 5.32 ug/m3\n",
      "  R2:   0.592\n",
      "\n",
      "Validation:\n",
      "  MAE:  3.60 ug/m3\n",
      "  RMSE: 4.68 ug/m3\n",
      "  R2:   0.129\n",
      "\n",
      "----------------------------------------\n",
      "Vergleich mit Einzelmodellen (R2 Validation):\n",
      "  XGBoost              R2 = 0.088\n",
      "  Gradient Boosting    R2 = 0.099\n",
      "  Random Forest        R2 = 0.077\n",
      "  Ensemble             R2 = 0.129\n",
      "\n",
      "Ensemble ist besser als alle Einzelmodelle!\n",
      "  Verbesserung: 0.030\n",
      "\n",
      "Ensemble-Vorhersagen gespeichert\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5.1.4.2 ENSEMBLE - MODELLE KOMBINIEREN \n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENSEMBLE MODELL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pruefe welche Modelle vorhanden sind\n",
    "print(\"\\nVerfuegbare Modelle:\")\n",
    "modelle = []\n",
    "\n",
    "if 'model' in locals():\n",
    "    print(\"  - XGBoost\")\n",
    "    modelle.append(('XGBoost', model))\n",
    "\n",
    "if 'model_gb_trained' in locals():\n",
    "    print(\"  - Gradient Boosting\")\n",
    "    modelle.append(('Gradient Boosting', model_gb_trained))\n",
    "    \n",
    "if 'model_rf_trained' in locals():\n",
    "    print(\"  - Random Forest\")\n",
    "    modelle.append(('Random Forest', model_rf_trained))\n",
    "\n",
    "print(f\"\\nAnzahl Modelle: {len(modelle)}\")\n",
    "\n",
    "if len(modelle) < 2:\n",
    "    print(\"Brauche mindestens 2 Modelle fuer Ensemble!\")\n",
    "else:\n",
    "    # Bereite Daten vor\n",
    "    print(\"\\nBereite Daten vor...\")\n",
    "    \n",
    "    # Training\n",
    "    train_mask = y_train.notna()\n",
    "    X_train_clean = X_train[train_mask]\n",
    "    y_train_clean = y_train[train_mask]\n",
    "    \n",
    "    # Validation\n",
    "    val_mask = y_val.notna()\n",
    "    X_val_clean = X_val[val_mask]\n",
    "    y_val_clean = y_val[val_mask]\n",
    "    \n",
    "    # Fuelle NaN fuer Modelle die das brauchen\n",
    "    X_train_filled = X_train_clean.fillna(X_train_clean.mean())\n",
    "    X_val_filled = X_val_clean.fillna(X_val_clean.mean())\n",
    "    \n",
    "    # VORHERSAGEN SAMMELN \n",
    "    print(\"\\n Vorhersagen mit allen Modellen...\")\n",
    "    \n",
    "    # Training Vorhersagen\n",
    "    train_predictions = []\n",
    "    for name, modell in modelle:\n",
    "        if 'XGBoost' in name:\n",
    "            # XGBoost kann mit NaN umgehen\n",
    "            pred = modell.predict(X_train_clean)\n",
    "        else:\n",
    "            # Andere brauchen gefuellte Daten\n",
    "            pred = modell.predict(X_train_filled)\n",
    "        train_predictions.append(pred)\n",
    "        print(f\"  {name}: OK\")\n",
    "    \n",
    "    # Validation Vorhersagen\n",
    "    val_predictions = []\n",
    "    for name, modell in modelle:\n",
    "        if 'XGBoost' in name:\n",
    "            pred = modell.predict(X_val_clean)\n",
    "        else:\n",
    "            pred = modell.predict(X_val_filled)\n",
    "        val_predictions.append(pred)\n",
    "    \n",
    "    # DURCHSCHNITT BERECHNEN \n",
    "    print(\"\\nBerechne Durchschnitt...\")\n",
    "    \n",
    "    # Einfacher Durchschnitt\n",
    "    ensemble_train_pred = np.mean(train_predictions, axis=0)\n",
    "    ensemble_val_pred = np.mean(val_predictions, axis=0)\n",
    "    \n",
    "    print(\"  Durchschnitt berechnet\")\n",
    "    \n",
    "    # METRIKEN \n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Ensemble Ergebnisse:\")\n",
    "    \n",
    "    # Training\n",
    "    mae_train = mean_absolute_error(y_train_clean, ensemble_train_pred)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train_clean, ensemble_train_pred))\n",
    "    r2_train = r2_score(y_train_clean, ensemble_train_pred)\n",
    "    \n",
    "    print(f\"\\nTraining:\")\n",
    "    print(f\"  MAE:  {mae_train:.2f} ug/m3\")\n",
    "    print(f\"  RMSE: {rmse_train:.2f} ug/m3\")\n",
    "    print(f\"  R2:   {r2_train:.3f}\")\n",
    "    \n",
    "    # Validation\n",
    "    mae_val = mean_absolute_error(y_val_clean, ensemble_val_pred)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val_clean, ensemble_val_pred))\n",
    "    r2_val = r2_score(y_val_clean, ensemble_val_pred)\n",
    "    \n",
    "    print(f\"\\nValidation:\")\n",
    "    print(f\"  MAE:  {mae_val:.2f} ug/m3\")\n",
    "    print(f\"  RMSE: {rmse_val:.2f} ug/m3\")\n",
    "    print(f\"  R2:   {r2_val:.3f}\")\n",
    "    \n",
    "    # VERGLEICH \n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Vergleich mit Einzelmodellen (R2 Validation):\")\n",
    "    \n",
    "    # Einzelmodelle nochmal auswerten fuer Vergleich\n",
    "    einzeln_r2 = []\n",
    "    \n",
    "    for name, modell in modelle:\n",
    "        if 'XGBoost' in name:\n",
    "            pred = modell.predict(X_val_clean)\n",
    "        else:\n",
    "            pred = modell.predict(X_val_filled)\n",
    "        r2 = r2_score(y_val_clean, pred)\n",
    "        einzeln_r2.append((name, r2))\n",
    "        print(f\"  {name:20} R2 = {r2:.3f}\")\n",
    "    \n",
    "    print(f\"  {'Ensemble':20} R2 = {r2_val:.3f}\")\n",
    "    \n",
    "    # Ist Ensemble besser?\n",
    "    beste_einzeln = max(einzeln_r2, key=lambda x: x[1])\n",
    "    if r2_val > beste_einzeln[1]:\n",
    "        print(f\"\\nEnsemble ist besser als alle Einzelmodelle!\")\n",
    "        print(f\"  Verbesserung: {r2_val - beste_einzeln[1]:.3f}\")\n",
    "    else:\n",
    "        print(f\"\\nEnsemble ist nicht besser...\")\n",
    "    \n",
    "    # Speichere Ensemble Vorhersagen\n",
    "    ensemble_predictions = {\n",
    "        'train': ensemble_train_pred,\n",
    "        'val': ensemble_val_pred,\n",
    "        'r2_train': r2_train,\n",
    "        'r2_val': r2_val\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEnsemble-Vorhersagen gespeichert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b7aa723-fa94-42e8-a511-5dadbc35ae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODELLVERGLEICH\n",
      "============================================================\n",
      "\n",
      "Alle trainierten Modelle...\n",
      "  - XGBoost gefunden\n",
      "  - Gradient Boosting gefunden\n",
      "  - Random Forest gefunden\n",
      "  - Ensemble Vorhersagen gefunden\n",
      "\n",
      "Anzahl Modelle: 3\n",
      "\n",
      "----------------------------------------\n",
      "Bereite Daten vor...\n",
      "  Training: 69949 Samples\n",
      "  Validation: 8573 Samples\n",
      "\n",
      "----------------------------------------\n",
      "Evaluiere alle Modelle...\n",
      "\n",
      "Evaluiere XGBoost...\n",
      "  Training R2: 0.591\n",
      "  Validation R2: 0.088\n",
      "\n",
      "Evaluiere Gradient Boosting...\n",
      "  Training R2: 0.578\n",
      "  Validation R2: 0.099\n",
      "\n",
      "Evaluiere Random Forest...\n",
      "  Training R2: 0.561\n",
      "  Validation R2: 0.077\n",
      "\n",
      "Evaluiere Ensemble...\n",
      "  Training R2: 0.592\n",
      "  Validation R2: 0.129\n",
      "\n",
      "============================================================\n",
      "ERGEBNIS-TABELLE\n",
      "============================================================\n",
      "\n",
      "TRAINING PERFORMANCE:\n",
      "--------------------------------------------------\n",
      "Modell            | MAE    | RMSE   | R2\n",
      "--------------------------------------------------\n",
      "XGBoost           |   3.70 |   5.32 |  0.591\n",
      "Gradient Boosting |   3.75 |   5.41 |  0.578\n",
      "Random Forest     |   3.93 |   5.51 |  0.561\n",
      "Ensemble          |   3.74 |   5.32 |  0.592\n",
      "\n",
      "VALIDATION PERFORMANCE:\n",
      "--------------------------------------------------\n",
      "Modell            | MAE    | RMSE   | R2\n",
      "--------------------------------------------------\n",
      "XGBoost           |   3.63 |   4.79 |  0.088\n",
      "Gradient Boosting |   3.64 |   4.76 |  0.099\n",
      "Random Forest     |   3.68 |   4.81 |  0.077\n",
      "Ensemble          |   3.60 |   4.68 |  0.129\n",
      "\n",
      "--------------------------------------------------\n",
      "BESTES MODELL:\n",
      "\n",
      "Hoechster R2 (Validation): Ensemble mit R2 = 0.129\n",
      "Niedrigster MAE (Validation): Ensemble mit MAE = 3.60\n",
      "\n",
      "--------------------------------------------------\n",
      "OVERFITTING CHECK:\n",
      "(Training viel besser als Validation = Overfitting)\n",
      "\n",
      "XGBoost:\n",
      "  Training R2: 0.591\n",
      "  Validation R2: 0.088\n",
      "  Differenz: 0.503\n",
      "  --> STARKES OVERFITTING!\n",
      "\n",
      "Gradient Boosting:\n",
      "  Training R2: 0.578\n",
      "  Validation R2: 0.099\n",
      "  Differenz: 0.479\n",
      "  --> STARKES OVERFITTING!\n",
      "\n",
      "Random Forest:\n",
      "  Training R2: 0.561\n",
      "  Validation R2: 0.077\n",
      "  Differenz: 0.484\n",
      "  --> STARKES OVERFITTING!\n",
      "\n",
      "Ensemble:\n",
      "  Training R2: 0.592\n",
      "  Validation R2: 0.129\n",
      "  Differenz: 0.463\n",
      "  --> STARKES OVERFITTING!\n",
      "\n",
      "============================================================\n",
      "FAZIT\n",
      "============================================================\n",
      "\n",
      "Alle Modelle sind SCHLECHT (R2 < 0.2)\n",
      "\n",
      "Vergleich gespeichert in 'modell_vergleich'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5.1.5 MODELLVERGLEICH - ALLE MODELLE ZUSAMMEN\n",
    "#============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODELLVERGLEICH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ALLE MODELLE \n",
    "print(\"\\nAlle trainierten Modelle...\")\n",
    "\n",
    "modelle_liste = []\n",
    "\n",
    "# XGBoost\n",
    "if 'model' in locals():\n",
    "    modelle_liste.append(('XGBoost', model))\n",
    "    print(\"  - XGBoost gefunden\")\n",
    "else:\n",
    "    print(\"  - XGBoost nicht gefunden\")\n",
    "\n",
    "# Gradient Boosting\n",
    "if 'model_gb_trained' in locals():\n",
    "    modelle_liste.append(('Gradient Boosting', model_gb_trained))\n",
    "    print(\"  - Gradient Boosting gefunden\")\n",
    "else:\n",
    "    print(\"  - Gradient Boosting nicht gefunden\")\n",
    "\n",
    "# Random Forest\n",
    "if 'model_rf_trained' in locals():\n",
    "    modelle_liste.append(('Random Forest', model_rf_trained))\n",
    "    print(\"  - Random Forest gefunden\")\n",
    "else:\n",
    "    print(\"  - Random Forest nicht gefunden\")\n",
    "\n",
    "# Ensemble\n",
    "if 'ensemble_predictions' in locals():\n",
    "    print(\"  - Ensemble Vorhersagen gefunden\")\n",
    "else:\n",
    "    print(\"  - Ensemble nicht gefunden\")\n",
    "\n",
    "print(f\"\\nAnzahl Modelle: {len(modelle_liste)}\")\n",
    "\n",
    "if len(modelle_liste) == 0:\n",
    "    print(\"\\nKEINE MODELLE GEFUNDEN!\")\n",
    "    print(\"Bitte erst die Modell-Zellen ausfuehren:\")\n",
    "    print(\"  - Zelle 8: XGBoost\")\n",
    "    print(\"  - Zelle 11: Gradient Boosting\")\n",
    "    print(\"  - Zelle 12: Random Forest\")\n",
    "else:\n",
    "    # Datenvorbereitung\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Bereite Daten vor...\")\n",
    "    \n",
    "    # Training\n",
    "    train_mask = y_train.notna()\n",
    "    X_train_clean = X_train[train_mask]\n",
    "    y_train_clean = y_train[train_mask]\n",
    "    \n",
    "    # Validation\n",
    "    val_mask = y_val.notna()\n",
    "    X_val_clean = X_val[val_mask]\n",
    "    y_val_clean = y_val[val_mask]\n",
    "    \n",
    "    # Fuelle NaN fuer Modelle die das brauchen\n",
    "    X_train_filled = X_train_clean.fillna(X_train_clean.mean())\n",
    "    X_val_filled = X_val_clean.fillna(X_val_clean.mean())\n",
    "    \n",
    "    print(f\"  Training: {len(X_train_clean)} Samples\")\n",
    "    print(f\"  Validation: {len(X_val_clean)} Samples\")\n",
    "    \n",
    "    # JEDES MODELL\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Evaluiere alle Modelle...\")\n",
    "    \n",
    "    ergebnisse = []\n",
    "    \n",
    "    for modell_name, modell in modelle_liste:\n",
    "        print(f\"\\nEvaluiere {modell_name}...\")\n",
    "        \n",
    "        # Mache Vorhersagen\n",
    "        if 'XGBoost' in modell_name:\n",
    "            # XGBoost kann mit NaN umgehen\n",
    "            y_pred_train = modell.predict(X_train_clean)\n",
    "            y_pred_val = modell.predict(X_val_clean)\n",
    "        else:\n",
    "            # Andere brauchen gefuellte Daten\n",
    "            y_pred_train = modell.predict(X_train_filled)\n",
    "            y_pred_val = modell.predict(X_val_filled)\n",
    "        \n",
    "        # Berechne Metriken Training\n",
    "        mae_train = mean_absolute_error(y_train_clean, y_pred_train)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train_clean, y_pred_train))\n",
    "        r2_train = r2_score(y_train_clean, y_pred_train)\n",
    "        \n",
    "        # Berechne Metriken Validation\n",
    "        mae_val = mean_absolute_error(y_val_clean, y_pred_val)\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_val_clean, y_pred_val))\n",
    "        r2_val = r2_score(y_val_clean, y_pred_val)\n",
    "        \n",
    "        # Speichere Ergebnisse\n",
    "        ergebnisse.append({\n",
    "            'Modell': modell_name,\n",
    "            'MAE_Train': mae_train,\n",
    "            'RMSE_Train': rmse_train,\n",
    "            'R2_Train': r2_train,\n",
    "            'MAE_Val': mae_val,\n",
    "            'RMSE_Val': rmse_val,\n",
    "            'R2_Val': r2_val\n",
    "        })\n",
    "        \n",
    "        print(f\"  Training R2: {r2_train:.3f}\")\n",
    "        print(f\"  Validation R2: {r2_val:.3f}\")\n",
    "    \n",
    "    # Ensemble hinzufuegen (falls vorhanden)\n",
    "    if 'ensemble_predictions' in locals():\n",
    "        print(f\"\\nEvaluiere Ensemble...\")\n",
    "        \n",
    "        # Hole gespeicherte Vorhersagen\n",
    "        ensemble_train_pred = ensemble_predictions['train']\n",
    "        ensemble_val_pred = ensemble_predictions['val']\n",
    "        \n",
    "        # Berechne Metriken\n",
    "        mae_train = mean_absolute_error(y_train_clean, ensemble_train_pred)\n",
    "        rmse_train = np.sqrt(mean_squared_error(y_train_clean, ensemble_train_pred))\n",
    "        r2_train = ensemble_predictions['r2_train']\n",
    "        \n",
    "        mae_val = mean_absolute_error(y_val_clean, ensemble_val_pred)\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_val_clean, ensemble_val_pred))\n",
    "        r2_val = ensemble_predictions['r2_val']\n",
    "        \n",
    "        ergebnisse.append({\n",
    "            'Modell': 'Ensemble',\n",
    "            'MAE_Train': mae_train,\n",
    "            'RMSE_Train': rmse_train,\n",
    "            'R2_Train': r2_train,\n",
    "            'MAE_Val': mae_val,\n",
    "            'RMSE_Val': rmse_val,\n",
    "            'R2_Val': r2_val\n",
    "        })\n",
    "        \n",
    "        print(f\"  Training R2: {r2_train:.3f}\")\n",
    "        print(f\"  Validation R2: {r2_val:.3f}\")\n",
    "    \n",
    "    # VERGLEICHSTABELLE\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERGEBNIS-TABELLE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Training Ergebnisse\n",
    "    print(\"\\nTRAINING PERFORMANCE:\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"Modell            | MAE    | RMSE   | R2\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    for erg in ergebnisse:\n",
    "        modell_name = erg['Modell'].ljust(17)\n",
    "        mae = f\"{erg['MAE_Train']:.2f}\".rjust(6)\n",
    "        rmse = f\"{erg['RMSE_Train']:.2f}\".rjust(6)\n",
    "        r2 = f\"{erg['R2_Train']:.3f}\".rjust(6)\n",
    "        print(f\"{modell_name} | {mae} | {rmse} | {r2}\")\n",
    "    \n",
    "    # Validation Ergebnisse\n",
    "    print(\"\\nVALIDATION PERFORMANCE:\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"Modell            | MAE    | RMSE   | R2\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    for erg in ergebnisse:\n",
    "        modell_name = erg['Modell'].ljust(17)\n",
    "        mae = f\"{erg['MAE_Val']:.2f}\".rjust(6)\n",
    "        rmse = f\"{erg['RMSE_Val']:.2f}\".rjust(6)\n",
    "        r2 = f\"{erg['R2_Val']:.3f}\".rjust(6)\n",
    "        print(f\"{modell_name} | {mae} | {rmse} | {r2}\")\n",
    "    \n",
    "    # BESTES MODELL \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"BESTES MODELL:\")\n",
    "    \n",
    "    # Nach R2 Validation sortieren\n",
    "    beste_r2 = max(ergebnisse, key=lambda x: x['R2_Val'])\n",
    "    print(f\"\\nHoechster R2 (Validation): {beste_r2['Modell']} mit R2 = {beste_r2['R2_Val']:.3f}\")\n",
    "    \n",
    "    # Nach MAE Validation sortieren\n",
    "    beste_mae = min(ergebnisse, key=lambda x: x['MAE_Val'])\n",
    "    print(f\"Niedrigster MAE (Validation): {beste_mae['Modell']} mit MAE = {beste_mae['MAE_Val']:.2f}\")\n",
    "    \n",
    "    # OVERFITTING CHECK \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"OVERFITTING CHECK:\")\n",
    "    print(\"(Training viel besser als Validation = Overfitting)\")\n",
    "    \n",
    "    for erg in ergebnisse:\n",
    "        diff = erg['R2_Train'] - erg['R2_Val']\n",
    "        print(f\"\\n{erg['Modell']}:\")\n",
    "        print(f\"  Training R2: {erg['R2_Train']:.3f}\")\n",
    "        print(f\"  Validation R2: {erg['R2_Val']:.3f}\")\n",
    "        print(f\"  Differenz: {diff:.3f}\")\n",
    "        \n",
    "        if diff > 0.3:\n",
    "            print(\"  --> STARKES OVERFITTING!\")\n",
    "        elif diff > 0.15:\n",
    "            print(\"  --> Mittleres Overfitting\")\n",
    "        elif diff > 0.05:\n",
    "            print(\"  --> Leichtes Overfitting\")\n",
    "        else:\n",
    "            print(\"  --> Kein Overfitting\")\n",
    "\n",
    "    # Zusammenfassung\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FAZIT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Gesamtbewertung\n",
    "    if beste_r2['R2_Val'] < 0.2:\n",
    "        print(\"\\nAlle Modelle sind SCHLECHT (R2 < 0.2)\")\n",
    "     \n",
    "    elif beste_r2['R2_Val'] < 0.5:\n",
    "        print(f\"\\nBestes Modell ({beste_r2['Modell']}) ist OKAY (R2 = {beste_r2['R2_Val']:.3f})\")\n",
    "        print(\"Aber es gibt noch viel Raum fuer Verbesserung\")\n",
    "    else:\n",
    "        print(f\"\\nBestes Modell ({beste_r2['Modell']}) ist GUT (R2 = {beste_r2['R2_Val']:.3f})\")\n",
    "\n",
    "    # Speichere Vergleich\n",
    "    modell_vergleich = ergebnisse\n",
    "    print(\"\\nVergleich gespeichert in 'modell_vergleich'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc7605-3885-4541-8e85-3d71950a2c1e",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## 5.2 Iterative Durchführung\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d13a0f67-f01d-4091-ba62-613e23661728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTAUSWERTUNG AUTOKORRELATION\n",
      "============================================================\n",
      "\n",
      "📊 Erfasse Ergebnisse für: Test_5\n",
      "----------------------------------------\n",
      "Gesammelte Metriken:\n",
      "  n_features: 14\n",
      "  xgb_r2_train: 0.5914948983178479\n",
      "  xgb_r2_val: 0.08806590444781082\n",
      "  xgb_mae_train: 3.7021799354642746\n",
      "  xgb_mae_val: 3.6332224237188036\n",
      "  xgb_rmse_val: 4.786334182878064\n",
      "  top_feature_1: NO2_mean\n",
      "  top_importance_1: 0.1956249475479126\n",
      "  top_feature_2: month\n",
      "  top_importance_2: 0.128220334649086\n",
      "  has_lag_24h: False\n",
      "  has_lag_168h: True\n",
      "  has_rolling: False\n",
      "  gb_r2_val: 0.12080323349890476\n",
      "  gb_mae_val: 3.609869160893212\n",
      "  ensemble_r2_val: 0.12909432521316921\n",
      "\n",
      "✅ 6 vorherige Tests geladen\n",
      "📝 Test 'Test_5' aktualisiert\n",
      "💾 Ergebnisse gespeichert in: autokorrelation_test_results.json\n",
      "\n",
      "============================================================\n",
      "VERGLEICH ALLER TESTS\n",
      "============================================================\n",
      "\n",
      "📊 HAUPTMETRIKEN (XGBoost):\n",
      "------------------------------------------------------------\n",
      "test_name  xgb_r2_train  xgb_r2_val  xgb_mae_val  n_features\n",
      "   Test_0         0.951       0.872        1.326          16\n",
      "   Test_1         0.894       0.783        1.678          15\n",
      "   Test_2         0.729       0.132        2.995          15\n",
      "   Test_3         0.950       0.870        1.330          15\n",
      "   Test_4         0.566       0.130        3.591          13\n",
      "   Test_5         0.591       0.088        3.633          14\n",
      "\n",
      "🔍 TOP FEATURES:\n",
      "------------------------------------------------------------\n",
      "test_name    top_feature_1  top_importance_1 top_feature_2\n",
      "   Test_0 PM10_rolling_24h          0.730025  PM10_lag_24h\n",
      "   Test_1 PM10_rolling_24h          0.742154      NO2_mean\n",
      "   Test_2     PM10_lag_24h          0.370201      NO2_mean\n",
      "   Test_3 PM10_rolling_24h          0.724399  PM10_lag_24h\n",
      "   Test_4         NO2_mean          0.211154         month\n",
      "   Test_5         NO2_mean          0.195625         month\n",
      "\n",
      "🔄 LAG-FEATURES IN TOP 10:\n",
      "------------------------------------------------------------\n",
      "test_name  has_lag_24h  has_lag_168h  has_rolling\n",
      "   Test_0         True          True         True\n",
      "   Test_1        False          True         True\n",
      "   Test_2         True          True        False\n",
      "   Test_3         True         False         True\n",
      "   Test_4        False         False        False\n",
      "   Test_5        False          True        False\n",
      "\n",
      "📈 Erstelle Visualisierung...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Plot gespeichert als: autokorrelation_test_vergleich_20250826_093023.png\n",
      "\n",
      "============================================================\n",
      "EMPFEHLUNG\n",
      "============================================================\n",
      "\n",
      " EMPFOHLENER TEST: Test_1\n",
      "   R² Validation: 0.7826314437293842\n",
      "   MAE: 1.6784427105836062 µg/m³\n",
      "   Features: 15\n",
      "\n",
      " Gut: Keine problematische 24h-Autokorrelation\n",
      "\n",
      "============================================================\n",
      "Nächste Schritte:\n",
      "1. Kernel neu starten\n",
      "2. Nächsten Test in Zelle 6 aktivieren\n",
      "3. Notebook durchlaufen\n",
      "4. Diese Zelle erneut ausführen\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# 5.2.1 Zusammenfassung aller 6 Testergebnisse\n",
    "# ================================================================================\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "'''\n",
    "print(\"=\"*60)\n",
    "print(\"TESTAUSWERTUNG AUTOKORRELATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ================================================================================\n",
    "# SCHRITT 1: AKTUELLEN TEST IDENTIFIZIEREN\n",
    "# ================================================================================\n",
    "\n",
    "# Da wir keine ACTIVE_TEST Variable haben, manuell setzen\n",
    "# ÄNDERN SIE DIESE ZEILE für jeden Test!\n",
    "current_test = \"Test_5\"  # Ändern zu \"Test_1\", \"Test_2\", etc.\n",
    "\n",
    "print(f\"\\n📊 Erfasse Ergebnisse für: {current_test}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# ================================================================================\n",
    "# SCHRITT 2: ERGEBNISSE SAMMELN\n",
    "# ================================================================================\n",
    "\n",
    "# Sammle Metriken aus dem aktuellen Durchlauf\n",
    "current_results = {\n",
    "    'test_name': current_test,\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'n_features': X_train.shape[1] if 'X_train' in globals() else None,\n",
    "}\n",
    "\n",
    "# XGBoost Metriken (aus Zelle 9)\n",
    "if 'validation_metriken' in globals():\n",
    "    current_results['xgb_r2_train'] = training_metriken.get('r2', None) if 'training_metriken' in globals() else None\n",
    "    current_results['xgb_r2_val'] = validation_metriken.get('r2', None)\n",
    "    current_results['xgb_mae_train'] = training_metriken.get('mae', None) if 'training_metriken' in globals() else None\n",
    "    current_results['xgb_mae_val'] = validation_metriken.get('mae', None)\n",
    "    current_results['xgb_rmse_val'] = validation_metriken.get('rmse', None)\n",
    "\n",
    "# Feature Importance (aus Zelle 10)\n",
    "if 'feature_importance_dict' in globals():\n",
    "    # Sortiere nach Importance\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    if len(sorted_features) > 0:\n",
    "        current_results['top_feature_1'] = sorted_features[0][0]\n",
    "        current_results['top_importance_1'] = sorted_features[0][1]\n",
    "    if len(sorted_features) > 1:\n",
    "        current_results['top_feature_2'] = sorted_features[1][0]\n",
    "        current_results['top_importance_2'] = sorted_features[1][1]\n",
    "    \n",
    "    # Prüfe ob Lag-Features in Top 10\n",
    "    top_10_features = [f[0] for f in sorted_features[:10]]\n",
    "    current_results['has_lag_24h'] = 'PM10_lag_24h' in top_10_features\n",
    "    current_results['has_lag_168h'] = 'PM10_lag_168h' in top_10_features\n",
    "    current_results['has_rolling'] = 'PM10_rolling_24h' in top_10_features\n",
    "\n",
    "# Andere Modelle (falls vorhanden)\n",
    "if 'gb_results' in globals():\n",
    "    current_results['gb_r2_val'] = gb_results.get('val_r2', None)\n",
    "    current_results['gb_mae_val'] = gb_results.get('val_mae', None)\n",
    "\n",
    "if 'ensemble_predictions' in globals():\n",
    "    current_results['ensemble_r2_val'] = ensemble_predictions.get('r2_val', None)\n",
    "\n",
    "print(\"Gesammelte Metriken:\")\n",
    "for key, value in current_results.items():\n",
    "    if key not in ['timestamp', 'test_name']:\n",
    "        # Konvertiere numpy types zu Python types\n",
    "        if hasattr(value, 'item'):  # numpy scalar\n",
    "            current_results[key] = value.item()\n",
    "        elif isinstance(value, np.ndarray):  # numpy array\n",
    "            current_results[key] = value.tolist()\n",
    "        print(f\"  {key}: {current_results[key]}\")\n",
    "\n",
    "# ================================================================================\n",
    "# SCHRITT 3: ERGEBNISSE SPEICHERN\n",
    "# ================================================================================\n",
    "\n",
    "# Datei für persistente Speicherung\n",
    "results_file = 'autokorrelation_test_results.json'\n",
    "\n",
    "# Funktion zum Konvertieren von numpy zu Python types\n",
    "def convert_to_python_types(obj):\n",
    "    \"\"\"Konvertiert numpy types zu Python types für JSON\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_to_python_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_python_types(item) for item in obj]\n",
    "    elif hasattr(obj, 'item'):  # numpy scalar\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, np.ndarray):  # numpy array\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):  # NaN values\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Konvertiere current_results\n",
    "current_results = convert_to_python_types(current_results)\n",
    "\n",
    "# Lade existierende Ergebnisse\n",
    "try:\n",
    "    with open(results_file, 'r') as f:\n",
    "        all_results = json.load(f)\n",
    "    print(f\"\\n {len(all_results)} vorherige Tests geladen\")\n",
    "except:\n",
    "    all_results = []\n",
    "    print(\"\\n Neue Ergebnisdatei wird erstellt\")\n",
    "\n",
    "# Füge aktuelle Ergebnisse hinzu oder update\n",
    "test_exists = False\n",
    "for i, result in enumerate(all_results):\n",
    "    if result['test_name'] == current_test:\n",
    "        all_results[i] = current_results\n",
    "        test_exists = True\n",
    "        print(f\" Test '{current_test}' aktualisiert\")\n",
    "        break\n",
    "\n",
    "if not test_exists:\n",
    "    all_results.append(current_results)\n",
    "    print(f\" Test '{current_test}' hinzugefügt\")\n",
    "\n",
    "# Speichern (mit Fehlerbehandlung)\n",
    "try:\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\" Ergebnisse gespeichert in: {results_file}\")\n",
    "except TypeError as e:\n",
    "    print(f\" Fehler beim Speichern: {e}\")\n",
    "    print(\"Debug - Datentypen in current_results:\")\n",
    "    for key, value in current_results.items():\n",
    "        print(f\"  {key}: {type(value)}\")\n",
    "\n",
    "# ================================================================================\n",
    "# SCHRITT 4: VERGLEICHSTABELLE ERSTELLEN\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VERGLEICH ALLER TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Konvertiere zu DataFrame für bessere Darstellung\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Sortiere nach Test-Name\n",
    "if not df_results.empty:\n",
    "    df_results = df_results.sort_values('test_name')\n",
    "    \n",
    "    # Hauptmetriken\n",
    "    print(\"\\n HAUPTMETRIKEN (XGBoost):\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    display_cols = ['test_name', 'xgb_r2_train', 'xgb_r2_val', 'xgb_mae_val', 'n_features']\n",
    "    if all(col in df_results.columns for col in display_cols):\n",
    "        summary = df_results[display_cols].round(3)\n",
    "        print(summary.to_string(index=False))\n",
    "    \n",
    "    # Feature Importance Analyse\n",
    "    print(\"\\n TOP FEATURES:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    feature_cols = ['test_name', 'top_feature_1', 'top_importance_1', 'top_feature_2']\n",
    "    if all(col in df_results.columns for col in feature_cols):\n",
    "        features_df = df_results[feature_cols]\n",
    "        print(features_df.to_string(index=False))\n",
    "    \n",
    "    # Lag-Feature Präsenz\n",
    "    print(\"\\n LAG-FEATURES IN TOP 10:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    lag_cols = ['test_name', 'has_lag_24h', 'has_lag_168h', 'has_rolling']\n",
    "    if all(col in df_results.columns for col in lag_cols):\n",
    "        lag_df = df_results[lag_cols]\n",
    "        print(lag_df.to_string(index=False))\n",
    "\n",
    "# ================================================================================\n",
    "# SCHRITT 5: VISUALISIERUNG\n",
    "# ================================================================================\n",
    "\n",
    "if len(all_results) > 1:\n",
    "    print(\"\\n Erstelle Visualisierung...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Autokorrelations-Test Vergleich', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: R² Vergleich\n",
    "    ax1 = axes[0, 0]\n",
    "    tests = df_results['test_name'].values\n",
    "    x_pos = np.arange(len(tests))\n",
    "    \n",
    "    if 'xgb_r2_train' in df_results.columns and 'xgb_r2_val' in df_results.columns:\n",
    "        ax1.bar(x_pos - 0.2, df_results['xgb_r2_train'], 0.4, label='Training', alpha=0.7)\n",
    "        ax1.bar(x_pos + 0.2, df_results['xgb_r2_val'], 0.4, label='Validation', alpha=0.7)\n",
    "        ax1.set_xlabel('Test')\n",
    "        ax1.set_ylabel('R² Score')\n",
    "        ax1.set_title('R² Score Vergleich')\n",
    "        ax1.set_xticks(x_pos)\n",
    "        ax1.set_xticklabels(tests, rotation=45)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Akzeptabel')\n",
    "    \n",
    "    # Plot 2: MAE Vergleich\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'xgb_mae_val' in df_results.columns:\n",
    "        ax2.bar(tests, df_results['xgb_mae_val'], color='orange', alpha=0.7)\n",
    "        ax2.set_xlabel('Test')\n",
    "        ax2.set_ylabel('MAE (µg/m³)')\n",
    "        ax2.set_title('Mean Absolute Error (Validation)')\n",
    "        ax2.set_xticklabels(tests, rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.axhline(y=5, color='r', linestyle='--', alpha=0.5, label='Ziel')\n",
    "    \n",
    "    # Plot 3: Feature Count\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'n_features' in df_results.columns:\n",
    "        ax3.bar(tests, df_results['n_features'], color='green', alpha=0.7)\n",
    "        ax3.set_xlabel('Test')\n",
    "        ax3.set_ylabel('Anzahl Features')\n",
    "        ax3.set_title('Feature-Anzahl pro Test')\n",
    "        ax3.set_xticklabels(tests, rotation=45)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Overfitting Check\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'xgb_r2_train' in df_results.columns and 'xgb_r2_val' in df_results.columns:\n",
    "        overfitting = df_results['xgb_r2_train'] - df_results['xgb_r2_val']\n",
    "        colors = ['red' if x > 0.15 else 'orange' if x > 0.1 else 'green' for x in overfitting]\n",
    "        ax4.bar(tests, overfitting, color=colors, alpha=0.7)\n",
    "        ax4.set_xlabel('Test')\n",
    "        ax4.set_ylabel('R² Differenz (Train - Val)')\n",
    "        ax4.set_title('Overfitting Check')\n",
    "        ax4.set_xticklabels(tests, rotation=45)\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.axhline(y=0.1, color='orange', linestyle='--', alpha=0.5, label='Warnung')\n",
    "        ax4.axhline(y=0.15, color='red', linestyle='--', alpha=0.5, label='Kritisch')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Speichere Plot\n",
    "    plot_file = f'autokorrelation_test_vergleich_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
    "    fig.savefig(plot_file, dpi=150, bbox_inches='tight')\n",
    "    print(f\"📊 Plot gespeichert als: {plot_file}\")\n",
    "\n",
    "# ================================================================================\n",
    "# SCHRITT 6: EMPFEHLUNG\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EMPFEHLUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(all_results) >= 3:\n",
    "    # Finde besten Kompromiss\n",
    "    best_test = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for result in all_results:\n",
    "        if result.get('xgb_r2_val'):\n",
    "            r2 = result['xgb_r2_val']\n",
    "            # Penalty für Tests mit lag_24h\n",
    "            if result.get('has_lag_24h', False):\n",
    "                r2 *= 0.8  # 20% Penalty für Autokorrelation\n",
    "            \n",
    "            if r2 > best_score:\n",
    "                best_score = r2\n",
    "                best_test = result['test_name']\n",
    "    \n",
    "    if best_test:\n",
    "        print(f\"\\n EMPFOHLENER TEST: {best_test}\")\n",
    "        best_result = [r for r in all_results if r['test_name'] == best_test][0]\n",
    "        print(f\"   R² Validation: {best_result.get('xgb_r2_val', 'N/A')}\")\n",
    "        print(f\"   MAE: {best_result.get('xgb_mae_val', 'N/A')} µg/m³\")\n",
    "        print(f\"   Features: {best_result.get('n_features', 'N/A')}\")\n",
    "        \n",
    "        if best_result.get('has_lag_24h'):\n",
    "            print(\"\\n  Warnung: Nutzt noch PM10_lag_24h - starke Autokorrelation!\")\n",
    "        else:\n",
    "            print(\"\\n Gut: Keine problematische 24h-Autokorrelation\")\n",
    "else:\n",
    "    print(\"\\n⏳ Führen Sie mindestens 3 Tests durch für eine Empfehlung\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Nächste Schritte:\")\n",
    "print(\"1. Kernel neu starten\")\n",
    "print(\"2. Nächsten Test in Zelle 6 aktivieren\")\n",
    "print(\"3. Notebook durchlaufen\")\n",
    "print(\"4. Diese Zelle erneut ausführen\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022da260-9bf2-4bf9-b2e4-f1fd685a4344",
   "metadata": {},
   "source": [
    ">## 5.3 Wissenschaftliche Auswertung \n",
    "\n",
    ">>#### 5.3.1 Zusammenfassung der Untersuchung\n",
    "\n",
    ">>Diese Untersuchung analysiert systematisch den Einfluss von Lag-Features auf die Vorhersagegenauigkeit von PM10-Feinstaubkonzentrationen. Die Ergebnisse zeigen, dass die scheinbar hohe Modellperformance (R² = 0.872) primär auf Autokorrelation basiert und bei Entfernung der zeitversetzten Features auf R² = 0.13 kollabiert.\n",
    "\n",
    ">>####5.3.2 Methodik und Datenbasis\n",
    "\n",
    "\n",
    ">>- **Zeitraum:** 2015-2024 (87.601 stündliche Messungen)\n",
    ">>- **Stationen:** 13 PM10-Messstationen in NRW\n",
    ">>>>- **Parameter:** PM10, NO2, NO, O3, SO2, Temperatur, Feuchtigkeit, Windgeschwindigkeit, Windrichtung\n",
    "- **Datenaufteilung:** 80% Training (2015-2022), 10% Validation (2023), 10% Test (2024)\n",
    "\n",
    ">>#### 5.3.3 Experimentelles Design\n",
    "\n",
    ">>Sechs systematische Tests mit unterschiedlichen Feature-Konfigurationen:\n",
    "\n",
    "| Test | Entfernte Features | Hypothese |\n",
    "|------|-------------------|-----------|\n",
    "| Test 0 | Baseline (alle Features) | Maximale Performance mit Autokorrelation |\n",
    "| Test 1 | PM10_lag_24h | Einfluss des 24h-Lag quantifizieren |\n",
    "| Test 2 | PM10_rolling_24h | Bedeutung des gleitenden Mittelwerts |\n",
    "| Test 3 | PM10_lag_168h | Relevanz von Wochenmustern |\n",
    "| Test 4 | Alle PM10-Lag-Features | Reine meteorologische Vorhersage |\n",
    "| Test 5 | Test 4 + erweiterte Meteorologie | Maximale nicht-autokorrelative Performance |\n",
    "\n",
    "\n",
    ">>#### 5.3.4 Modellperformance (Ergebnistabelle)\n",
    "\n",
    "| Test | R² Training | R² Validation | MAE (µg/m³) | Dominantes Feature | Feature Importance |\n",
    "|------|------------|---------------|-------------|-------------------|-------------------|\n",
    "| Test 0 | 0.951 | 0.872 | 1.33 | PM10_rolling_24h | 73.0% |\n",
    "| Test 1 | 0.894 | 0.783 | 1.68 | PM10_rolling_24h | 74.2% |\n",
    "| Test 2 | 0.729 | **0.132** | 2.99 | PM10_lag_24h | 37.0% |\n",
    "| Test 3 | 0.950 | 0.870 | 1.33 | PM10_rolling_24h | 72.4% |\n",
    "| Test 4 | 0.566 | **0.130** | 3.59 | NO2_mean | 21.1% |\n",
    "| Test 5 | 0.591 | **0.088** | 3.63 | NO2_mean | 19.6% |\n",
    "\n",
    ">>#### 5.3.5 Kritische Beobachtungen\n",
    "\n",
    ">>1. **PM10_rolling_24h dominiert mit 73% Feature Importance** und erklärt allein 74% der Modellperformance (Differenz Test 0 zu Test 2)\n",
    "\n",
    ">>2. **Ohne Autokorrelation sinkt R² auf 0.13**, was nur 13% erklärter Varianz entspricht\n",
    "\n",
    ">>3. **Meteorologische Features sind insuffizient** für PM10-Vorhersage, selbst mit erweiterten Features (Test 5) verschlechtert sich die Performance\n",
    "\n",
    "\n",
    "\n",
    ">>#### 5.3.6 Autokorrelationsproblematik\n",
    "\n",
    ">>Die hohe Autokorrelation in PM10-Zeitreihen (r = 0.60-0.70 für 24h-Lag) entsteht durch physikalische Prozesse:\n",
    "\n",
    ">>- **Grenzschichthöhe:** Tageszyklus von 50-300m (nachts) zu 1200m (tags) erzeugt persistente Muster [15] (https://www.frontiersin.org/articles/10.3389/feart.2016.00070/full)\n",
    ">>- **Depositionsgeschwindigkeit:** PM10 mit 3.19 ± 1.18 cm/s führt zu Verweildauern von 5-8 Tagen [16] (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0199241)\n",
    ">>- **Temperaturinversionen:** Können 3-7 Tage anhalten und PM10 einschließen [17 ] (https://www.sciencedirect.com/science/article/pii/S1352231016302254)\n",
    "\n",
    ">>#### 5.3.7 Modellinterpretation\n",
    "\n",
    ">>Das XGBoost-Modell mit Lag-Features implementiert faktisch ein Persistenz-Modell:\n",
    "\n",
    ">>```\n",
    ">>PM10(t+1) ≈ mean(PM10[t-24:t]) + ε\n",
    ">>```\n",
    "\n",
    ">>Die marginale Verbesserung durch meteorologische Features (ε) zeigt, dass lokale Wetterparameter allein keine substantielle Vorhersagekraft besitzen.\n",
    "\n",
    ">>#### 5.3.8 Vergleich mit operationellen Systemen\n",
    "\n",
    ">>Moderne Vorhersagesysteme erreichen durch Hybrid-Ansätze deutlich bessere Performance:\n",
    "\n",
    ">>- **CAMS (Copernicus):** Ensemble aus 11 CTMs mit 4D-Var Assimilation [18] (https://atmosphere.copernicus.eu/regional-production)\n",
    ">>- **CMAQ-CNN:** Hybride CTM-ML Systeme erreichen 40% Fehlerreduktion [19] (https://www.sciencedirect.com/science/article/abs/pii/S1352231022000267)\n",
    "\n",
    ">>Diese Systeme integrieren Emissionsinventare, Grenzschichthöhen und chemische Transformationsprozesse.\n",
    "\n",
    ">>#### 5.3.9 Limitationen und Ausblick\n",
    "\n",
    ">>**Fehlende Datenquellen**\n",
    "\n",
    ">>Für verbesserte PM10-Vorhersage wären erforderlich:\n",
    ">>- Grenzschichthöhe (aus Radiosonden oder ERA5-Reanalyse)\n",
    ">>- Emissionsdaten (Verkehrszählungen, Industrieaktivität)\n",
    ">>- Regionale Hintergrundbelastung (aus CTMs)\n",
    "\n",
    ">>#### 5.3.10 Fazit\n",
    "\n",
    ">>Die Untersuchung demonstriert, dass hohe Validierungsmetriken bei Luftqualitätsvorhersagen kritisch hinterfragt werden müssen. Die scheinbare Genauigkeit von R² = 0.872 basiert zu 85 % auf einfacher Autokorrelation. Für operationelle Vorhersagen ohne zeitnahe PM10-Messungen ist die reale Modellperformance mit R² ≈ 0.13 praktisch unbrauchbar. Dies unterstreicht die Notwendigkeit prozessbasierter Modelle, die Emissionen, Transport und chemische Transformation explizit berücksichtigen. \n",
    "Das Notebook dokumentiert einen typischen Data Science Prozess: Problem lösen wollen → verdächtige Ergebnisse → kritisch hinterfragen → systematisch testen → ehrliche Schlussfolgerungen ziehen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e60c5-9ca6-4c92-a75c-44dc8208513a",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "## 6. Zusammenfassung der ML-SEMESTERARBEIT: PM10-Vorhersage \n",
    "\n",
    "**Projektziel & Methodik**\n",
    "\n",
    "XGBoost-basierte PM10-Feinstaubvorhersage für Köln und Duisburg mit LANUV-Daten (2015-2025). Systematische Testung von 6 Feature-Kombinationen (Test_0 bis Test_5) zur Identifikation der Autokorrelations-Abhängigkeit.\n",
    "Kernergebnisse der Tests\n",
    "\n",
    "- **Test_0** (Baseline mit allen Features): R²=0.872, MAE=1.33 μg/m³\n",
    "- **Test_4** (ohne Autokorrelation): R²=0.130, MAE=3.59 μg/m³\n",
    "- **Verlust:** 85% der Vorhersagekraft stammte aus PM10_rolling_24h (73% Feature Importance)\n",
    "- **Fazit:** Meteorologie allein erklärt nur 13% der PM10-Varianz\n",
    "\n",
    "**Systematische Test-Erkenntnisse**\n",
    "\n",
    "- **Test_1** (ohne lag_24h): R²=0.783 → rolling_24h kompensiert\n",
    "- **Test_2** (ohne rolling_24h): R²=0.132 → Modell bricht zusammen\n",
    "- **Test_3** (ohne lag_168h): R²=0.870 → Wochenmuster unwichtig\n",
    "- **Test_4/5** (ohne alle Lag/Rolling): R²=0.088-0.130 → wahre Vorhersagekraft\n",
    "\n",
    "**Modellbewertung**\n",
    "\n",
    "Alle Algorithmen (XGBoost, Gradient Boosting, Ensemble) zeigen identisches Verhalten. Problem liegt NICHT am Modell, sondern an fehlenden erklärenden Variablen. Mit vorhandenen Features ist R²=0.13 das realistische Maximum.\n",
    "\n",
    "**Mögliche, konkrete nächste Schritte mit Datenquellen**\n",
    "\n",
    "**1. Grenzschichthöhe (größter Impact):**\n",
    "\n",
    "DWD COSMO-REA6: https://opendata.dwd.de/climate_environment/REA/COSMO_REA6/\n",
    "Parameter \"HSURF\", stündlich, 6x6km Auflösung\n",
    "\n",
    "**2. Verkehrsdaten (Hauptquelle urbaner PM10):**\n",
    "\n",
    "MDM-Portal: https://www.mdm-portal.de/\n",
    "Verkehr.NRW Echtzeit: https://www.verkehr.nrw.de/\n",
    "\n",
    "**3. Emissionskataster:**\n",
    "\n",
    "LANUV interaktiv: https://www.ekl.nrw.de/\n",
    "1x1 km² Raster, CSV-Export\n",
    "\n",
    "**Wissenschaftlicher Beitrag**\n",
    "\n",
    "Systematischer Nachweis, dass hohe R²-Werte bei Luftqualitäts-Zeitreihen primär auf Autokorrelation basieren. Die Tests zeigen transparent: Rolling-Features maskieren fehlende Modellqualität.\n",
    "\n",
    "**Weiteres Vorgehen (von mir so bisher geplant)**\n",
    "\n",
    "- Ergänzung des Modells mit den \"fehlenden\" Features (was viel Zeit in Anspruch nehmen wird)\n",
    "- Hybrid-Ansatz: Physikalisch begründete Lag-Features (24h/168h) intelligent nutzen, kombiniert mit externen Datenquellen. Test_1 könnte als Ausgangsbasis (R²=0.783) trotz Autokorrelation für praktische Anwendung vertretbar sein. Es wäre sinnvoll, die Autokorrelation anhand von ergänzenden Daten \"herleitbar\" zu machen, damit dadurch die Autokorrelation als Muster erkennbar wird.\n",
    "- Aus der Literatur lassen sich damit durchaus Werte von R² = 0.4-0.6 und einem MAE =5-8 μg/m³ erreichen. [21], [22]\n",
    ">>**Favorisierter, neuer Ansatz:**\n",
    "\n",
    ">>- Autokorrelation ist der NORMALZUSTAND (physikalisch bedingt)\n",
    ">>- PM10 verhält sich meistens autokorrelativ\n",
    ">>- Interessant sind die AUSNAHMEN - wenn Autokorrelation bricht - also eine Art der \"Ausreißerbetrachtung\"!\n",
    "\n",
    ">>> **Fragen:**\n",
    "\n",
    ">>>- WANN bricht die Autokorrelation?\n",
    ">>>- WARUM bricht sie? (Events, Wetterumschwung, etc.)\n",
    ">>>- WIE können wir diese Bruchpunkte vorhersagen?\n",
    "\n",
    ">>>**Hypothese:**\n",
    ">>>Die Momente, wo PM10 NICHT autokorrelativ ist, sind genau die kritischen Events (Silvester, Saharastaub, Verkehrschaos, Industrieunfälle), die wir eigentlich vorhersagen wollen!\n",
    "\n",
    ">>>***Methodik***\n",
    "\n",
    ">>>-Autokorrelations-Stabilität über Zeit messen\n",
    ">>>-Bruchpunkte identifizieren\n",
    ">>>-Muster in den Bruchpunkten finden\n",
    "\n",
    "\n",
    "**Persönliche Lessons Learned**\n",
    "\n",
    "Ich habe die Datenvorbereitung völlig unterschätzt. Die reine Datenvorbereitung und das „Beschäftigen“ mit den Daten hat weit über 100 Stunden in Anspruch genommen. Des Weiteren ist es schwierig im „Testen“ auch gleichzeitig zu dokumentieren, mit der Konsequenz, dass man manchmal nicht mehr weiß, was man gemacht hatte. Ich bleibe bei meinem Ziel, die Daten über die Semester weiter zu behalten und daran zu wachsen. Gerade im Transfer Learning scheint es in Bezug auf den vorliegenden Daten einen höheren \"Foschungsbedarf\" zu geben. Bisher habe ich keinen Hinweis gefunden, dass Transfer Learning (Station-Station; Stadt - Stadt;...) genutzt wurde. Aus meiner Sicht wäre dies ein Mehrwert für die Städte, Gemeinden, der Gesellschaft.\n",
    "Das \"Aufhübschen\" und die Dokumentation des Notebooks ist sehr zeitaufwendig.\n",
    "\n",
    "**Fazit**\n",
    "\n",
    "Der Preis eines guten Ergebnisses, aus dem Gesamtmodell, wäre das \"i-Tüpfelchen\"  gewesen. Der Einsatz der Modelle war richtig. Die Datensubstanz ist zu gering und bildete nicht die meisten möglichen Erklärungsbedarfe ab. Das vorliegende Gesamtmodell ist NICHT zu verwenden, ist allerdings eine sehr gute Basis für die weitere Ergänzung.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee6e8d6-0ee0-4a42-bf14-a46a430dbd9f",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "## 7.LITERATURVERZEICHNIS UND QUELLEN\n",
    "\n",
    "[1] https://www.opengeodata.nrw.de/produkte/umwelt_klima/luftqualitaet/luqs/konti_nach_komponenten/\n",
    "\n",
    "[2] https://www.lanuk.nrw.de/\n",
    "\n",
    "[3] Praxiseinstieg Machine Learning\n",
    "\n",
    "[4] https://de.wikipedia.org/wiki/No-free-Lunch-Theoreme\n",
    "\n",
    "[5] Statistical persistence of air pollutants in Mexico City \n",
    "\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S0378437115001065\n",
    "\n",
    "[6] Time-Series Forecasting of PM2.5 and PM10 Concentrations - PMC\n",
    "\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC11722996/\n",
    "\n",
    "[7] PM10 and PM2.5 real-time prediction models using interpolated CNN - Nature\n",
    "\n",
    "https://www.nature.com/articles/s41598-021-91253-9\n",
    "\n",
    "[8] scikit-learn: Lagged features for time series forecasting\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_time_series_lagged_features.html\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn\n",
    "\n",
    "[9] https://facebook.github.io/prophet/\n",
    "\n",
    "https://github.com/facebook/prophet\n",
    "\n",
    "[10] XGBoost: A Scalable Tree Boosting System, Chen & Guestrin (2016),\n",
    "\n",
    "https://arxiv.org/pdf/1603.02754\n",
    "\n",
    "[11] XGBoost Official Documentation\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/\n",
    "https://github.com/dmlc/xgboost\n",
    "\n",
    "[12] Friedman (2001) - \"Greedy Function Approximation: A Gradient Boosting Machine\"\n",
    "\n",
    "https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.full\n",
    "\n",
    "[13] Breiman (2001) - Original Random Forest Paper\n",
    "\n",
    "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "\n",
    "[14] Dietterich (2000) - \"Ensemble Methods in Machine Learning\"\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/3-540-45014-9_1\n",
    "\n",
    "[15] Largeron, Y., & Staquet, C. (2016). The Atmospheric Boundary Layer during Wintertime Persistent Inversions in the Grenoble Valleys. *Frontiers in Earth Science*, 4, 70.\n",
    "\n",
    "https://www.frontiersin.org/articles/10.3389/feart.2016.00070/full\n",
    "\n",
    "[16] Zhang, Y., et al. (2018). Comparison of dry and wet deposition of particulate matter in near-surface waters during summer. *PLOS ONE*, 13(6), e0199241.\n",
    "\n",
    "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0199241\n",
    "\n",
    "[17] Largeron, Y., & Staquet, C. (2016). Persistent inversion dynamics and wintertime PM10 air pollution in Alpine valleys. *Atmospheric Environment*, 135, 92-108.\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S1352231016302254\n",
    "\n",
    "[18] Marécal, V., et al. (2015). A regional air quality forecasting system over Europe: the MACC-II daily ensemble production. *Geoscientific Model Development*, 8, 2777-2813.\n",
    "\n",
    "ttps://atmosphere.copernicus.eu/regional-production\n",
    "\n",
    "[19] Sayeed, A., et al. (2022). CMAQ-CNN: A new-generation of post-processing techniques for chemical transport models using deep neural networks. *Atmospheric Environment*, 273, 118961.\n",
    "\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S1352231022000267\n",
    "\n",
    "[20] Bozdağ et al. (2020) - Spatial prediction of PM10 concentration using machine learning algorithms in Ankara, Turkey\n",
    "\n",
    "Link: https://www.sciencedirect.com/science/article/abs/pii/S0269749120312306\n",
    "\n",
    "[21] Just et al. (2022) - Prediction of daily mean and one-hour maximum PM2.5 concentrations in Central Mexico\n",
    "\n",
    "Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC9731899/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce986e-8fc6-4f49-a64a-d785d7ca5597",
   "metadata": {},
   "source": [
    "## 8. Anhang: Testergebnisse im Detail (Test 0-5)\n",
    "\n",
    "### Test 0 - Baseline\n",
    "- **Features:** Alle inkl. PM10_lag_24h, PM10_lag_168h, PM10_rolling_24h\n",
    "- **Performance:** R² = 0.872, MAE = 1.33 µg/m³\n",
    "- **Interpretation:** Höchste Performance durch Autokorrelation\n",
    "\n",
    "### Test 1 - Ohne PM10_lag_24h\n",
    "- **Entfernt:** 24-Stunden Lag\n",
    "- **Performance:** R² = 0.783, MAE = 1.68 µg/m³\n",
    "- **Verlust:** 10% R² Reduktion\n",
    "\n",
    "### Test 2 - Ohne PM10_rolling_24h\n",
    "- **Entfernt:** Gleitender 24h-Durchschnitt\n",
    "- **Performance:** R² = 0.132, MAE = 2.99 µg/m³\n",
    "- **Verlust:** 85% R² Reduktion - kritisches Feature\n",
    "\n",
    "### Test 3 - Ohne PM10_lag_168h\n",
    "- **Entfernt:** Wochen-Lag (168h)\n",
    "- **Performance:** R² = 0.870, MAE = 1.33 µg/m³\n",
    "- **Verlust:** Minimal - Wochenmuster irrelevant\n",
    "\n",
    "### Test 4 - Ohne alle Lag-Features\n",
    "- **Entfernt:** Alle PM10-basierten Features\n",
    "- **Performance:** R² = 0.130, MAE = 3.59 µg/m³\n",
    "- **Interpretation:** Reine meteorologische Vorhersage versagt\n",
    "\n",
    "### Test 5 - Erweiterte Meteorologie ohne Lags\n",
    "- **Features:** Zusätzliche Interaktionsterme, Polynome\n",
    "- **Performance:** R² = 0.088, MAE = 3.63 µg/m³\n",
    "- **Interpretation:** Mehr Features verschlechtern sogar Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f4570-10ff-4af0-8bd5-85f931045a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
